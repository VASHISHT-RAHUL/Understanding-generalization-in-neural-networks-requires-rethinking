{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Generalization_requires_rethinking_v1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["x6IF70RPlbn2","YhxuJRPKlboI","pXgvUubulboN","eP8oBKZClboV","H4PkIBO-lbo6","KMkycZSqlbpA","TtXvK5oxlbpT","tpNYNVyKlbpX"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"bOmWKXFjlbmv","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from tqdm import tqdm\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hxBi-WWUlbm1","colab":{}},"source":["transform = transforms.Compose(\n","    [transforms.CenterCrop((28,28)),transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","# transform = transforms.Compose(\n","#     [transforms.ToTensor(),transforms.CenterCrop(28,28)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"US00oroClbm6","outputId":"6d9e8d58-f1af-4c15-e445-5ffeac121b8e","executionInfo":{"status":"ok","timestamp":1567863963019,"user_tz":-330,"elapsed":23835,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["cifar_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","cifar_testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":[" 99%|█████████▉| 168861696/170498071 [00:19<00:00, 12325165.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1GpM77y3lbm_"},"source":["# Training set with Random Labels"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j3Dudp74lbnA","outputId":"6988138e-8f9a-4717-85e6-5744a7537e5e","executionInfo":{"status":"ok","timestamp":1567863964856,"user_tz":-330,"elapsed":21070,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cifar_trainset_random = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","\n","cifar_trainset_random.targets[:50000] = np.random.randint(low=0,high=9,size=50000)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Rw01W4v5lbnE","outputId":"96c5d4c9-4710-467a-d5d5-40235d1d5cf1","executionInfo":{"status":"ok","timestamp":1567863964857,"user_tz":-330,"elapsed":20703,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.unique(cifar_trainset.targets)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hm8UA6SplbnI","colab":{}},"source":["trainloader = torch.utils.data.DataLoader(cifar_trainset, batch_size=256,\n","                                          shuffle=True, num_workers=2)\n","testloader = torch.utils.data.DataLoader(cifar_testset, batch_size=256,\n","                                         shuffle=False, num_workers=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bR0BA7BSlbnL","colab":{}},"source":["trainloader_random = torch.utils.data.DataLoader(cifar_trainset_random,batch_size=256,shuffle=True,num_workers=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lXtGmO_olbnN","colab":{}},"source":["classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OUYkWWyVlbnQ","colab":{}},"source":["dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6eCTbUwvlbnS","colab":{}},"source":["dataiter_random = iter(trainloader_random)\n","images_random, labels_random = dataiter_random.next()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n3JXiTX1lbnV","colab":{}},"source":["def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-U2z7N4mlbnZ","outputId":"231e9216-be82-418f-9f96-5ff12ca02b19","executionInfo":{"status":"ok","timestamp":1567863967079,"user_tz":-330,"elapsed":19452,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["imshow(torchvision.utils.make_grid(images[:4]))\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHeVhAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["GroundTruth:  plane truck  bird horse\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x8zYJUdQlbnd","outputId":"01537ff9-d870-4c1b-dfdc-46079f238dfb","executionInfo":{"status":"ok","timestamp":1567863967079,"user_tz":-330,"elapsed":17999,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["imshow(torchvision.utils.make_grid(images_random[:4]))\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels_random[j]] for j in range(4)))"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["GroundTruth:   frog   cat  frog horse\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3SqXFtvdlbnf","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(3*28*28,512)\n","        self.fc2 = nn.Linear(512,512)\n","        self.fc3 = nn.Linear(512,512)\n","        self.fc4 = nn.Linear(512,10)\n","#         self.conv1 = nn.Conv2d(3, 6, 5)\n","#         self.pool = nn.MaxPool2d(2, 2)\n","#         self.conv2 = nn.Conv2d(6, 16, 5)\n","#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","#         self.fc2 = nn.Linear(120, 84)\n","#         self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        #x = x - x.mean(dim=(0,2),keepdim=True)/x.std(dim=(0,2),keepdim=True)\n","        \n","        x = (x.view(-1,3*28*28))\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = self.fc4(x)\n","#         x = self.pool(F.relu(self.conv1(x)))\n","#         x = self.pool(F.relu(self.conv2(x)))\n","#         x = x.view(-1, 16 * 5 * 5)\n","#         x = F.relu(self.fc1(x))\n","#         x = F.relu(self.fc2(x))\n","#         x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rC_AK1bNlbnh","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wRmkKcxAlbnj","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N5p7hsWYlbnm","outputId":"c3fc2e5c-02f5-4f6c-b3f2-9af402e12e43","colab":{"base_uri":"https://localhost:8080/","height":4216}},"source":["for epoch in range(100):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 50 == 49:    # print every 50 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 50))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,    50] loss: 2.284\n","[1,   100] loss: 2.158\n","[1,   150] loss: 1.990\n","[2,    50] loss: 1.796\n","[2,   100] loss: 1.739\n","[2,   150] loss: 1.675\n","[3,    50] loss: 1.590\n","[3,   100] loss: 1.539\n","[3,   150] loss: 1.549\n","[4,    50] loss: 1.463\n","[4,   100] loss: 1.447\n","[4,   150] loss: 1.434\n","[5,    50] loss: 1.379\n","[5,   100] loss: 1.362\n","[5,   150] loss: 1.334\n","[6,    50] loss: 1.294\n","[6,   100] loss: 1.315\n","[6,   150] loss: 1.292\n","[7,    50] loss: 1.233\n","[7,   100] loss: 1.227\n","[7,   150] loss: 1.255\n","[8,    50] loss: 1.166\n","[8,   100] loss: 1.173\n","[8,   150] loss: 1.185\n","[9,    50] loss: 1.100\n","[9,   100] loss: 1.133\n","[9,   150] loss: 1.128\n","[10,    50] loss: 1.063\n","[10,   100] loss: 1.062\n","[10,   150] loss: 1.076\n","[11,    50] loss: 1.009\n","[11,   100] loss: 1.035\n","[11,   150] loss: 1.020\n","[12,    50] loss: 0.960\n","[12,   100] loss: 0.979\n","[12,   150] loss: 0.970\n","[13,    50] loss: 0.916\n","[13,   100] loss: 0.935\n","[13,   150] loss: 0.939\n","[14,    50] loss: 0.849\n","[14,   100] loss: 0.860\n","[14,   150] loss: 0.883\n","[15,    50] loss: 0.793\n","[15,   100] loss: 0.827\n","[15,   150] loss: 0.852\n","[16,    50] loss: 0.752\n","[16,   100] loss: 0.777\n","[16,   150] loss: 0.800\n","[17,    50] loss: 0.718\n","[17,   100] loss: 0.730\n","[17,   150] loss: 0.741\n","[18,    50] loss: 0.659\n","[18,   100] loss: 0.686\n","[18,   150] loss: 0.709\n","[19,    50] loss: 0.616\n","[19,   100] loss: 0.639\n","[19,   150] loss: 0.656\n","[20,    50] loss: 0.567\n","[20,   100] loss: 0.601\n","[20,   150] loss: 0.640\n","[21,    50] loss: 0.562\n","[21,   100] loss: 0.555\n","[21,   150] loss: 0.580\n","[22,    50] loss: 0.504\n","[22,   100] loss: 0.497\n","[22,   150] loss: 0.537\n","[23,    50] loss: 0.475\n","[23,   100] loss: 0.486\n","[23,   150] loss: 0.512\n","[24,    50] loss: 0.417\n","[24,   100] loss: 0.437\n","[24,   150] loss: 0.467\n","[25,    50] loss: 0.378\n","[25,   100] loss: 0.385\n","[25,   150] loss: 0.414\n","[26,    50] loss: 0.344\n","[26,   100] loss: 0.385\n","[26,   150] loss: 0.393\n","[27,    50] loss: 0.347\n","[27,   100] loss: 0.335\n","[27,   150] loss: 0.357\n","[28,    50] loss: 0.358\n","[28,   100] loss: 0.323\n","[28,   150] loss: 0.332\n","[29,    50] loss: 0.297\n","[29,   100] loss: 0.276\n","[29,   150] loss: 0.323\n","[30,    50] loss: 0.276\n","[30,   100] loss: 0.250\n","[30,   150] loss: 0.250\n","[31,    50] loss: 0.238\n","[31,   100] loss: 0.231\n","[31,   150] loss: 0.252\n","[32,    50] loss: 0.236\n","[32,   100] loss: 0.215\n","[32,   150] loss: 0.231\n","[33,    50] loss: 0.188\n","[33,   100] loss: 0.179\n","[33,   150] loss: 0.197\n","[34,    50] loss: 0.195\n","[34,   100] loss: 0.179\n","[34,   150] loss: 0.198\n","[35,    50] loss: 0.159\n","[35,   100] loss: 0.143\n","[35,   150] loss: 0.176\n","[36,    50] loss: 0.161\n","[36,   100] loss: 0.138\n","[36,   150] loss: 0.169\n","[37,    50] loss: 0.150\n","[37,   100] loss: 0.129\n","[37,   150] loss: 0.130\n","[38,    50] loss: 0.129\n","[38,   100] loss: 0.145\n","[38,   150] loss: 0.128\n","[39,    50] loss: 0.125\n","[39,   100] loss: 0.098\n","[39,   150] loss: 0.103\n","[40,    50] loss: 0.131\n","[40,   100] loss: 0.127\n","[40,   150] loss: 0.114\n","[41,    50] loss: 0.080\n","[41,   100] loss: 0.108\n","[41,   150] loss: 0.116\n","[42,    50] loss: 0.102\n","[42,   100] loss: 0.115\n","[42,   150] loss: 0.133\n","[43,    50] loss: 0.149\n","[43,   100] loss: 0.118\n","[43,   150] loss: 0.097\n","[44,    50] loss: 0.087\n","[44,   100] loss: 0.084\n","[44,   150] loss: 0.075\n","[45,    50] loss: 0.069\n","[45,   100] loss: 0.085\n","[45,   150] loss: 0.093\n","[46,    50] loss: 0.070\n","[46,   100] loss: 0.070\n","[46,   150] loss: 0.076\n","[47,    50] loss: 0.107\n","[47,   100] loss: 0.092\n","[47,   150] loss: 0.105\n","[48,    50] loss: 0.078\n","[48,   100] loss: 0.079\n","[48,   150] loss: 0.071\n","[49,    50] loss: 0.054\n","[49,   100] loss: 0.053\n","[49,   150] loss: 0.060\n","[50,    50] loss: 0.059\n","[50,   100] loss: 0.069\n","[50,   150] loss: 0.055\n","[51,    50] loss: 0.060\n","[51,   100] loss: 0.054\n","[51,   150] loss: 0.064\n","[52,    50] loss: 0.042\n","[52,   100] loss: 0.047\n","[52,   150] loss: 0.049\n","[53,    50] loss: 0.036\n","[53,   100] loss: 0.033\n","[53,   150] loss: 0.031\n","[54,    50] loss: 0.027\n","[54,   100] loss: 0.030\n","[54,   150] loss: 0.031\n","[55,    50] loss: 0.029\n","[55,   100] loss: 0.027\n","[55,   150] loss: 0.021\n","[56,    50] loss: 0.026\n","[56,   100] loss: 0.022\n","[56,   150] loss: 0.027\n","[57,    50] loss: 0.066\n","[57,   100] loss: 0.064\n","[57,   150] loss: 0.075\n","[58,    50] loss: 0.107\n","[58,   100] loss: 0.117\n","[58,   150] loss: 0.106\n","[59,    50] loss: 0.115\n","[59,   100] loss: 0.108\n","[59,   150] loss: 0.129\n","[60,    50] loss: 0.074\n","[60,   100] loss: 0.069\n","[60,   150] loss: 0.059\n","[61,    50] loss: 0.059\n","[61,   100] loss: 0.040\n","[61,   150] loss: 0.037\n","[62,    50] loss: 0.033\n","[62,   100] loss: 0.023\n","[62,   150] loss: 0.027\n","[63,    50] loss: 0.019\n","[63,   100] loss: 0.016\n","[63,   150] loss: 0.012\n","[64,    50] loss: 0.004\n","[64,   100] loss: 0.003\n","[64,   150] loss: 0.002\n","[65,    50] loss: 0.001\n","[65,   100] loss: 0.001\n","[65,   150] loss: 0.001\n","[66,    50] loss: 0.001\n","[66,   100] loss: 0.001\n","[66,   150] loss: 0.001\n","[67,    50] loss: 0.001\n","[67,   100] loss: 0.001\n","[67,   150] loss: 0.001\n","[68,    50] loss: 0.001\n","[68,   100] loss: 0.001\n","[68,   150] loss: 0.001\n","[69,    50] loss: 0.001\n","[69,   100] loss: 0.001\n","[69,   150] loss: 0.001\n","[70,    50] loss: 0.001\n","[70,   100] loss: 0.001\n","[70,   150] loss: 0.001\n","[71,    50] loss: 0.001\n","[71,   100] loss: 0.001\n","[71,   150] loss: 0.001\n","[72,    50] loss: 0.001\n","[72,   100] loss: 0.001\n","[72,   150] loss: 0.001\n","[73,    50] loss: 0.001\n","[73,   100] loss: 0.001\n","[73,   150] loss: 0.000\n","[74,    50] loss: 0.000\n","[74,   100] loss: 0.000\n","[74,   150] loss: 0.000\n","[75,    50] loss: 0.000\n","[75,   100] loss: 0.000\n","[75,   150] loss: 0.001\n","[76,    50] loss: 0.000\n","[76,   100] loss: 0.000\n","[76,   150] loss: 0.000\n","[77,    50] loss: 0.000\n","[77,   100] loss: 0.000\n","[77,   150] loss: 0.000\n","[78,    50] loss: 0.000\n","[78,   100] loss: 0.000\n","[78,   150] loss: 0.000\n","[79,    50] loss: 0.000\n","[79,   100] loss: 0.000\n","[79,   150] loss: 0.000\n","[80,    50] loss: 0.000\n","[80,   100] loss: 0.000\n","[80,   150] loss: 0.000\n","[81,    50] loss: 0.000\n","[81,   100] loss: 0.000\n","[81,   150] loss: 0.000\n","[82,    50] loss: 0.000\n","[82,   100] loss: 0.000\n","[82,   150] loss: 0.000\n","[83,    50] loss: 0.000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RXvaDpDZlbnp","outputId":"a2080c1c-cabd-4581-d2df-417b658ed5b0","colab":{}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in trainloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 50000 train images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 50000 train images: 100 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0k2EE2USlbnr","outputId":"350f024d-4ecc-40df-8e10-5b793946c88a","colab":{}},"source":["total,correct"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 50000)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pL8Atxa7lbnt","outputId":"4908c4d9-94c0-4330-f69d-b3d6024b1c99","colab":{}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 55 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9-0CUnM_lbnw","colab":{}},"source":["dataiter = iter(testloader)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6dkQ28Y5lbny","outputId":"17118ec1-a709-44de-8466-3f95fa08ab98","colab":{}},"source":["images, labels = dataiter.next()\n","\n","# print images\n","imshow(torchvision.utils.make_grid(images[:4]))\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["GroundTruth:    cat  ship  ship plane\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D_Wf0aDXlbn0","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x6IF70RPlbn2"},"source":["# Training with Random Labels"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q_ISKD7Ulbn2","colab":{}},"source":["net_random_labels = Net()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PZT-76OLlbn4","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net_random_labels.parameters(), lr=0.01, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wi9qBZoelbn6","outputId":"b1c9fc02-26cc-42b2-926e-01eb7bab4a72","colab":{}},"source":["for epoch in range(300):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader_random, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net_random_labels(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 50 == 49:    # print every 50 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 50))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,    50] loss: 2.277\n","[1,   100] loss: 2.229\n","[1,   150] loss: 2.209\n","[2,    50] loss: 2.200\n","[2,   100] loss: 2.201\n","[2,   150] loss: 2.201\n","[3,    50] loss: 2.199\n","[3,   100] loss: 2.198\n","[3,   150] loss: 2.199\n","[4,    50] loss: 2.197\n","[4,   100] loss: 2.198\n","[4,   150] loss: 2.198\n","[5,    50] loss: 2.196\n","[5,   100] loss: 2.196\n","[5,   150] loss: 2.196\n","[6,    50] loss: 2.195\n","[6,   100] loss: 2.194\n","[6,   150] loss: 2.196\n","[7,    50] loss: 2.193\n","[7,   100] loss: 2.194\n","[7,   150] loss: 2.193\n","[8,    50] loss: 2.191\n","[8,   100] loss: 2.191\n","[8,   150] loss: 2.191\n","[9,    50] loss: 2.188\n","[9,   100] loss: 2.190\n","[9,   150] loss: 2.189\n","[10,    50] loss: 2.187\n","[10,   100] loss: 2.188\n","[10,   150] loss: 2.188\n","[11,    50] loss: 2.183\n","[11,   100] loss: 2.183\n","[11,   150] loss: 2.183\n","[12,    50] loss: 2.177\n","[12,   100] loss: 2.180\n","[12,   150] loss: 2.179\n","[13,    50] loss: 2.173\n","[13,   100] loss: 2.173\n","[13,   150] loss: 2.174\n","[14,    50] loss: 2.165\n","[14,   100] loss: 2.166\n","[14,   150] loss: 2.169\n","[15,    50] loss: 2.156\n","[15,   100] loss: 2.158\n","[15,   150] loss: 2.162\n","[16,    50] loss: 2.147\n","[16,   100] loss: 2.152\n","[16,   150] loss: 2.151\n","[17,    50] loss: 2.138\n","[17,   100] loss: 2.139\n","[17,   150] loss: 2.143\n","[18,    50] loss: 2.120\n","[18,   100] loss: 2.125\n","[18,   150] loss: 2.132\n","[19,    50] loss: 2.108\n","[19,   100] loss: 2.108\n","[19,   150] loss: 2.116\n","[20,    50] loss: 2.082\n","[20,   100] loss: 2.099\n","[20,   150] loss: 2.096\n","[21,    50] loss: 2.066\n","[21,   100] loss: 2.075\n","[21,   150] loss: 2.083\n","[22,    50] loss: 2.039\n","[22,   100] loss: 2.061\n","[22,   150] loss: 2.060\n","[23,    50] loss: 2.004\n","[23,   100] loss: 2.032\n","[23,   150] loss: 2.035\n","[24,    50] loss: 1.976\n","[24,   100] loss: 1.987\n","[24,   150] loss: 2.013\n","[25,    50] loss: 1.946\n","[25,   100] loss: 1.958\n","[25,   150] loss: 1.987\n","[26,    50] loss: 1.901\n","[26,   100] loss: 1.919\n","[26,   150] loss: 1.958\n","[27,    50] loss: 1.864\n","[27,   100] loss: 1.897\n","[27,   150] loss: 1.918\n","[28,    50] loss: 1.826\n","[28,   100] loss: 1.845\n","[28,   150] loss: 1.868\n","[29,    50] loss: 1.750\n","[29,   100] loss: 1.821\n","[29,   150] loss: 1.831\n","[30,    50] loss: 1.732\n","[30,   100] loss: 1.754\n","[30,   150] loss: 1.778\n","[31,    50] loss: 1.658\n","[31,   100] loss: 1.701\n","[31,   150] loss: 1.730\n","[32,    50] loss: 1.605\n","[32,   100] loss: 1.622\n","[32,   150] loss: 1.681\n","[33,    50] loss: 1.543\n","[33,   100] loss: 1.586\n","[33,   150] loss: 1.597\n","[34,    50] loss: 1.466\n","[34,   100] loss: 1.537\n","[34,   150] loss: 1.552\n","[35,    50] loss: 1.404\n","[35,   100] loss: 1.434\n","[35,   150] loss: 1.500\n","[36,    50] loss: 1.364\n","[36,   100] loss: 1.394\n","[36,   150] loss: 1.443\n","[37,    50] loss: 1.278\n","[37,   100] loss: 1.318\n","[37,   150] loss: 1.366\n","[38,    50] loss: 1.217\n","[38,   100] loss: 1.245\n","[38,   150] loss: 1.318\n","[39,    50] loss: 1.139\n","[39,   100] loss: 1.193\n","[39,   150] loss: 1.253\n","[40,    50] loss: 1.070\n","[40,   100] loss: 1.108\n","[40,   150] loss: 1.159\n","[41,    50] loss: 1.005\n","[41,   100] loss: 1.038\n","[41,   150] loss: 1.121\n","[42,    50] loss: 0.963\n","[42,   100] loss: 1.008\n","[42,   150] loss: 1.027\n","[43,    50] loss: 0.910\n","[43,   100] loss: 0.953\n","[43,   150] loss: 0.986\n","[44,    50] loss: 0.838\n","[44,   100] loss: 0.877\n","[44,   150] loss: 0.929\n","[45,    50] loss: 0.767\n","[45,   100] loss: 0.806\n","[45,   150] loss: 0.881\n","[46,    50] loss: 0.773\n","[46,   100] loss: 0.781\n","[46,   150] loss: 0.794\n","[47,    50] loss: 0.713\n","[47,   100] loss: 0.730\n","[47,   150] loss: 0.762\n","[48,    50] loss: 0.684\n","[48,   100] loss: 0.658\n","[48,   150] loss: 0.727\n","[49,    50] loss: 0.603\n","[49,   100] loss: 0.611\n","[49,   150] loss: 0.670\n","[50,    50] loss: 0.604\n","[50,   100] loss: 0.592\n","[50,   150] loss: 0.649\n","[51,    50] loss: 0.553\n","[51,   100] loss: 0.562\n","[51,   150] loss: 0.593\n","[52,    50] loss: 0.523\n","[52,   100] loss: 0.515\n","[52,   150] loss: 0.556\n","[53,    50] loss: 0.496\n","[53,   100] loss: 0.491\n","[53,   150] loss: 0.522\n","[54,    50] loss: 0.442\n","[54,   100] loss: 0.441\n","[54,   150] loss: 0.469\n","[55,    50] loss: 0.497\n","[55,   100] loss: 0.472\n","[55,   150] loss: 0.473\n","[56,    50] loss: 0.414\n","[56,   100] loss: 0.419\n","[56,   150] loss: 0.453\n","[57,    50] loss: 0.424\n","[57,   100] loss: 0.453\n","[57,   150] loss: 0.424\n","[58,    50] loss: 0.397\n","[58,   100] loss: 0.362\n","[58,   150] loss: 0.375\n","[59,    50] loss: 0.361\n","[59,   100] loss: 0.343\n","[59,   150] loss: 0.390\n","[60,    50] loss: 0.337\n","[60,   100] loss: 0.313\n","[60,   150] loss: 0.355\n","[61,    50] loss: 0.320\n","[61,   100] loss: 0.306\n","[61,   150] loss: 0.381\n","[62,    50] loss: 0.305\n","[62,   100] loss: 0.288\n","[62,   150] loss: 0.335\n","[63,    50] loss: 0.271\n","[63,   100] loss: 0.274\n","[63,   150] loss: 0.301\n","[64,    50] loss: 0.317\n","[64,   100] loss: 0.298\n","[64,   150] loss: 0.306\n","[65,    50] loss: 0.289\n","[65,   100] loss: 0.286\n","[65,   150] loss: 0.290\n","[66,    50] loss: 0.251\n","[66,   100] loss: 0.256\n","[66,   150] loss: 0.230\n","[67,    50] loss: 0.267\n","[67,   100] loss: 0.254\n","[67,   150] loss: 0.266\n","[68,    50] loss: 0.265\n","[68,   100] loss: 0.222\n","[68,   150] loss: 0.248\n","[69,    50] loss: 0.221\n","[69,   100] loss: 0.217\n","[69,   150] loss: 0.232\n","[70,    50] loss: 0.225\n","[70,   100] loss: 0.206\n","[70,   150] loss: 0.212\n","[71,    50] loss: 0.190\n","[71,   100] loss: 0.164\n","[71,   150] loss: 0.171\n","[72,    50] loss: 0.201\n","[72,   100] loss: 0.195\n","[72,   150] loss: 0.210\n","[73,    50] loss: 0.197\n","[73,   100] loss: 0.190\n","[73,   150] loss: 0.192\n","[74,    50] loss: 0.189\n","[74,   100] loss: 0.198\n","[74,   150] loss: 0.208\n","[75,    50] loss: 0.159\n","[75,   100] loss: 0.152\n","[75,   150] loss: 0.171\n","[76,    50] loss: 0.164\n","[76,   100] loss: 0.146\n","[76,   150] loss: 0.148\n","[77,    50] loss: 0.145\n","[77,   100] loss: 0.148\n","[77,   150] loss: 0.175\n","[78,    50] loss: 0.154\n","[78,   100] loss: 0.141\n","[78,   150] loss: 0.160\n","[79,    50] loss: 0.143\n","[79,   100] loss: 0.120\n","[79,   150] loss: 0.141\n","[80,    50] loss: 0.189\n","[80,   100] loss: 0.161\n","[80,   150] loss: 0.154\n","[81,    50] loss: 0.150\n","[81,   100] loss: 0.157\n","[81,   150] loss: 0.143\n","[82,    50] loss: 0.151\n","[82,   100] loss: 0.134\n","[82,   150] loss: 0.146\n","[83,    50] loss: 0.161\n","[83,   100] loss: 0.128\n","[83,   150] loss: 0.125\n","[84,    50] loss: 0.109\n","[84,   100] loss: 0.100\n","[84,   150] loss: 0.095\n","[85,    50] loss: 0.090\n","[85,   100] loss: 0.083\n","[85,   150] loss: 0.089\n","[86,    50] loss: 0.080\n","[86,   100] loss: 0.080\n","[86,   150] loss: 0.070\n","[87,    50] loss: 0.121\n","[87,   100] loss: 0.094\n","[87,   150] loss: 0.106\n","[88,    50] loss: 0.115\n","[88,   100] loss: 0.092\n","[88,   150] loss: 0.100\n","[89,    50] loss: 0.108\n","[89,   100] loss: 0.109\n","[89,   150] loss: 0.107\n","[90,    50] loss: 0.100\n","[90,   100] loss: 0.095\n","[90,   150] loss: 0.090\n","[91,    50] loss: 0.099\n","[91,   100] loss: 0.093\n","[91,   150] loss: 0.093\n","[92,    50] loss: 0.077\n","[92,   100] loss: 0.074\n","[92,   150] loss: 0.071\n","[93,    50] loss: 0.076\n","[93,   100] loss: 0.068\n","[93,   150] loss: 0.087\n","[94,    50] loss: 0.065\n","[94,   100] loss: 0.067\n","[94,   150] loss: 0.081\n","[95,    50] loss: 0.074\n","[95,   100] loss: 0.069\n","[95,   150] loss: 0.051\n","[96,    50] loss: 0.067\n","[96,   100] loss: 0.068\n","[96,   150] loss: 0.059\n","[97,    50] loss: 0.080\n","[97,   100] loss: 0.083\n","[97,   150] loss: 0.103\n","[98,    50] loss: 0.096\n","[98,   100] loss: 0.081\n","[98,   150] loss: 0.099\n","[99,    50] loss: 0.125\n","[99,   100] loss: 0.110\n","[99,   150] loss: 0.115\n","[100,    50] loss: 0.076\n","[100,   100] loss: 0.065\n","[100,   150] loss: 0.074\n","[101,    50] loss: 0.090\n","[101,   100] loss: 0.073\n","[101,   150] loss: 0.086\n","[102,    50] loss: 0.104\n","[102,   100] loss: 0.101\n","[102,   150] loss: 0.110\n","[103,    50] loss: 0.097\n","[103,   100] loss: 0.088\n","[103,   150] loss: 0.094\n","[104,    50] loss: 0.088\n","[104,   100] loss: 0.083\n","[104,   150] loss: 0.079\n","[105,    50] loss: 0.064\n","[105,   100] loss: 0.049\n","[105,   150] loss: 0.064\n","[106,    50] loss: 0.052\n","[106,   100] loss: 0.049\n","[106,   150] loss: 0.054\n","[107,    50] loss: 0.048\n","[107,   100] loss: 0.041\n","[107,   150] loss: 0.048\n","[108,    50] loss: 0.041\n","[108,   100] loss: 0.037\n","[108,   150] loss: 0.033\n","[109,    50] loss: 0.028\n","[109,   100] loss: 0.028\n","[109,   150] loss: 0.030\n","[110,    50] loss: 0.037\n","[110,   100] loss: 0.038\n","[110,   150] loss: 0.034\n","[111,    50] loss: 0.044\n","[111,   100] loss: 0.040\n","[111,   150] loss: 0.050\n","[112,    50] loss: 0.045\n","[112,   100] loss: 0.031\n","[112,   150] loss: 0.032\n","[113,    50] loss: 0.033\n","[113,   100] loss: 0.037\n","[113,   150] loss: 0.036\n","[114,    50] loss: 0.046\n","[114,   100] loss: 0.045\n"],"name":"stdout"},{"output_type":"stream","text":["[114,   150] loss: 0.059\n","[115,    50] loss: 0.065\n","[115,   100] loss: 0.078\n","[115,   150] loss: 0.080\n","[116,    50] loss: 0.104\n","[116,   100] loss: 0.077\n","[116,   150] loss: 0.108\n","[117,    50] loss: 0.106\n","[117,   100] loss: 0.110\n","[117,   150] loss: 0.094\n","[118,    50] loss: 0.116\n","[118,   100] loss: 0.115\n","[118,   150] loss: 0.109\n","[119,    50] loss: 0.107\n","[119,   100] loss: 0.083\n","[119,   150] loss: 0.077\n","[120,    50] loss: 0.061\n","[120,   100] loss: 0.060\n","[120,   150] loss: 0.055\n","[121,    50] loss: 0.031\n","[121,   100] loss: 0.023\n","[121,   150] loss: 0.019\n","[122,    50] loss: 0.020\n","[122,   100] loss: 0.013\n","[122,   150] loss: 0.013\n","[123,    50] loss: 0.008\n","[123,   100] loss: 0.011\n","[123,   150] loss: 0.009\n","[124,    50] loss: 0.004\n","[124,   100] loss: 0.003\n","[124,   150] loss: 0.006\n","[125,    50] loss: 0.004\n","[125,   100] loss: 0.005\n","[125,   150] loss: 0.005\n","[126,    50] loss: 0.005\n","[126,   100] loss: 0.006\n","[126,   150] loss: 0.003\n","[127,    50] loss: 0.002\n","[127,   100] loss: 0.002\n","[127,   150] loss: 0.005\n","[128,    50] loss: 0.002\n","[128,   100] loss: 0.001\n","[128,   150] loss: 0.002\n","[129,    50] loss: 0.001\n","[129,   100] loss: 0.004\n","[129,   150] loss: 0.001\n","[130,    50] loss: 0.001\n","[130,   100] loss: 0.003\n","[130,   150] loss: 0.002\n","[131,    50] loss: 0.001\n","[131,   100] loss: 0.002\n","[131,   150] loss: 0.001\n","[132,    50] loss: 0.001\n","[132,   100] loss: 0.002\n","[132,   150] loss: 0.001\n","[133,    50] loss: 0.001\n","[133,   100] loss: 0.002\n","[133,   150] loss: 0.001\n","[134,    50] loss: 0.001\n","[134,   100] loss: 0.000\n","[134,   150] loss: 0.002\n","[135,    50] loss: 0.001\n","[135,   100] loss: 0.001\n","[135,   150] loss: 0.000\n","[136,    50] loss: 0.000\n","[136,   100] loss: 0.001\n","[136,   150] loss: 0.001\n","[137,    50] loss: 0.001\n","[137,   100] loss: 0.000\n","[137,   150] loss: 0.001\n","[138,    50] loss: 0.001\n","[138,   100] loss: 0.001\n","[138,   150] loss: 0.000\n","[139,    50] loss: 0.001\n","[139,   100] loss: 0.000\n","[139,   150] loss: 0.001\n","[140,    50] loss: 0.001\n","[140,   100] loss: 0.000\n","[140,   150] loss: 0.001\n","[141,    50] loss: 0.000\n","[141,   100] loss: 0.001\n","[141,   150] loss: 0.001\n","[142,    50] loss: 0.000\n","[142,   100] loss: 0.000\n","[142,   150] loss: 0.001\n","[143,    50] loss: 0.000\n","[143,   100] loss: 0.000\n","[143,   150] loss: 0.001\n","[144,    50] loss: 0.001\n","[144,   100] loss: 0.001\n","[144,   150] loss: 0.001\n","[145,    50] loss: 0.000\n","[145,   100] loss: 0.001\n","[145,   150] loss: 0.001\n","[146,    50] loss: 0.001\n","[146,   100] loss: 0.000\n","[146,   150] loss: 0.000\n","[147,    50] loss: 0.000\n","[147,   100] loss: 0.000\n","[147,   150] loss: 0.000\n","[148,    50] loss: 0.001\n","[148,   100] loss: 0.000\n","[148,   150] loss: 0.001\n","[149,    50] loss: 0.001\n","[149,   100] loss: 0.001\n","[149,   150] loss: 0.000\n","[150,    50] loss: 0.001\n","[150,   100] loss: 0.000\n","[150,   150] loss: 0.001\n","[151,    50] loss: 0.001\n","[151,   100] loss: 0.000\n","[151,   150] loss: 0.001\n","[152,    50] loss: 0.000\n","[152,   100] loss: 0.000\n","[152,   150] loss: 0.001\n","[153,    50] loss: 0.000\n","[153,   100] loss: 0.001\n","[153,   150] loss: 0.000\n","[154,    50] loss: 0.000\n","[154,   100] loss: 0.000\n","[154,   150] loss: 0.001\n","[155,    50] loss: 0.000\n","[155,   100] loss: 0.000\n","[155,   150] loss: 0.000\n","[156,    50] loss: 0.000\n","[156,   100] loss: 0.001\n","[156,   150] loss: 0.001\n","[157,    50] loss: 0.000\n","[157,   100] loss: 0.001\n","[157,   150] loss: 0.000\n","[158,    50] loss: 0.000\n","[158,   100] loss: 0.000\n","[158,   150] loss: 0.001\n","[159,    50] loss: 0.000\n","[159,   100] loss: 0.000\n","[159,   150] loss: 0.001\n","[160,    50] loss: 0.001\n","[160,   100] loss: 0.001\n","[160,   150] loss: 0.000\n","[161,    50] loss: 0.001\n","[161,   100] loss: 0.000\n","[161,   150] loss: 0.000\n","[162,    50] loss: 0.000\n","[162,   100] loss: 0.000\n","[162,   150] loss: 0.001\n","[163,    50] loss: 0.001\n","[163,   100] loss: 0.000\n","[163,   150] loss: 0.000\n","[164,    50] loss: 0.001\n","[164,   100] loss: 0.000\n","[164,   150] loss: 0.000\n","[165,    50] loss: 0.000\n","[165,   100] loss: 0.000\n","[165,   150] loss: 0.000\n","[166,    50] loss: 0.000\n","[166,   100] loss: 0.000\n","[166,   150] loss: 0.001\n","[167,    50] loss: 0.000\n","[167,   100] loss: 0.001\n","[167,   150] loss: 0.000\n","[168,    50] loss: 0.000\n","[168,   100] loss: 0.001\n","[168,   150] loss: 0.001\n","[169,    50] loss: 0.001\n","[169,   100] loss: 0.000\n","[169,   150] loss: 0.000\n","[170,    50] loss: 0.000\n","[170,   100] loss: 0.000\n","[170,   150] loss: 0.001\n","[171,    50] loss: 0.000\n","[171,   100] loss: 0.000\n","[171,   150] loss: 0.001\n","[172,    50] loss: 0.001\n","[172,   100] loss: 0.000\n","[172,   150] loss: 0.001\n","[173,    50] loss: 0.000\n","[173,   100] loss: 0.000\n","[173,   150] loss: 0.001\n","[174,    50] loss: 0.000\n","[174,   100] loss: 0.000\n","[174,   150] loss: 0.000\n","[175,    50] loss: 0.000\n","[175,   100] loss: 0.000\n","[175,   150] loss: 0.001\n","[176,    50] loss: 0.000\n","[176,   100] loss: 0.001\n","[176,   150] loss: 0.000\n","[177,    50] loss: 0.000\n","[177,   100] loss: 0.000\n","[177,   150] loss: 0.000\n","[178,    50] loss: 0.000\n","[178,   100] loss: 0.000\n","[178,   150] loss: 0.000\n","[179,    50] loss: 0.000\n","[179,   100] loss: 0.000\n","[179,   150] loss: 0.000\n","[180,    50] loss: 0.000\n","[180,   100] loss: 0.000\n","[180,   150] loss: 0.000\n","[181,    50] loss: 0.000\n","[181,   100] loss: 0.000\n","[181,   150] loss: 0.000\n","[182,    50] loss: 0.000\n","[182,   100] loss: 0.000\n","[182,   150] loss: 0.000\n","[183,    50] loss: 0.000\n","[183,   100] loss: 0.000\n","[183,   150] loss: 0.000\n","[184,    50] loss: 0.000\n","[184,   100] loss: 0.000\n","[184,   150] loss: 0.000\n","[185,    50] loss: 0.000\n","[185,   100] loss: 0.000\n","[185,   150] loss: 0.000\n","[186,    50] loss: 0.000\n","[186,   100] loss: 0.000\n","[186,   150] loss: 0.000\n","[187,    50] loss: 0.000\n","[187,   100] loss: 0.000\n","[187,   150] loss: 0.000\n","[188,    50] loss: 0.000\n","[188,   100] loss: 0.000\n","[188,   150] loss: 0.000\n","[189,    50] loss: 0.000\n","[189,   100] loss: 0.000\n","[189,   150] loss: 0.000\n","[190,    50] loss: 0.000\n","[190,   100] loss: 0.000\n","[190,   150] loss: 0.000\n","[191,    50] loss: 0.000\n","[191,   100] loss: 0.000\n","[191,   150] loss: 0.000\n","[192,    50] loss: 0.000\n","[192,   100] loss: 0.000\n","[192,   150] loss: 0.000\n","[193,    50] loss: 0.000\n","[193,   100] loss: 0.000\n","[193,   150] loss: 0.000\n","[194,    50] loss: 0.000\n","[194,   100] loss: 0.000\n","[194,   150] loss: 0.000\n","[195,    50] loss: 0.000\n","[195,   100] loss: 0.000\n","[195,   150] loss: 0.000\n","[196,    50] loss: 0.000\n","[196,   100] loss: 0.000\n","[196,   150] loss: 0.000\n","[197,    50] loss: 0.000\n","[197,   100] loss: 0.000\n","[197,   150] loss: 0.000\n","[198,    50] loss: 0.000\n","[198,   100] loss: 0.000\n","[198,   150] loss: 0.000\n","[199,    50] loss: 0.000\n","[199,   100] loss: 0.000\n","[199,   150] loss: 0.000\n","[200,    50] loss: 0.000\n","[200,   100] loss: 0.000\n","[200,   150] loss: 0.000\n","[201,    50] loss: 0.000\n","[201,   100] loss: 0.000\n","[201,   150] loss: 0.000\n","[202,    50] loss: 0.000\n","[202,   100] loss: 0.000\n","[202,   150] loss: 0.000\n","[203,    50] loss: 0.000\n","[203,   100] loss: 0.000\n","[203,   150] loss: 0.000\n","[204,    50] loss: 0.000\n","[204,   100] loss: 0.000\n","[204,   150] loss: 0.000\n","[205,    50] loss: 0.000\n","[205,   100] loss: 0.000\n","[205,   150] loss: 0.000\n","[206,    50] loss: 0.000\n","[206,   100] loss: 0.000\n","[206,   150] loss: 0.000\n","[207,    50] loss: 0.000\n","[207,   100] loss: 0.000\n","[207,   150] loss: 0.000\n","[208,    50] loss: 0.000\n","[208,   100] loss: 0.000\n","[208,   150] loss: 0.000\n","[209,    50] loss: 0.000\n","[209,   100] loss: 0.000\n","[209,   150] loss: 0.000\n","[210,    50] loss: 0.000\n","[210,   100] loss: 0.000\n","[210,   150] loss: 0.000\n","[211,    50] loss: 0.000\n","[211,   100] loss: 0.000\n","[211,   150] loss: 0.000\n","[212,    50] loss: 0.000\n","[212,   100] loss: 0.000\n","[212,   150] loss: 0.000\n","[213,    50] loss: 0.000\n","[213,   100] loss: 0.000\n","[213,   150] loss: 0.000\n","[214,    50] loss: 0.000\n","[214,   100] loss: 0.000\n","[214,   150] loss: 0.000\n","[215,    50] loss: 0.000\n","[215,   100] loss: 0.000\n","[215,   150] loss: 0.000\n","[216,    50] loss: 0.000\n","[216,   100] loss: 0.000\n","[216,   150] loss: 0.000\n","[217,    50] loss: 0.000\n","[217,   100] loss: 0.000\n","[217,   150] loss: 0.000\n","[218,    50] loss: 0.000\n","[218,   100] loss: 0.000\n","[218,   150] loss: 0.000\n","[219,    50] loss: 0.000\n","[219,   100] loss: 0.000\n","[219,   150] loss: 0.000\n","[220,    50] loss: 0.000\n","[220,   100] loss: 0.000\n","[220,   150] loss: 0.000\n","[221,    50] loss: 0.000\n","[221,   100] loss: 0.000\n","[221,   150] loss: 0.000\n","[222,    50] loss: 0.000\n","[222,   100] loss: 0.000\n","[222,   150] loss: 0.000\n","[223,    50] loss: 0.000\n","[223,   100] loss: 0.000\n","[223,   150] loss: 0.000\n"],"name":"stdout"},{"output_type":"stream","text":["[224,    50] loss: 0.000\n","[224,   100] loss: 0.000\n","[224,   150] loss: 0.000\n","[225,    50] loss: 0.000\n","[225,   100] loss: 0.000\n","[225,   150] loss: 0.000\n","[226,    50] loss: 0.000\n","[226,   100] loss: 0.000\n","[226,   150] loss: 0.000\n","[227,    50] loss: 0.000\n","[227,   100] loss: 0.000\n","[227,   150] loss: 0.000\n","[228,    50] loss: 0.000\n","[228,   100] loss: 0.000\n","[228,   150] loss: 0.000\n","[229,    50] loss: 0.000\n","[229,   100] loss: 0.000\n","[229,   150] loss: 0.000\n","[230,    50] loss: 0.000\n","[230,   100] loss: 0.000\n","[230,   150] loss: 0.000\n","[231,    50] loss: 0.000\n","[231,   100] loss: 0.000\n","[231,   150] loss: 0.000\n","[232,    50] loss: 0.000\n","[232,   100] loss: 0.000\n","[232,   150] loss: 0.000\n","[233,    50] loss: 0.000\n","[233,   100] loss: 0.000\n","[233,   150] loss: 0.000\n","[234,    50] loss: 0.000\n","[234,   100] loss: 0.000\n","[234,   150] loss: 0.000\n","[235,    50] loss: 0.000\n","[235,   100] loss: 0.000\n","[235,   150] loss: 0.000\n","[236,    50] loss: 0.000\n","[236,   100] loss: 0.000\n","[236,   150] loss: 0.000\n","[237,    50] loss: 0.000\n","[237,   100] loss: 0.000\n","[237,   150] loss: 0.000\n","[238,    50] loss: 0.000\n","[238,   100] loss: 0.000\n","[238,   150] loss: 0.000\n","[239,    50] loss: 0.000\n","[239,   100] loss: 0.000\n","[239,   150] loss: 0.000\n","[240,    50] loss: 0.000\n","[240,   100] loss: 0.000\n","[240,   150] loss: 0.000\n","[241,    50] loss: 0.000\n","[241,   100] loss: 0.000\n","[241,   150] loss: 0.000\n","[242,    50] loss: 0.000\n","[242,   100] loss: 0.000\n","[242,   150] loss: 0.000\n","[243,    50] loss: 0.000\n","[243,   100] loss: 0.000\n","[243,   150] loss: 0.000\n","[244,    50] loss: 0.000\n","[244,   100] loss: 0.000\n","[244,   150] loss: 0.000\n","[245,    50] loss: 0.000\n","[245,   100] loss: 0.000\n","[245,   150] loss: 0.000\n","[246,    50] loss: 0.000\n","[246,   100] loss: 0.000\n","[246,   150] loss: 0.000\n","[247,    50] loss: 0.000\n","[247,   100] loss: 0.000\n","[247,   150] loss: 0.000\n","[248,    50] loss: 0.000\n","[248,   100] loss: 0.000\n","[248,   150] loss: 0.000\n","[249,    50] loss: 0.000\n","[249,   100] loss: 0.000\n","[249,   150] loss: 0.000\n","[250,    50] loss: 0.000\n","[250,   100] loss: 0.000\n","[250,   150] loss: 0.000\n","[251,    50] loss: 0.000\n","[251,   100] loss: 0.000\n","[251,   150] loss: 0.000\n","[252,    50] loss: 0.000\n","[252,   100] loss: 0.000\n","[252,   150] loss: 0.000\n","[253,    50] loss: 0.000\n","[253,   100] loss: 0.000\n","[253,   150] loss: 0.000\n","[254,    50] loss: 0.000\n","[254,   100] loss: 0.000\n","[254,   150] loss: 0.000\n","[255,    50] loss: 0.000\n","[255,   100] loss: 0.000\n","[255,   150] loss: 0.000\n","[256,    50] loss: 0.000\n","[256,   100] loss: 0.000\n","[256,   150] loss: 0.000\n","[257,    50] loss: 0.000\n","[257,   100] loss: 0.000\n","[257,   150] loss: 0.000\n","[258,    50] loss: 0.000\n","[258,   100] loss: 0.000\n","[258,   150] loss: 0.000\n","[259,    50] loss: 0.000\n","[259,   100] loss: 0.000\n","[259,   150] loss: 0.000\n","[260,    50] loss: 0.000\n","[260,   100] loss: 0.000\n","[260,   150] loss: 0.000\n","[261,    50] loss: 0.000\n","[261,   100] loss: 0.000\n","[261,   150] loss: 0.000\n","[262,    50] loss: 0.000\n","[262,   100] loss: 0.000\n","[262,   150] loss: 0.000\n","[263,    50] loss: 0.000\n","[263,   100] loss: 0.000\n","[263,   150] loss: 0.000\n","[264,    50] loss: 0.000\n","[264,   100] loss: 0.000\n","[264,   150] loss: 0.000\n","[265,    50] loss: 0.000\n","[265,   100] loss: 0.000\n","[265,   150] loss: 0.000\n","[266,    50] loss: 0.000\n","[266,   100] loss: 0.000\n","[266,   150] loss: 0.000\n","[267,    50] loss: 0.000\n","[267,   100] loss: 0.000\n","[267,   150] loss: 0.000\n","[268,    50] loss: 0.000\n","[268,   100] loss: 0.000\n","[268,   150] loss: 0.000\n","[269,    50] loss: 0.000\n","[269,   100] loss: 0.000\n","[269,   150] loss: 0.000\n","[270,    50] loss: 0.000\n","[270,   100] loss: 0.000\n","[270,   150] loss: 0.000\n","[271,    50] loss: 0.000\n","[271,   100] loss: 0.000\n","[271,   150] loss: 0.000\n","[272,    50] loss: 0.000\n","[272,   100] loss: 0.000\n","[272,   150] loss: 0.000\n","[273,    50] loss: 0.000\n","[273,   100] loss: 0.000\n","[273,   150] loss: 0.000\n","[274,    50] loss: 0.000\n","[274,   100] loss: 0.000\n","[274,   150] loss: 0.000\n","[275,    50] loss: 0.000\n","[275,   100] loss: 0.000\n","[275,   150] loss: 0.000\n","[276,    50] loss: 0.000\n","[276,   100] loss: 0.000\n","[276,   150] loss: 0.000\n","[277,    50] loss: 0.000\n","[277,   100] loss: 0.000\n","[277,   150] loss: 0.000\n","[278,    50] loss: 0.000\n","[278,   100] loss: 0.000\n","[278,   150] loss: 0.000\n","[279,    50] loss: 0.000\n","[279,   100] loss: 0.000\n","[279,   150] loss: 0.000\n","[280,    50] loss: 0.000\n","[280,   100] loss: 0.000\n","[280,   150] loss: 0.000\n","[281,    50] loss: 0.000\n","[281,   100] loss: 0.000\n","[281,   150] loss: 0.000\n","[282,    50] loss: 0.000\n","[282,   100] loss: 0.000\n","[282,   150] loss: 0.000\n","[283,    50] loss: 0.000\n","[283,   100] loss: 0.000\n","[283,   150] loss: 0.000\n","[284,    50] loss: 0.000\n","[284,   100] loss: 0.000\n","[284,   150] loss: 0.000\n","[285,    50] loss: 0.000\n","[285,   100] loss: 0.000\n","[285,   150] loss: 0.000\n","[286,    50] loss: 0.000\n","[286,   100] loss: 0.000\n","[286,   150] loss: 0.000\n","[287,    50] loss: 0.000\n","[287,   100] loss: 0.000\n","[287,   150] loss: 0.000\n","[288,    50] loss: 0.000\n","[288,   100] loss: 0.000\n","[288,   150] loss: 0.000\n","[289,    50] loss: 0.000\n","[289,   100] loss: 0.000\n","[289,   150] loss: 0.000\n","[290,    50] loss: 0.000\n","[290,   100] loss: 0.000\n","[290,   150] loss: 0.000\n","[291,    50] loss: 0.000\n","[291,   100] loss: 0.000\n","[291,   150] loss: 0.000\n","[292,    50] loss: 0.000\n","[292,   100] loss: 0.000\n","[292,   150] loss: 0.000\n","[293,    50] loss: 0.000\n","[293,   100] loss: 0.000\n","[293,   150] loss: 0.000\n","[294,    50] loss: 0.000\n","[294,   100] loss: 0.000\n","[294,   150] loss: 0.000\n","[295,    50] loss: 0.000\n","[295,   100] loss: 0.000\n","[295,   150] loss: 0.000\n","[296,    50] loss: 0.000\n","[296,   100] loss: 0.000\n","[296,   150] loss: 0.000\n","[297,    50] loss: 0.000\n","[297,   100] loss: 0.000\n","[297,   150] loss: 0.000\n","[298,    50] loss: 0.000\n","[298,   100] loss: 0.000\n","[298,   150] loss: 0.000\n","[299,    50] loss: 0.000\n","[299,   100] loss: 0.000\n","[299,   150] loss: 0.000\n","[300,    50] loss: 0.000\n","[300,   100] loss: 0.000\n","[300,   150] loss: 0.000\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F_hvwjnDlbn-","outputId":"d1ab4407-0c5c-4362-acfd-01ed6f9436ef","colab":{}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in trainloader_random:\n","        images, labels = data\n","        outputs = net_random_labels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 50000 train images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 50000 train images: 100 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4eAHiCkAlboA","outputId":"3fac6f94-51d4-46cc-a3a6-3cd34c9ac6bd","colab":{}},"source":["total,correct"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 50000)"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2L2Car58lboC","outputId":"290b4c69-eb7f-4be8-bed5-0136413dfa70","colab":{}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net_random_labels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 9 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R7Mt9SSslboE","colab":{}},"source":["dataiter = iter(testloader)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FOjhi9wulboG","outputId":"497d3c36-7a1d-4d73-8ce7-2d382e50f449","colab":{}},"source":["images, labels = dataiter.next()\n","\n","# print images\n","imshow(torchvision.utils.make_grid(images[:4]))\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztfWmQHdd13ndf99vfvNlnMAMMsRAACS7iIpAiZZqhJbtCyY7kH17kctmqRFWsSskVO+WqWI5/OKzKD6eScpaS44SxZMmOSwytJWJJiiKZlCwp1kKAC0QQK4ltgMHs29vf6775cW/3+R7xBgNghhjh6X5VKNzp16/79u3b/e75zjnfUVprODg4ODh0DxJb3QEHBwcHh82Fe7E7ODg4dBnci93BwcGhy+Be7A4ODg5dBvdid3BwcOgyuBe7g4ODQ5fBvdgdHBwcugwberErpZ5USp1QSp1WSn1iszrl4ODg4HDjUDeaoKSU8gCcBPALACYBvATgN7TWb2xe9xwcHBwcrhf+Br77MIDTWuu3AEAp9SyADwNY88Wey+V0X1/fBk7p4ODg8NOHqampOa318LXuv5EX+3YAF+jvSQDveftOSqmnADwFAL29vXjqqac2cEoHBweHnz48/fTT565n/41w7KrDtit4Ha31M1rrg1rrg7lcbgOnc3BwcHC4FmzkxT4JYIL+3gHg0sa64+Dg4OCwUWzkxf4SgH1Kqd1KqRSAjwB4fnO65eDg4OBwo7hhjl1r3VJK/Q6A/wvAA/BprfXR6z3OzqX/GbezKMTterMRt72s+f1JJDqxP0AYhtIv+39LJ2VbMxu3/YQcN+mvAgAURQYltBxLeTI85TADAFgJ0vG2y8tN+bzhxe1SyRzD00G8rScjn6eUnKOYM8fLplvxtqBVkv6Attt+liZ+G53w8Y9/vOP2mwml6B7Z/ioaBybwtJIx0XaNUW/Kvn5S7iFC2e6pjUlNcx8/+clPXvH5bQefjNvLiwtx+4479gMAhgYH421JT45Vr5bjdi5t7muxIHOvWa/F7Qa1C3YOpJL8OMo1ZnNyjIUF0590WuZhksYpRe16rQIAmJ+djbeNDvXHbT5GImXOsbKy2vFzplHLJXOd9Wo13vbfn/lzdMKB9/4aAKAvn4q3eWm5ztVKRfqwvAgAKFRk/jdq9bgd9A7E7bDXBGH0pGT8E1qelURC1qyNunnmA3pPZDJybTydoihBniPc5uO2muZ8dNi2+Z3y5V5ks1n7MR9X3h9hQub3l7/0LDaKjThPobX+GoCvbbgXDg4ODg6bBpd56uDg4NBl2NCKfTOQCMUcSXtiSsEnm8aaPwmPfofIfGqF9Iela5IpMV+37bojbq8szcXtuXljBiZ9MRMTEBOt0ZLhqWpjih47J2atTotJ3vTy8r2CoW1Ky2LGX5xejNuFjBw3mFoCANy2Tfow2CN9yPiyryJTsxPaaJAbwKZX07LdCei4OpQ+tsiGbbaMKXrqrbfibaPbRuJ22BAKbXjA0AmZtJi64Sb23YPMyWRC+pi02xOB0AepJJn0XkDfa9j/5f6FSq4hEQrF0KqZ76VpDtXoenNExXgRHcn2P117uSYUz+HDLwMAmlXpb3/xobidTsvzFDFKiqhIpr8S9MBF1FoYXn0+AkDomePVtdBuHrXzvoxfMWfuZ/jyS/G2xpzQMmP3yHOsZs0zVlcyZgWixVaJFsvYvqeJnk0MCu2baMj9jl4x9Vwm3uY35dq9Jp0jb+5RenlZ9p24K25X+nrjdtgy9yUgOjkTyjOvNvnZcyt2BwcHhy6De7E7ODg4dBm2nIpRKfF0t8gMTCTEzGu0jMmT8sRsCwIxE3XIURfG1Ekl5TfrPT//C3H78D98P25fsrRMmSiXViAm2rnJmbh9ZvIiACDdPxZv2zG6W/qQ7pH+WvMyWZAM4FZNTMr5GQn3z/UbOmeydDneViMze7RHzMdcUkzYm4lOFM+10Tbme15STM5Ay7GqJaEjlpaN6Tw9J/RVtkfM7MEeGd+EStijyz1WikMTOnWFohHW6XUyQdcWSB89G6GkaFsSck+aLaFBAks5eUU2t8XkRyhUS9iyfaeIq9LKUtwuEC2QsOPeakgffIqmWaIok4UV0876FCFC7EmjKWPmp8xxNT2DQSD9bbWkvw177pS//usjoU3kTNCSawNRqorokZoy9zgZyn1XQ0LHVValD80zJ02/lNBUoQwTykl6J9jnKdUkmvUCPUs0DgqmXSvIwbwajZN0AfVtpu/VyzJne5Q886p3KG5HETlNmltJomVCvc78vU64FbuDg4NDl8G92B0cHBy6DFtOxZxbFpOnvyB2YpEiDHxrfoZkDrYlFZB3PoqcqVQkCuXFr3w5bk8viQk7XTL7nrso+567JLpmXkZomcArAgDyRTG1kjn53M+ISZi2VEEmISblXEOSOcZ23Ba3a9Z7/9ZbQsUsLIlJ722Xc+walnYnXE9MjOadO7AqbUkZHaiYgM7GCWIemdkNG20wO78Sb1spy7VV63KPyxVzXxJpSoSpyv0u5KSTLdsUkqONaVkX60UPcSQMJxVFyWI6pG1KHiGf6EPfRmh4lISiicLhQW/ZyLCAonFKqzJm57kPllZhymSiKGPGyUivHTkCAHjX3XfH20JOqApkfDOWEgmJIqpWpJ3y5XytpqF4PH997ScdzROKXGtQdFdAx+1dNdevh0fjbdmRnXJeLdEnSJlx10PbpL9JOYd/eV729QztUqZnVI9Sklkoc7Zmad080YCNVaG36jR+ftbMQI/mtD8o1JFKEq2lDQ3UQ1PPA42pomS8TYBbsTs4ODh0GbZ8xf75bx+P23ftl1/Jn7tbHA/9nl2xk8M04YnzI5GQX7vAOqgU/WSdOSex0QtVcaDonHHcegVyzA3ISilL2vENGx/cYDmAfulvsSDtmctm9b1C6eg9KRnqTFZWDucXjQM3WZRVysyUKHQWLkuK97aifK8TohRnANB2heT5FD9MbUUmT7R6T4Sdf+cTbAvY1W6JVpHsSM2SQ61m+zNFK/aZRWmHdNymXYZXVsXJPEOO1MmLU3H7rn17AAC379oh10ayBW2OXW2viRfp66zuE2QZVpelv6hX7CEp7jkr15uinIyUHWvVlHjqoC4rPwR0L2zOhqY493JZVqfT0/K9fLFg+yD3StOYN0qyb8bG2M8uiSP25dePyLHS0oe9e8yY+mRJ1Csy97K+bA/rkUN0fYdfGAU20NTiwIekknb69CkAQO3wd+NtrYfIyknQs2vzSlKrMuY1yLUXpuSaPSuNEOblXEqTQ78px+gZNM988iKt+EsyJ5Oj8q7ABbOPXxRLujYr4+uRRR/uN/HttRTlzNC7JNXaWA7K2+FW7A4ODg5dBvdid3BwcOgybDkV00yJM3KhIqZhpSFO1WLKmKghp9STM8bzxIlTaxi6YpYsuLlVMcFyfeI06R82TsxyKOb2ECh9m5wtjaTpQ60s5mmtJN/bSc6YiqVdZshhqij1fHmBTHJrqlbJ3PNScj3TK+LYnVo29McQq+ATQkrPDqxDuY1dYccNKzZYLkYl1vidJ2ojcjxenroYbxsYkFyEbEZMzUhdMJeWbduGhWLT1KFyxVxbnkzVRk3GzyOHZqlubm6rTYFPpnJ7jL29NvX2LWuDqZg0UTwFG5veS7HriWWhWtKUT5GxXUhU5BoSNZIiIFoBgTluY0XO25OXz/tpfM9MGprvrQvibD95+oW4vTgnFESpZo5XaYroqg+KRye6516rXPmhXxRly+00p+sZubZauWy/L31YC2FgaVSK3/ZpPVlYlPFrTZr8jiI9K6uX5ByNjKToa5j3g7osuSb5cXJ4FolqhJlbWcqbSC3Rc0xO69acofxSNRmn1oqMU3qhGLebVUuhZffE25bOSPBFKitUTM+YcQJ7FGuvSdGx3imCYQNwK3YHBweHLoN7sTs4ODh0Gbaciin0ChXz8KNSCzvnSWRIw9IfCRKuV0mhSQItxQN6RgxP8eqRU3KOPjH/t++UmF5tzeFkktK76+INbzRI4sCe2yOT/+hrr8XtIikN5vLGJMyTV/zS5em4zWqUnjU7BygWeWlRTMPFBWmfmTIm4dA96IimT3ZeFG1AUQcBq/UxvWLbeg1zkGPeoyxoTmlvK6RBOQV9Nha4Sep48GicKBopomKUx2qJcuJ0lu697USLQp/aMrI79JfjxteLGF6clTkQNOU6L1409NMi3esy0XEjg0KZFPLmXni+jE2DopZ8Uh9NWHXRMlE1NS4qo2XOnb9koqjOTErEULkh9FWml+Ko82ZQOPshn5Ixmzp3Mm5fumTm53e/+//ibQf2CcUw3CcURLVk6J7yCkWOrIXovpCqZ4LaJZL+KB28DwBQ9N8db6usCmXS9GjORsU6GhRhk5X5X6YY/SgPoxnIuZIJodOqNCbR1ipF7lRK0oc8naNmv5cuyAgP9Mi7KKD3VSmavxRrn21S0Y4NKrO+HW7F7uDg4NBlcC92BwcHhy7DllMxB+6+L27ftntv3B4i833pzFkAQJNTkVtCXTz8+C/LMfYcBADsvvdsvO3wK0KZ9BckBfnSjDFrfUpWSHOdTWIQSjYSYGlBzM+BQrLTrggs1TI0LDRTnczwuUXxsiubgt9DCU4+1VptkHn+5oVJAICUSmjH//jMX8ftQo8xGffuFvmCh94lRQBI8C9OZuJoEp24MikJAFqWauFIjVRazFOOdEmlDK0y2M+1TaXtUwRMrBSYJFO3JWO2RNFBS7awweqyRIA0KfqE9SYGbcLJvr1CKyRTV5/2rx8XGq9KBRvOXjZRGzw0PI79vUJX5G10UJr2TVKCmM/1Ri2FVqFIDJ+OpYmeurxgoqeaFO6U65FEOlCN3ChZiRPMajW5nmKPnOORd98LAChTcZgaFe04f17G/8033wQAVFsyzgPDQgExdMTFECXIBVYUUVLZURP1slKWOT+7LNFiipISGxVDUaaIGm0syfdYKTadMs/pClGgGa4vy8VQLF1Zr1BYXSjnXa7S+NpdciSL0LNDQtY8pgdtVBArknJT3eyoGKXUp5VSM0qp12nbgFLqm0qpU/b//qsdw8HBwcHh5uFaVuyfAfBJAH9F2z4B4AWt9Z8opT5h//6DG+nA/e+W9We+V1bh3qrESQd2ZeDTSuutC+LQeKxfdNGRM2nmPXlKrfbFuZGlGPGMXVFyCbDt46K3/oZdmQBAKmVWVSvkzNk9sT9u779TVsMLC7baelFWUpco3laR46av36x8l2lFykJa2Zwco0piRJ2wtCgr2FVrFOQo3Tw4cGfcrmku02ZLh9HqiUPB20rb2dV774BYI20iYVwd3q7MPFqZs9YDL2hCu2I5S/IPF2dkzBbmxVKqVm1Ke51WTyQYVqfU/R0TRqrhtgmRH8ivs2I/OSnyBfWWHKvXauenU2JVNGgFPFsi8TY7Jj0ZscRapG+uyGno2eBm5cu+6bJYg42mOGgXFqIVNecWSN8bJDS2Wjbj1KjKtolhsbQG+8V6jSQMFhZFRGywT67z4H0SdDBpcxiWq+vXB0ilzD4+mTYBx7RTWn3CzsmQYu0Vlcv06bmJWs2G3J8sWds+rcIjS4kdpgFZg40alSm0szKZJZG7gKxQum+ReFiyRZYERRoomuEZG8+PgHJx6L6F1yXhtz7WXbFrrb8DYOFtmz8M4LO2/VkAvwwHBwcHh58I3KjzdFRrPQUA9v/OBBsApdRTSqlDSqlDlcrVV5wODg4ODhvHO+481Vo/A+AZABgfH7/CQ1CvU0V4oklyeXZEGYogTWZZwRfz6TPPfCpu/5Nf/x1zLEp3TlE1di65t3vPdgDAzIKUqquVxLTeNiLx71GZsTpVj9+zV5y9t+8VWmb5FVMdvkxKhewQagViolWrxnzvo4rmgRa6p7dfzMtW4+pV4X/z1349bkfOmCzRDlw9bmWFVBZb5h4kKQ7ep3hdTU6/atNcvw7luAmiX5IUu+tHJnCSzNPElbQOADQt3VMjhcQ8qeb1k9JmYHXeM55QR0vz4pCevHg2bu+1DnmPTPNgvbJ+lAqepRzwHRO3m75SVfvZyzLP5oguGh01a530kFBA5SX5PCSJhN5+Qxel0+KqqlEVvUpL7lXGPhdBkyQoyDHJ5SOTlgZpZuT+PfygUCr7d47L+Rpm3p95U673zRNvxO1HH7o3bk9MmO+dPyK5JkBnbfZc1vQnS07xlpJ5vEoyCoF1jmZ6hS4azZOaIjlEo/mtiMLwaJ3qEeW3Xgk/Tc9jRMUEFDPP2vcJaqciQojOVaf3CyvM+paWDEAKkyyJEW7uq/hGV+zTSqkxALD/z6yzv4ODg4PDTcKNvtifB/BR2/4ogC9fZV8HBwcHh5uIddf/SqnPAXgCwJBSahLAHwP4EwDPKaU+BuA8gF+90Q7UKP44yapu85SmbtUbk5Coj7E+MS9PHZO440uTp02jIvTKucmzcfuBbQ/H7e07TVTA+IwUuSifFvNyIC3mf4+VJXjzzTPSh/HtcXuJqI2mNe2mKTU9ZG85xalXLBWjSOmN/eN5im9HOIirgWMUCinzvWxGxrRakz5WmnK+s2+dBQCkKCrmtt1SkuzMBRnLr3zdKAk2qbhJhtQbc3S+KP26tyi0Wl+vmNYPPPCuuD08ZGiI23fImCYURUGQXRtFMXDkQ3VEzPfxMblv49tNlBMXd6hUiOfogMEBcRnNzU3G7XKk7Ekp8TXKT+gdliiT7ZYC6ukVeqU4JMedX5AoqMCa4XRL2uLnKxWhXRrN6Hmhoh5cxCUt8yVpo0xGaPyH+6WdoQiPYUsHFVNyX+fPn4/b5948G7e3DZhnYXn6B6CN6ISMlZBYmpH4i4WSRB3NTsn49veY+X3PXUL7JElhlRUQmza6JMHyHGDKlSQMLFXI1AfnbARtkTlXlvLjJ5KL+kThSEzV+PQ9nr/R95JMla1TnnIjWPfFrrX+jTU+ev/mdsXBwcHBYTPgJAUcHBwcugxbLikwNiT0ApvxLx6R5KB+W1tx3wCb/xQJ4EtiyOzMWQBAWBdT97bbJYHJo3PkisZMHhqVyIX5BTF7l1ckkiWy5EdGxJz2iTqqUcRKpOJX5cQHogK4Xasbc7nVkt/YQTLZFVUvTym5zk743HNfiNsFG2HUQ2b4rn1yncODEvkxOGZkBwbovJm8RDEsHRN66sfHTCGBKpmyFDTTVjOzaI+x9zahdR59+EE5L0U85C09xUqSDRrTFiXeVKyUQJMSfrI56W9fn9AR01ZVc47qp2bzV68dW69TggytfRbmzXlXVigiheaAR6nn5y6a8xZXhGrs7RWKyKNom7qVElAULZLmlPe8RJxkbbX7hM/qj0IF5LOyb9LW/90xKOORS0kfyytCbbYs3UNqDNhNEh/Hjkvi2P79d5hGcPUoLUBokFVK7JudlUiipUVJRDx55EcAgOOvfT/etnevJP7t2nsgbvcPWfqUKJeAlEXjWrcQIsVLMFkp3/PbagGb7SHJHnCtZf5eVEOYWZQ2WY4O0VdtETi87xV7bgxuxe7g4ODQZdjyFXtfj6yeFP3irmhZZcwtml/JoR7pbp6cPAFVjT976SwAYLRf4sJ30q8+xwf/6PAxAMDFKVnd9xTE2ZWk2NujpyNHEqfEU/wqrS5LNpW7j4SyWrQUnZqmcl49pp8+xc3mcrLqioS0AADNq+tfHz5yjL5n+vaeR0Sy4dxFKds1L/4r3HO3iW1OUex6hVatSbJyHnzQODxrlKaeotXlvj1iHd19wKzsxodkpVrMyf0OSfTqwmWTyj6zSKUA5yS9vUz5BUtLZqXZIK10FvZiUbJIjqJJTs5cH8VGd0CTxK08iu0PrJ63TxIVIa0MU2k57tCQcdoWCnK9GRrfXuqjnzTOZ47r14H0odWSSdtrY/sTlA8Qkva4r7m2QMmei47bkjELyApq2LT4Kt2TXI88Q+cuy9x7481vAADqdRJeWwOZjLnOO+8QOYu9B8RBXlmV1fvRl03+xyuHxCn73e+ItXjsjViuCvsP3A8A2HeHrOL7+mWesUPZi8XD2Fu5hoC/XTs3SWYkbHV2tkdSAwE92yFLPXT8Fp21TapjfXmG64FbsTs4ODh0GdyL3cHBwaHLsOVUDFcsD8nZOLZDTPpDll5ZUqIoqD0xzXuHxGzqLdp40YyYxbuIiin0irP2Lz9t9MsrdN6VqjjZKhRLHLEN2yjFv7YgZmI5zX0wNNLxExJfPz0ttMIKSQ309ZkDF/Ni3nuaZBYa0gevEjmaRMOeMToopuhd79pnvk9m+NFXfyT7ZoQKKNiU9Jk54WfyRTHDB4uy74eefBwAkKC48t5e2XdoUMZ3wWrXnzkn47C8JLH0K8viUFu1juqlslzvAlWHbzVpTKyKX4pK1CVIEbO3KNfcZ6UI+kdkPqSJ6ipfkryECNvGRFM7DCjPImHGYWREUvEVSSikKOY6ooMyGaIESOGQaZe4BCBt47j9SlnmS5TSzs5VTbRMZVkok4tnzbgvUMB0X1a+x/MlkzFjwkEA2hcKzs+JE3520uQ1TIzJ87gWIucpx5V7VB6xb1DG+rEnjPN+71559r/399+O22fOiKO1/Ip5ZlfIAXzvu+S5mJiQ40b1DYIWl4kk5yhRwHF5SC4dqbgt16ai+Hh+h5EXlKU2IkcqnxdtztPNXWO7FbuDg4NDl8G92B0cHBy6DFtOxbQC6UKaTL/9VNLt0GFjRq8kJa42VGLGj24X0+6NYyYG9r3/6J/G277/D+JlL5cp9b9hSuPNXJZoEf6tK1EVcd+mcPcnhKrZnpVjLc8K3dDyTGTN6AhVLKeY30jREQBqVUNBlCkeuhWK6d2sScr1SPLqUQgP3HV73H7ySZMY/HcvfkO+T9EgIzmJOsramOgMpVaPUmm2HmpnbLx4i7z/HIXCypWXTxjT+fzMdLytQSUPfSpC0dNjIohGMkKTsIoiI2kjorggCbd7euQ6i8Ue+7nY0CVS2pSkeUGW4uv7ihLbH8YFX0RCIVuQfTmyIWHN/1DTtjXKokWBNZoiNVotudetQPq7Mm/LOVJ/k0TFlJaF8pu6ZCiT0QGSdMiLYmmlQXSEpYladGSOzNlOJd/u2GfKDN5/l5Qb/Nb3hOZjJG3ZuCRFfQU0TlyMImGjg/btF6mJkPI7pqYkT2NxzlzbqbrQddMXT8Tt2/dJFM6Bu83xRkaliI5P75pWU+5n0xbgCLTQNnxfVaJDrEub6mTnWJi4ZCTF0vOhdLi5kexuxe7g4ODQZXAvdgcHB4cuw9ZTMZ6YQbWEtDMFMh9tEYrzFySZ4bGHpGBArSSmUK7HJP9MXRQK4/TJk3I+SuaIrKIyRV/0DIq5trxM9S4Lhm64Y78oz7302vG4/fIxia547Oc+CKC9cMhbp4WqWSKpgijJqVYV+mXnqJj3WUonH7AmtcQBtON9739f3B7sM9EpP/Oex+NtnNTSQ9RP0SpIelTL0+f6p5wMY+tRLi9K9EWRzNqQNCb33HEPAGBkhxQhWVgU+qqHimc0rdmvKOGHa1RyinetZqisEkWLaEooKZEa4oUpE+kTUV4A0KxcXZrBIwW+GVLoXLFSBmEofdwbpdcD6BsQmsNLmr4rGg+mqRoNkkiwkU81qtXaasg4KZJO0HXzPU7Q6+uTRLhsSiJVfBvN0VeQOdTbI+1Gnfpgr6lBhW8SJHHQT3RczhaumbzAhTY6w7dzJ8X1PTm1P7wyMqRBFNyOiV1xe9cuab80be5ri5LJZmfkyZidE0XSY8eOAGiXSLj99n1xe3RUEqZ6oqQskvKoNSiapiHnS1pKjqUDOEGJFQU0V7mRrXFL6fXSma4PbsXu4ODg0GXY8hW7l5Ffxgo5a9gZFlWYP3mU4qEr8gtYyIuj1VYvw7mTspq4eEl+vR99VPTYI53rHtJVHxiXGNrzC7Iir9bN+VJ5WR0Vh8Wh9ECPCGzN2lXe2XOvxtvKFbEUlpZlRTkybFZYvVr6uLMgseAjRVndJJVZ2a21Yq8EMpYnThuHZUgrjwyVmmvSCmFhya5IQhY9E+edolkSwqzyVlfEee1Nywrr0ozIJURlD8OarPzy5LR965RYVWes9jfHhQ+QQByvLpeXjYU1PzcXb9Mk1JSgsnPKtvNZsUD6yGkrNqLgxz8+Erc57b6v3zjDx8ZEv79B6ebNhlgCoXW+rVQkLr9KVkNAqf1etKolfXRekWdItCxr49drZJWE5IDMFygfwgZdpzzStafnKknnqFmnofI6OzabTZm/k/NG9qFSFkuXtfzbEAUNKHKEt8Vvd0jtp88zlG/R0yNWQ+zEXENjXWkqv7do5uQrcyRf8NpLcXtgUIIctm0zz/S2sV3UB8rpIIt+eNTo7ytyzIfkdG2RFdmyDta2OHaOiQ9dHLuDg4ODw1XgXuwODg4OXYYtp2J80hjnSt2cxjs0YEzykwnRhJ5ZEBN33qOK7wVjHt15j5hPb52VaGUuPxY5MfftE0fKvt0SC35uSkzNo0d/bM41R8qLaTF7+ymeefKooXCm5sgBRo5hj+QOxiZMLPBOMstuI8XLDFU9r9fsdZLgI+O114XaiBxQDTL9AnLkaTL9PGsTKnLmBOTo07RdsqSpTFlL9p2bl5j1KBabmBH0FcVhyg7EhXl7P4kKmJuTuVFvUly3zQMIGkIPeKTml8vIWKct9eC15LgNkvhMdVjasAPsTirTFunV50ihskayE4uLkuPQtMqTFVJbzJFmfG+RSgimTTtL1IhPFENAztNWq2GPT5r+NEdUWxk3z36f7hU59HwKXNChGdNaXcZ8flaorrl5aUfa6otLQgoevFfixhkJ6zRURFGwqmF7jr5pJylPoFoSyu/yZZG8uHTJtJdzsm+S5k6RSkrmLZ2T82VfLpV4kcrznTpr3jHV6gvxtlYgxx0aFjmJe+81UiX79golOzwseQ/FXnGmp7OGRtKQOQB6Nlss+b4JWHfFrpSaUEp9Syl1TCl1VCn1u3b7gFLqm0qpU/b//vWO5eDg4ODwzuNaqJgWgN/XWh8A8AiAjyul7gLwCQAvaK33AXjB/u3g4ODgsMW4lmLWUwCmbHtVKXUMwHYAHwbwhN3tswC+DeAPrrcDmQQVBmiIue2+hQZhAAAWH0lEQVSTNzzyjPf0CPVRoJJvd94pscR/942vAQAqy+IBzw1KFMPpSYnamNhhoml23yHl2tJk0u+5TaJtlmxV+TeOSWROSJ73yUW5jpWqsatqgZjbK0sSETGyTUy3c/Nm+8CEUBTzaeJaQoqmaV29FNmL3/h63I4U9Lh8HxeNAJK0rzE1feIlOBohUlMEgJTtW4KiIDwtnxdTYrglLFXV9Ig2IGkFCkFGyiouNisUW03yDw2KIlGR0iOp5zWIbghIMqC8ar6Xo/s63CvziC3jCHupeAPPw9WSiUQplaRfaVKY5MiRqDjD+KjElaeJIvIoN0BbdcFyTeZ/jaKOlojimV8wkgFVooAOHJD5n6TcACkJJ3RHjeZQvSznmLSyGrNU3KRBVFeFVDeXlwxFmfLWZ3LDlpkvLUq75wAQ1UYHmX08ipR57eXDcbu0KH0btPH4F6ZkW5Fi7VM+FXSxlGCxQAqTSY/2pXKCaZvTkSCqd1Eop7NnjsbtpUUzZi8foueDckEmJkRyYdyWnxwbl2d/fFTeL/nC5hIe1+U8VUrtAvAAgB8CGLUv/ejlP7LGd55SSh1SSh2qVCqddnFwcHBw2ERc84tdKVUA8AUAv6e1Xllv/wha62e01ge11ge55JuDg4ODwzuDa4qKUUolYV7qf6O1/qLdPK2UGtNaTymlxgDMrH2EtRGSF18x1UCpxivWC7+0JJ75wYH74/YHn/y5uH3/fcY7/9wXv0T9F7Ort1dMnu3jJqmoQJEaXktMsIFtMjxju41pvUx1K19+VRKQpkqUKJE0ETm9Y5JgM7RXonTa6mjaRKETVOP19GWhLlKU/FC1qfTvlRypNnzzq8/G7WwuiryhQg+alPvoNz2RjKgYOVcmTZE5VPM0ZdUX/bxcWyYl15ZOUGSHPYXK0D2maKcm1VWt2UiXNjqD07Dpe34UtcKp6USJ9OWl3Zs311zIUqRMslN6t8CnZKaAKATP9sGnJB9W6MsQ1VItm+uoUjGRqjTbaK+ETUzSRFOdOPZG3D539mzcjiQxNEWZjI9ti9sDVPSkai3kKlnKS0QrzJMsRNXSoKxCyhb20oqs5RJ2/HP++q+PVsvsw/IEPPoasj2a6iWKhOHaunfsF4rswfsPAgAOH5E6qD94SRQml6hGbmAjiUbGJKLlsccei9s+ze+z50xi4w9+8P142z13iXxJkcZ3+rKhe6enJRKM5+82UpPcvXuX6QtFm5VXJeqOI882A9cSFaMAfArAMa31n9JHzwP4qG1/FMCXN7VnDg4ODg43hGtZsf8MgN8C8GOlVLRE/dcA/gTAc0qpj8HIWv/qjXQgSMpqOdGgX7CQdIvtymx8TGj8n32vODwzSVm97N5p5AF+8Vc+Em/7/Je+GrfnLss5ppbNr2etdjrelqIVxEJV2qfPWWcsCRTpYYnd7R8VmimKg1aUzh+SznioSP/ZOv2WSQ4gkyQxNF+WhGUVraA665TrQFZjxQGzrPepDytzi3F7dUVWNE27CgzJQckxtm2wK/JkVu6FTorTqkX6Awm7ZM+RGFo+K+2g2cFCS8taQ7EFQc7PrF1hDfSIlTNBeQQ7xiR+OAodr9dkFZjQVxcBS9KY8zAkrHUZUqr4NEkosJhcvWpXwGSF8mp4z95dcXt4xPSX082TJK3QR07ByAFLIdttsefHT4gmeSSSxp83qT8hxZOXrVVcqYoDt0JyCA2yrqKyfOep3OPBe8WBy4jS/FnHnAwehLSSj4z3LFG2P/vE++ljqo9gHbf77xeJkHve/VDcJt90fN+4bOOePZKv4pOltWuf0W4fv02uJ0sWHJeBjK4tKgEJtK/IR4bFkorExTyychLkRQ5CevY2AdcSFfM9YA31eOD9a2x3cHBwcNgiOEkBBwcHhy7DlksKnF8WU2xbSkzrHFVhH9tmTJqxITFJb98jaoqgtO0pq6z46WeFfjn8qjii6jXZN7ZKSQNck157kJbzBZaC8CFmWYucsq0EORujrpOCYq1B5yCz1LeOVI/McE1qiC1yNSXXUYBLpsgxGRgz/M4D98hxx8UUnaF08RmbLl5aEoqBHWdMIejAmPV5X0zSO+8TnetL5CycXTHUT7UhSoTVmhzXI0MwbePt80l2gsqYDvcLZTc2bubD3u2SnzCSlntRovj3BRv37ZGzMpcXBzo7cCNUViRuvE1OIa52L1TYqVOi9b+6LFRYys5fLhvoE38SUg55IpJkoFj8wQHxkLODtmJ1+6uk33/hwmTHfVVUco/i/SukQLlEkgDlOUMjJem5azVJyoBS8Ms2jr1FsfRrIZpHDXpGWyDVQ5KjiNL8WXuf1QdaNA+VvaYG0WLjt4kyK0Jy2Nt2gp7zM+flHlepRGB03J5eORb3Z5HeV76lVfLFXXJeVk1dFlrr0vSCPZZcUJpkRlKdZEY3ALdid3BwcOgyuBe7g4ODQ5dhy6mY516U2NMPvPuuuH37uJj6Z94yafyPPyS0QoZM9tWGmLjPfd0I6L/8hhSuqLQoRZ9iyKP4YTaPON6WKZPAmnx1okOaZJ4qKiRQt+n6LPzv+/I9LnaQs+p0KTJPybGOgKJMxOPe2YPOhRwqF4yi5YAn4zRMBSaSVIYta+UXq1RJXmuWL2DpObNPpSpUzuNUpvDuA6KGeP68iQmeX5JonDpTHzTuvo18ylI4wxDFF/flpe+B7c/lOVHtPDEnyn+KohyKI4Z+yhYlaiZH0TTLHaiYkJQkFVeVt/ctQXRFkYqXZChNvWBLGnp0DTmSJ2Ca49Rxowa6vCD0wDKl+wcUs55M2ZwDmkNpsuMVjV/FShTMUNRGhSJkPLq2/l5DdTVq8nmFAu9bpCYZxvN+/XJuX/zC35proPnWJGqjydSnVbHk56ZJtFdAtEsUXVKr03NDVJbSVKDGlm4c6JNoqUKByzLKWEZTUinOvWDFTIraslxXgigVnxQkE+rKfduELTlNQ1HuijyyNwy3YndwcHDoMrgXu4ODg0OXYcupmKlFMdH+4TWpMRo0d9JexrwZ3iaRMIoqyf/okKQVf/VFkwpcD0mXxpd92ZSKz0XmuCZ6gBNRIvMwIK93kpINuFYkrGKd31ZrUvZllUrP9sfTZHKS9z4kFcY2jqYDAqowD0spnTkpCSvLlCjEo1AOzffKZPaGAVMxTFWZ62/UxUx/+XvfiNtP5OXa7rHXVu0VGoSjQVhComajNZapxugMFXc4d1zStueqJuqllpR7kR2RKJL+bWJmp4uWEiFJgRwl/CxT0lbcL9U5eqVur5mjYrKccEL0YNWqIdYXhBI8z3VK6dqjwhOsoukTZZjMEB1kT9docE1PUoWslahtni0mTDI0/5tVmfdNW4SlSglK3ObIkCjZqMWSDmvAs1RimiLMQqYX6bgJe1yORApDGieiNiJJhZCeGy4yojVTKaaf9DgjAbl23yPFS1tbV/F7ggawRZKkTZtgx9RqgsZkLQonQoOkEzQl643tKlyx7/XCrdgdHBwcugxbvmIPKL3+zLTEH9fLx+L24w/uBwBk+0RUZ7kmv/R//8NDcbtqnX7sdElTLDGvPDrJCHu0muCqXdEiIk0rb5Wg4aO2SptVIqci+7Sya9Kv86pd2QVkKdQptre3Xxw+26JU+UAchW1okwEwna+Rg3eBjpui62zYMWMnHdYQJWora2Zx6og4wC+sykpoOGHGgZ1hAa1cSlQz77I2q8PT5GSbJImDSo4sntuMmNPobrHqMn2yIuR7EeWvFwqyCsqRI7UTjr8u4m61mvQhsP1hoSe+l2ztJayiVZLkLtod6LKy863TlWPQm1QOLxIUA4B63cyXVYqRZj93vihzPbIGdVPGuV6S8Y3K7AHAsl2p8iqdnZW8Gg711S1HRqNmnmlaQCOg9SRLHDSaFdsvknygsn+aVufRPQhbFHfPmvxsGdqVPkso8AJaa7nH9VokhkbOYvoe32MdBxWQZU/PTZsDtsOxvAZfD6/YP4SNwq3YHRwcHLoM7sXu4ODg0GXYciom9MR0bEDM0+mSmEcvnzAOqA9WxIxZ1eJ4uLgo7Yw1uVsVOVatLsfiCvN+0r/i87a4ZcWxsGZfTWY+a5onie4p2ZjfBmm7My3D1EREu5RJ6qBA8bb9pBDXiEzn9cOHxfSjbXWiWrhafRQXHlyDJnS8B9MGZL6XqbRaIm2cmB7FTl8is/VVisc/7dtxKIgDMT8hqf/D49vj9uCwkRJI58UZ3KC+a6IK0r65h57PjuyrO/2Ov/ZS3GZVQt9qviuvc4xzisoQRoqW/DnTgC2iIEolY5I36qy8SI43xTHkZg6k0hKLP7pddMZLJVGYXFk0juEWlbjT7LSlm1hpRDQIUx8cdM1NSzMl1p+Ibxz/HgDAJ74oaJvAcr8jyYAwFIoiRWqfvD2icAIWOqWxZodmVAMgwf3l+0r0anSPON8iDK50HJtD+Pb4pOIadp6H0VDylTdJSTYY2NwiRG7F7uDg4NBlcC92BwcHhy7DllMxHqW8h5QGHFCJtTMzhmr59HNfi7e974mD8vklMf/LNj04ZJqEq8NT+nXOmmspKndXXaUCFBzxYCmTZEaGjM173jcy9dksq3IMM22P9u3rlzjsQSqpNTsvaeZLc6bYx2P70BFJUjAMbCQEkystxX8RSaPf9v9VEH+LzN4SXc/xhkRd9KYM/XS8JjHoR4memi+K+Tk4YdT0xnYL5dI3JmOSpvj4hFXra3LZOkrl9ogS8e39ZhOaIx46QbXkGtq+Z2m4hO4cOVWnGPxW01wnUyprnTeKmEqmpN8eFdrwOarIzsNMWvqQzsr3FualD1HxjCTRix7FgjeIgmzpaL50jupoS6W3/cn468exq+BKeQ2OR4dHcew6igvn/hL1yXHo9h5ookv5Zuj2oHUA7VQY55i0qD9N24eQ3ks6wfQKaLu6omMKna9T24ioVlK2FceFZt1x7345sDCbNwy3YndwcHDoMrgXu4ODg0OXYV0qRimVAfAdAGm7/+e11n+slNoN4FkAAwBeBvBbWusrpfLWgaYkiZRHRSwomSZhTeu//9GReNuZS5KqvVQW1/hCydgxdFjkyYxvkTmWTpvj+kTPZLKkIJfgJBKzDydXtIiCUG3ecBtlQgp+DUpqyZLKX1SHcWBI6JcGSQrUqdZnNX11Nf6ePjlurWzMbE7ZDsg0DJh2sX+oqzMUACRVW1MkQZmSSL5LdWvPVcz2+RzVqhydiNtjO4bj9u5h0x7slWIgCbpvZTJxa5ZS8okKyJCKYiYnESN+yoxJhmqtpmn8O4GVLTUVbNA2lIgpFY5y4DT0wJr6HtWvjeYb0D63EnZfviVMJQRNiSoKbARSI0n0IRW8iOgXQGQLVIoixCgpj+mRaMpxH5iK4e1+lPjUWL9OZ8PW8uRkKIRcF5c22+cmQf3iQhoh3ZcoUiUktVWOSmK2J/oe02ptn1OiUCTbwYl4TNsw3aMiGomjeJjWoXdCM2/mwcAdUmt1+y55FmrTQlciQ8l2N4hrWbHXAbxPa30fgPsBPKmUegTAvwPwH7XW+wAsAvjYhnvj4ODg4LBhKN0hRXzNnZXKAfgegH8O4KsAtmmtW0qpRwH8G631P77a98fHx/VTTz21kf46ODg4/NTh6aefPqy1Prj+ngbXxLErpTyl1KsAZgB8E8CbAJa02KyTALav9X0HBwcHh5uHa3qxa60DrfX9AHYAeBjAgU67dfquUuoppdQhpdShTqJbDg4ODg6bi+uKitFaLwH4NoBHAPQpFQeZ7gBwaY3vPKO1Pqi1PpjLbW7arIODg4PDlVj3xa6UGlZK9dl2FsDPAzgG4FsAfsXu9lEAX36nOung4ODgcO24lszTMQCfVaYMSQLAc1rrryil3gDwrFLq3wJ4BcCn3sF+Ojg4ODhcI64rKmbDJ1NqFkAZwNx6+96iGIK7tlsR7tpuTfw0XdtOrfXwWju/HTf1xQ4ASqlD1xO2cyvBXdutCXdttybcta0NJyng4ODg0GVwL3YHBweHLsNWvNif2YJz3iy4a7s14a7t1oS7tjVw0zl2BwcHB4d3Fo6KcXBwcOgyuBe7g4ODQ5fhpr7YlVJPKqVOKKVOK6U+cTPPvdlQSk0opb6llDqmlDqqlPpdu31AKfVNpdQp+3//Vvf1RmCF315RSn3F/r1bKfVDe13/Syl1dXH4n1AopfqUUp9XSh239+7RLrpn/9LOxdeVUp9TSmVu1fumlPq0UmpGKfU6bet4n5TBf7HvlSNKqQe3rufrY41r+/d2Th5RSn0pyva3n/2hvbYTSqmrKuhGuGkvdpu5+mcAPgDgLgC/oZS662ad/x1AC8Dva60PwGjnfNxezycAvGB16l+wf9+K+F0Y6YgI3aK//58BfF1rfSeA+2Cu8Za/Z0qp7QD+BYCDWut7AHgAPoJb9759BsCTb9u21n36AIB99t9TAP78JvXxRvEZXHlt3wRwj9b6XQBOAvhDALDvlI8AuNt+57/ad+lVcTNX7A8DOK21fstWWnoWwIdv4vk3FVrrKa31y7a9CvOC2A5zTZ+1u30WwC9vTQ9vHEqpHQB+EcBf2L8VgPcB+Lzd5Va9riKAx2HlL7TWDStsd8vfMwsfQNaK8+UATOEWvW9a6+8AWHjb5rXu04cB/JU2+AGMQOEYfkLR6dq01t8gGfQfwAgrAubantVa17XWZwCchnmXXhU388W+HcAF+rtrNNyVUrsAPADghwBGtdZTgHn5AxjZup7dMP4TgH8FIKqrN4ju0N/fA2AWwF9amukvlFJ5dME901pfBPAfAJyHeaEvAziM7rhvEda6T932bvlnAP6Pbd/Qtd3MF7vqsO2Wj7VUShUAfAHA72mtV7a6PxuFUuqXAMxorQ/z5g673or3zgfwIIA/11o/AKNbdMvRLp1g+eYPA9gNYBxAHoaieDtuxfu2HrplfkIp9UcwNO/fRJs67Lbutd3MF/skgAn6e00N91sFSqkkzEv9b7TWX7SbpyMz0P4/s1X9u0H8DIAPKaXOwtBl74NZwV+T/v5POCYBTGqtf2j//jzMi/5Wv2eAkdM+o7We1Vo3AXwRwHvRHfctwlr3qSveLUqpjwL4JQC/qSXB6Iau7Wa+2F8CsM966VMwDoHnb+L5NxWWd/4UgGNa6z+lj56H0acHbkGdeq31H2qtd2itd8Hcoxe11r+JLtDf11pfBnBBKXWH3fR+AG/gFr9nFucBPKKUytm5GV3bLX/fCGvdp+cB/LaNjnkEwHJE2dwqUEo9CeAPAHxIa82l5p4H8BGlVFoptRvGQfyjdQ+otb5p/wB8EMbj+yaAP7qZ534HruUxGJPoCIBX7b8PwvDRLwA4Zf8f2Oq+buAanwDwFdveYyfUaQB/CyC91f27wWu6H8Ahe9/+N4D+brlnAJ4GcBzA6wD+GkD6Vr1vAD4H4ytowqxaP7bWfYKhK/7Mvld+DBMZtOXXcJ3XdhqGS4/eJf+N9v8je20nAHzgWs7hJAUcHBwcugwu89TBwcGhy+Be7A4ODg5dBvdid3BwcOgyuBe7g4ODQ5fBvdgdHBwcugzuxe7g4ODQZXAvdgcHB4cuw/8HyTVZyiycJ2QAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["GroundTruth:    cat  ship  ship plane\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YhxuJRPKlboI"},"source":["# Conv Module"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Yq2YOGqolboJ","colab":{}},"source":["class Conv_module(nn.Module):\n","    def __init__(self,inp_ch,f,s,k,pad):\n","        super(Conv_module,self).__init__()\n","        self.inp_ch = inp_ch\n","        self.f = f\n","        self.s = s \n","        self.k = k \n","        self.pad = pad\n","        \n","        \n","        self.conv = nn.Conv2d(self.inp_ch,self.f,k,stride=s,padding=self.pad)\n","        self.bn = nn.BatchNorm2d(self.f)\n","        self.act = nn.ReLU()\n","    def forward(self,x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fszMLJRwlboK","outputId":"e4ca2447-f5da-4c79-a7e7-5cda9824a730","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["conv = Conv_module(3,64,1,3,1)\n","conv.forward(images).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([256, 64, 28, 28])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pXgvUubulboN"},"source":["# Inception module"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D1dG1aQ-lboN","colab":{}},"source":["class inception_module(nn.Module):\n","    def __init__(self,inp_ch,f0,f1):\n","        super(inception_module, self).__init__()\n","        self.inp_ch = inp_ch\n","        self.f0 = f0\n","        self.f1 = f1\n","        \n","        \n","        \n","        self.conv1 = Conv_module(self.inp_ch,self.f0,1,1,pad=0)\n","        self.conv3 = Conv_module(self.inp_ch,self.f1,1,3,pad=1)\n","        #self.conv1 = nn.Conv2d(3,self.f0,1)\n","        #self.conv3 = nn.Conv2d(3,self.f1,3,padding=1)\n","    def forward(self,x):\n","        x1 = self.conv1.forward(x)\n","        x3 = self.conv3.forward(x)\n","        #print(x1.shape,x3.shape)\n","        \n","        x = torch.cat((x1,x3),dim=1)\n","        \n","    \n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CVA66dtulboR","colab":{}},"source":["inc_module = inception_module(96,32,32)\n","conv_module = Conv_module(3,96,1,1,0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tTvE9wlGlboS","outputId":"3ec2ca24-9272-4895-bec0-44101cac8138","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["img = conv_module(images)\n","print(img.shape)\n","inc_module.forward(img).shape"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([256, 96, 28, 28])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["torch.Size([256, 64, 28, 28])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eP8oBKZClboV"},"source":["# Downsample module"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Nre7N9d-lboW","colab":{}},"source":["class downsample_module(nn.Module):\n","    def __init__(self,inp_ch,f):\n","        super(downsample_module,self).__init__()\n","        self.inp_ch = inp_ch\n","        self.f = f\n","        self.conv = Conv_module(self.inp_ch,self.f,2,3,pad=0)\n","        self.pool = nn.MaxPool2d(3,stride=2,padding=0)\n","    def forward(self,x):\n","        x1 = self.conv(x)\n","        #print(x1.shape)\n","        x2 = self.pool(x)\n","        #print(x2.shape)\n","        x = torch.cat((x1,x2),dim=1)\n","        \n","        return x\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"b4rD4J4FlboX","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9TOqXejopw2p"},"source":["Inception Net\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Y5gEimrwlboZ","colab":{}},"source":["class inception_net(nn.Module):\n","    def __init__(self):\n","        super(inception_net,self).__init__()\n","        self.conv1 = Conv_module(3,96,1,3,0)\n","        \n","        self.incept1 = inception_module(96,32,32)\n","        self.incept2 = inception_module(64,32,48)\n","        \n","        self.downsample1 = downsample_module(80,80)\n","        \n","        self.incept3 = inception_module(160,112,48)\n","        self.incept4 = inception_module(160,96,64)\n","        self.incept5 = inception_module(160,80,80)\n","        self.incept6 = inception_module(160,48,96)\n","        \n","        self.downsample2 = downsample_module(144,96)\n","        \n","        self.incept7 = inception_module(240,176,60)\n","        self.incept8 = inception_module(236,176,60)\n","        \n","        self.pool = nn.AvgPool2d(7)\n","        \n","        \n","        \n","        self.linear = nn.Linear(236,10)\n","    def forward(self,x):\n","        x = self.conv1.forward(x)\n","        \n","        x = self.incept1.forward(x)\n","        x = self.incept2.forward(x)\n","        \n","        x = self.downsample1.forward(x)\n","        \n","        x = self.incept3.forward(x)\n","        x = self.incept4.forward(x)\n","        x = self.incept5.forward(x)\n","        x = self.incept6.forward(x)\n","        \n","        x = self.downsample2.forward(x)\n","        \n","        x = self.incept7.forward(x)\n","        x = self.incept8.forward(x)\n","        \n","        x = self.pool(x)\n","        x = x.view(-1,1*1*236)\n","        x = self.linear(x) \n","        \n","        return x\n","        \n","        \n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y-g4gPjWlbob","colab":{}},"source":["inc = inception_net()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4PGmGPhClbog","outputId":"8ac7de0f-8fc6-49dc-fa91-7d4d62a2b3ae","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["inc.forward(images).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([256, 10])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"b3tHaKShlboi","colab":{}},"source":["criterion_inception = nn.CrossEntropyLoss()\n","optimizer_inception = optim.SGD(inc.parameters(), lr=0.01, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BkupoITklbok","outputId":"001e9fad-5365-4c26-f57c-9fa081c9a759","colab":{}},"source":["for epoch in range(20):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer_inception.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = inc(inputs)\n","        loss = criterion_inception(outputs, labels)\n","        loss.backward()\n","        optimizer_inception.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 50 == 49:    # print every 50 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 50))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,    50] loss: 1.963\n","[1,   100] loss: 1.530\n","[1,   150] loss: 1.330\n","[2,    50] loss: 1.066\n","[2,   100] loss: 0.999\n","[2,   150] loss: 0.949\n","[3,    50] loss: 0.812\n","[3,   100] loss: 0.781\n","[3,   150] loss: 0.781\n","[4,    50] loss: 0.647\n","[4,   100] loss: 0.648\n","[4,   150] loss: 0.640\n","[5,    50] loss: 0.539\n","[5,   100] loss: 0.539\n","[5,   150] loss: 0.537\n","[6,    50] loss: 0.469\n","[6,   100] loss: 0.467\n","[6,   150] loss: 0.491\n","[7,    50] loss: 0.397\n","[7,   100] loss: 0.394\n","[7,   150] loss: 0.407\n","[8,    50] loss: 0.333\n","[8,   100] loss: 0.333\n","[8,   150] loss: 0.346\n","[9,    50] loss: 0.275\n","[9,   100] loss: 0.281\n","[9,   150] loss: 0.299\n","[10,    50] loss: 0.220\n","[10,   100] loss: 0.226\n","[10,   150] loss: 0.259\n","[11,    50] loss: 0.183\n","[11,   100] loss: 0.174\n","[11,   150] loss: 0.195\n","[12,    50] loss: 0.150\n","[12,   100] loss: 0.154\n","[12,   150] loss: 0.161\n","[13,    50] loss: 0.131\n","[13,   100] loss: 0.118\n","[13,   150] loss: 0.131\n","[14,    50] loss: 0.097\n","[14,   100] loss: 0.087\n","[14,   150] loss: 0.103\n","[15,    50] loss: 0.085\n","[15,   100] loss: 0.077\n","[15,   150] loss: 0.093\n","[16,    50] loss: 0.061\n","[16,   100] loss: 0.060\n","[16,   150] loss: 0.061\n","[17,    50] loss: 0.048\n","[17,   100] loss: 0.045\n","[17,   150] loss: 0.045\n","[18,    50] loss: 0.043\n","[18,   100] loss: 0.035\n","[18,   150] loss: 0.035\n","[19,    50] loss: 0.027\n","[19,   100] loss: 0.021\n","[19,   150] loss: 0.018\n","[20,    50] loss: 0.012\n","[20,   100] loss: 0.009\n","[20,   150] loss: 0.008\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JF9CAEKMlbom","outputId":"df843b1d-c8fa-4856-9a59-18466e0db94d","colab":{}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in trainloader:\n","        images, labels = data\n","        outputs = inc(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 50000 train images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 50000 train images: 99 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bfr-dPXwlboo","outputId":"533cfa0e-9321-4211-9670-3175f7d6cf01","colab":{}},"source":["total,correct"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 49987)"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J8oMNfwBlboq","outputId":"29a28b30-54dc-4ba3-9837-413555900497","colab":{}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = inc(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 83 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5EUS3ljMlbot","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FUJpDLDDlbou","colab":{}},"source":["inc_net_random_labels = inception_net()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q0jKhmRblbov","colab":{}},"source":["criterion_inc_rand = nn.CrossEntropyLoss()\n","optimizer_inc_rand = optim.SGD(inc_net_random_labels.parameters(), lr=0.01, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sEnpiMs7lbox","outputId":"70c862fe-40b5-4cfe-8ddc-edb4f8c2da81","colab":{"base_uri":"https://localhost:8080/"}},"source":["for epoch in range(50):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader_random, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer_inc_rand.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = inc_net_random_labels(inputs)\n","        loss = criterion_inc_rand(outputs, labels)\n","        loss.backward()\n","        optimizer_inc_rand.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 50 == 49:    # print every 50 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 50))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,    50] loss: 2.238\n","[1,   100] loss: 2.208\n","[1,   150] loss: 2.204\n","[2,    50] loss: 2.200\n","[2,   100] loss: 2.199\n","[2,   150] loss: 2.199\n","[3,    50] loss: 2.195\n","[3,   100] loss: 2.197\n","[3,   150] loss: 2.196\n","[4,    50] loss: 2.190\n","[4,   100] loss: 2.192\n","[4,   150] loss: 2.193\n","[5,    50] loss: 2.185\n","[5,   100] loss: 2.186\n","[5,   150] loss: 2.188\n","[6,    50] loss: 2.181\n","[6,   100] loss: 2.181\n","[6,   150] loss: 2.183\n","[7,    50] loss: 2.171\n","[7,   100] loss: 2.173\n","[7,   150] loss: 2.177\n","[8,    50] loss: 2.156\n","[8,   100] loss: 2.163\n","[8,   150] loss: 2.172\n","[9,    50] loss: 2.141\n","[9,   100] loss: 2.154\n","[9,   150] loss: 2.168\n","[10,    50] loss: 2.128\n","[10,   100] loss: 2.140\n","[10,   150] loss: 2.156\n","[11,    50] loss: 2.108\n","[11,   100] loss: 2.127\n","[11,   150] loss: 2.133\n","[12,    50] loss: 2.076\n","[12,   100] loss: 2.099\n","[12,   150] loss: 2.122\n","[13,    50] loss: 2.045\n","[13,   100] loss: 2.065\n","[13,   150] loss: 2.089\n","[14,    50] loss: 1.991\n","[14,   100] loss: 2.027\n","[14,   150] loss: 2.063\n","[15,    50] loss: 1.939\n","[15,   100] loss: 1.989\n","[15,   150] loss: 2.035\n","[16,    50] loss: 1.873\n","[16,   100] loss: 1.936\n","[16,   150] loss: 1.989\n","[17,    50] loss: 1.803\n","[17,   100] loss: 1.860\n","[17,   150] loss: 1.937\n","[18,    50] loss: 1.720\n","[18,   100] loss: 1.793\n","[18,   150] loss: 1.865\n","[19,    50] loss: 1.648\n","[19,   100] loss: 1.712\n","[19,   150] loss: 1.784\n","[20,    50] loss: 1.549\n","[20,   100] loss: 1.611\n","[20,   150] loss: 1.709\n","[21,    50] loss: 1.441\n","[21,   100] loss: 1.504\n","[21,   150] loss: 1.605\n","[22,    50] loss: 1.340\n","[22,   100] loss: 1.417\n","[22,   150] loss: 1.516\n","[23,    50] loss: 1.241\n","[23,   100] loss: 1.318\n","[23,   150] loss: 1.423\n","[24,    50] loss: 1.121\n","[24,   100] loss: 1.177\n","[24,   150] loss: 1.317\n","[25,    50] loss: 1.026\n","[25,   100] loss: 1.087\n","[25,   150] loss: 1.254\n","[26,    50] loss: 0.945\n","[26,   100] loss: 0.983\n","[26,   150] loss: 1.094\n","[27,    50] loss: 0.862\n","[27,   100] loss: 0.880\n","[27,   150] loss: 0.975\n","[28,    50] loss: 0.792\n","[28,   100] loss: 0.810\n","[28,   150] loss: 0.906\n","[29,    50] loss: 0.703\n","[29,   100] loss: 0.700\n","[29,   150] loss: 0.805\n","[30,    50] loss: 0.645\n","[30,   100] loss: 0.632\n","[30,   150] loss: 0.715\n","[31,    50] loss: 0.533\n","[31,   100] loss: 0.552\n","[31,   150] loss: 0.626\n","[32,    50] loss: 0.499\n","[32,   100] loss: 0.499\n","[32,   150] loss: 0.568\n","[33,    50] loss: 0.463\n","[33,   100] loss: 0.464\n","[33,   150] loss: 0.497\n","[34,    50] loss: 0.396\n","[34,   100] loss: 0.380\n","[34,   150] loss: 0.475\n","[35,    50] loss: 0.369\n","[35,   100] loss: 0.373\n","[35,   150] loss: 0.413\n","[36,    50] loss: 0.299\n","[36,   100] loss: 0.288\n","[36,   150] loss: 0.302\n","[37,    50] loss: 0.286\n","[37,   100] loss: 0.282\n","[37,   150] loss: 0.300\n","[38,    50] loss: 0.261\n","[38,   100] loss: 0.255\n","[38,   150] loss: 0.276\n","[39,    50] loss: 0.222\n","[39,   100] loss: 0.229\n","[39,   150] loss: 0.241\n","[40,    50] loss: 0.190\n","[40,   100] loss: 0.202\n","[40,   150] loss: 0.231\n","[41,    50] loss: 0.194\n","[41,   100] loss: 0.190\n","[41,   150] loss: 0.223\n","[42,    50] loss: 0.216\n","[42,   100] loss: 0.213\n","[42,   150] loss: 0.228\n","[43,    50] loss: 0.207\n","[43,   100] loss: 0.202\n","[43,   150] loss: 0.226\n","[44,    50] loss: 0.172\n","[44,   100] loss: 0.160\n","[44,   150] loss: 0.176\n","[45,    50] loss: 0.129\n","[45,   100] loss: 0.104\n","[45,   150] loss: 0.119\n","[46,    50] loss: 0.109\n","[46,   100] loss: 0.102\n","[46,   150] loss: 0.107\n","[47,    50] loss: 0.082\n","[47,   100] loss: 0.076\n","[47,   150] loss: 0.072\n","[48,    50] loss: 0.078\n","[48,   100] loss: 0.069\n","[48,   150] loss: 0.072\n","[49,    50] loss: 0.056\n","[49,   100] loss: 0.053\n","[49,   150] loss: 0.055\n","[50,    50] loss: 0.044\n","[50,   100] loss: 0.040\n","[50,   150] loss: 0.043\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YDDiXdBvlboz","outputId":"f64b29d2-a57e-47d1-cbfe-65e2e3a22dcd","colab":{}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in trainloader_random:\n","        images, labels = data\n","        outputs = inc_net_random_labels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 50000 train images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 50000 train images: 99 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4Tmmfg-Ulbo1","outputId":"69a4f920-9f17-4202-bc58-75a7398a8ded","colab":{}},"source":["total,correct"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 49772)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FCDchYOalbo2","outputId":"c89c19c8-c0f9-44a7-ce7f-a4dd6131072f","colab":{}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = inc_net_random_labels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 10 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"H4PkIBO-lbo6"},"source":["# Save Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Kxs3ECpylbo6","outputId":"579c83b0-939a-419b-f86b-1fa5c97f5b19","colab":{}},"source":["torch.save(inc.state_dict(), \"inception.pt\")   #,Path)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('conv1.conv.weight', tensor([[[[ 0.1304,  0.1683,  0.0297],\n","                        [-0.2224,  0.1339,  0.1555],\n","                        [-0.0881,  0.1081,  0.0486]],\n","              \n","                       [[ 0.0793,  0.1005,  0.0591],\n","                        [-0.0831, -0.1551,  0.0623],\n","                        [ 0.1310, -0.0098, -0.0411]],\n","              \n","                       [[ 0.1015,  0.0386, -0.2247],\n","                        [ 0.1922,  0.0115, -0.1654],\n","                        [ 0.0381, -0.2064,  0.1216]]],\n","              \n","              \n","                      [[[ 0.0525, -0.0084, -0.0976],\n","                        [ 0.2441, -0.1759,  0.0378],\n","                        [-0.0858, -0.0514, -0.0928]],\n","              \n","                       [[ 0.0060, -0.1901, -0.1407],\n","                        [-0.0304, -0.1804,  0.2390],\n","                        [ 0.1882,  0.0604,  0.2187]],\n","              \n","                       [[-0.1399, -0.1670,  0.0145],\n","                        [-0.0575, -0.1405, -0.0083],\n","                        [ 0.0928,  0.1398, -0.0989]]],\n","              \n","              \n","                      [[[-0.1282, -0.1907, -0.1577],\n","                        [ 0.0169, -0.1782, -0.0584],\n","                        [ 0.2640,  0.0914, -0.1767]],\n","              \n","                       [[-0.0375, -0.1095,  0.2074],\n","                        [ 0.0684,  0.2524,  0.2991],\n","                        [ 0.0947, -0.1796,  0.0304]],\n","              \n","                       [[ 0.1520, -0.1289, -0.0315],\n","                        [-0.0576, -0.0435,  0.1029],\n","                        [-0.1870, -0.2241,  0.0842]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[-0.0192,  0.2135, -0.0861],\n","                        [-0.0273,  0.0128,  0.1619],\n","                        [-0.0766, -0.0380, -0.1889]],\n","              \n","                       [[-0.1795,  0.1805,  0.0424],\n","                        [ 0.1185,  0.0844,  0.1356],\n","                        [-0.1208, -0.1081,  0.1269]],\n","              \n","                       [[ 0.1860,  0.0113,  0.0728],\n","                        [-0.0682,  0.1033, -0.1786],\n","                        [-0.0309, -0.1850, -0.1368]]],\n","              \n","              \n","                      [[[-0.1552, -0.1369,  0.1535],\n","                        [-0.1441,  0.1516,  0.1737],\n","                        [-0.0701,  0.1400, -0.0898]],\n","              \n","                       [[ 0.1081, -0.0844,  0.1064],\n","                        [ 0.0885,  0.0935, -0.1337],\n","                        [ 0.0021, -0.1274, -0.0165]],\n","              \n","                       [[-0.1345, -0.1909,  0.0349],\n","                        [ 0.0257,  0.0197, -0.0463],\n","                        [ 0.2151,  0.1089, -0.0163]]],\n","              \n","              \n","                      [[[-0.1621, -0.2782,  0.2722],\n","                        [-0.0962, -0.1270, -0.0439],\n","                        [ 0.1297,  0.1302,  0.1924]],\n","              \n","                       [[ 0.2710, -0.1291, -0.0614],\n","                        [ 0.0922, -0.0252, -0.0014],\n","                        [-0.1931, -0.2399, -0.2307]],\n","              \n","                       [[ 0.2342, -0.0946, -0.1596],\n","                        [ 0.0722,  0.1214,  0.0681],\n","                        [-0.1106,  0.1148,  0.0049]]]])),\n","             ('conv1.conv.bias',\n","              tensor([-0.1921, -0.1188, -0.1419, -0.1744, -0.1834,  0.0040,  0.0832, -0.0482,\n","                       0.1197, -0.0566, -0.1670,  0.1856,  0.1401,  0.0261,  0.0229, -0.0620,\n","                      -0.1841, -0.1026,  0.1647, -0.0607, -0.1595, -0.1577, -0.0156,  0.1304,\n","                       0.1880, -0.0394,  0.0996, -0.1588,  0.1800, -0.1838,  0.0833,  0.1129,\n","                      -0.1731,  0.0100, -0.1677,  0.0775,  0.0250, -0.0211, -0.0592,  0.0804,\n","                       0.0260,  0.1133, -0.1311, -0.0919, -0.0403,  0.1370, -0.0886, -0.1371,\n","                       0.1242, -0.0114,  0.1043, -0.1369, -0.0151,  0.0251,  0.1822,  0.1242,\n","                      -0.1511,  0.1245, -0.1850,  0.1023,  0.1316,  0.1115,  0.1065, -0.1184,\n","                       0.0505, -0.1745, -0.0262, -0.0914, -0.0188, -0.0560, -0.1150,  0.1606,\n","                      -0.0522, -0.0272,  0.1445, -0.0468, -0.1198,  0.1672, -0.0558, -0.0921,\n","                       0.1068,  0.1058, -0.1465, -0.1112, -0.1038,  0.1202,  0.0999,  0.0692,\n","                       0.1357,  0.0613, -0.1222, -0.1482,  0.1483,  0.1340,  0.0215, -0.0934])),\n","             ('conv1.bn.weight',\n","              tensor([0.6093, 0.9079, 0.7996, 0.3598, 0.6736, 0.8109, 0.3288, 0.1859, 0.5661,\n","                      0.2743, 0.1609, 0.5252, 0.5718, 0.8386, 0.4374, 0.0473, 0.7809, 0.3454,\n","                      0.4785, 0.5135, 0.3338, 0.4969, 0.2214, 0.3863, 0.7338, 0.4496, 0.4349,\n","                      0.5076, 0.2450, 0.0196, 0.3741, 0.8778, 0.1607, 0.3440, 0.5116, 0.3429,\n","                      0.8887, 0.3660, 0.9105, 0.1295, 0.4605, 0.1070, 0.3698, 0.5849, 0.7346,\n","                      0.2252, 0.6797, 0.4083, 0.8019, 0.5649, 0.6341, 0.9678, 0.7266, 0.6935,\n","                      0.2551, 0.8016, 0.5144, 0.4627, 0.3419, 0.7551, 0.0093, 0.4787, 0.5698,\n","                      0.8433, 0.6801, 0.7759, 0.5215, 0.6348, 0.1802, 0.0205, 0.1328, 0.8974,\n","                      0.0872, 0.3389, 0.0397, 0.2028, 0.5082, 0.5194, 0.2870, 0.8263, 0.1709,\n","                      0.8828, 0.6833, 0.6855, 0.5799, 0.2112, 0.1194, 0.1234, 0.6618, 0.7202,\n","                      0.6286, 0.3861, 0.1059, 0.2860, 0.2782, 0.7875])),\n","             ('conv1.bn.bias',\n","              tensor([-0.0694, -0.1246, -0.0534, -0.0452,  0.0013,  0.1057, -0.0468,  0.0478,\n","                      -0.0806, -0.0142, -0.0103,  0.0835, -0.0455,  0.1729, -0.0211, -0.0192,\n","                      -0.0696,  0.1571, -0.0957,  0.0696,  0.1247,  0.1046, -0.0061, -0.0915,\n","                       0.1064,  0.1340,  0.0039,  0.0746, -0.0246,  0.0335, -0.0303,  0.0511,\n","                      -0.0636, -0.0409, -0.0033, -0.0339,  0.1151, -0.0761, -0.0579, -0.0203,\n","                      -0.0469, -0.0005,  0.0159,  0.0562,  0.0534, -0.0290,  0.0820,  0.0340,\n","                       0.1286, -0.0513, -0.0861,  0.1013,  0.1820,  0.0471, -0.0813,  0.0880,\n","                       0.0594, -0.0977,  0.0828,  0.0639,  0.0153,  0.0695, -0.0796, -0.0503,\n","                       0.0838,  0.2023, -0.0653, -0.1261,  0.0299, -0.0223, -0.0630,  0.1619,\n","                      -0.0119, -0.0741, -0.0140, -0.0388, -0.1007, -0.0773, -0.0245, -0.0039,\n","                      -0.0056,  0.4292,  0.0408,  0.0476, -0.0476,  0.0656,  0.0109,  0.0063,\n","                       0.1887,  0.0517, -0.0744, -0.0123, -0.0257,  0.0671,  0.0458, -0.0485])),\n","             ('conv1.bn.running_mean',\n","              tensor([-1.9735e-01, -8.5082e-02, -1.2118e-01, -1.4925e-01, -2.2267e-01,\n","                      -4.6181e-03,  1.5795e-01, -3.4342e-02,  1.1763e-01, -6.0967e-02,\n","                      -1.0611e-01,  2.3793e-01,  9.6938e-02,  3.2500e-02,  1.0237e-01,\n","                      -5.2836e-02, -2.5990e-01, -8.3947e-02,  1.6222e-01, -6.7207e-02,\n","                      -1.6788e-01, -1.3439e-01,  3.1738e-02,  1.1076e-01,  1.9366e-01,\n","                      -2.5514e-02,  1.1194e-01, -1.4399e-01,  3.0834e-01, -1.7428e-01,\n","                       1.2493e-01,  1.3343e-01, -7.0337e-02, -8.1082e-02, -1.6665e-01,\n","                       7.8132e-02,  3.7636e-02, -8.8677e-02, -6.1947e-02,  1.2135e-01,\n","                       2.6288e-04,  9.9494e-02, -1.4236e-01, -9.5220e-02, -4.7290e-02,\n","                       2.0077e-01, -7.5493e-02, -1.5515e-01,  1.2059e-01,  2.8428e-02,\n","                       1.3761e-01, -1.1871e-01, -1.3918e-02,  1.2573e-02,  1.6821e-01,\n","                       1.2708e-01, -1.3946e-01,  1.9131e-01, -1.8817e-01,  8.2955e-02,\n","                       1.6038e-01,  8.9543e-02,  1.3869e-01, -1.6308e-01,  6.3236e-02,\n","                      -1.6831e-01, -4.8271e-02,  2.0675e-02, -1.9994e-02, -7.5906e-02,\n","                      -2.1106e-01,  1.7365e-01, -5.1254e-02, -5.8938e-02,  2.0147e-01,\n","                      -1.3206e-01, -6.8420e-02,  1.6415e-01, -4.5327e-02, -8.0535e-02,\n","                       5.7221e-02,  1.1033e-01, -1.5013e-01, -1.0206e-01, -1.2993e-01,\n","                       1.4575e-01,  9.0061e-02,  1.4238e-01,  1.2980e-01,  6.1075e-02,\n","                      -8.1525e-02, -1.3901e-01,  1.7728e-01,  1.5339e-01,  1.4438e-02,\n","                      -9.6668e-02])),\n","             ('conv1.bn.running_var',\n","              tensor([0.0605, 0.0641, 0.0276, 0.0490, 0.0676, 0.0496, 0.0942, 0.0336, 0.0381,\n","                      0.0164, 0.1983, 0.0391, 0.0329, 0.0332, 0.0940, 0.1011, 0.0825, 0.0276,\n","                      0.0370, 0.0810, 0.0248, 0.0763, 0.1214, 0.1926, 0.0388, 0.0168, 0.0182,\n","                      0.0159, 0.3179, 0.0272, 0.0266, 0.0487, 0.2549, 0.1457, 0.0369, 0.0189,\n","                      0.0685, 0.1531, 0.0998, 0.0869, 0.0529, 0.0807, 0.0382, 0.0216, 0.0156,\n","                      0.0755, 0.0557, 0.0135, 0.0356, 0.0614, 0.0216, 0.0442, 0.0333, 0.0530,\n","                      0.0400, 0.0225, 0.0291, 0.0625, 0.0113, 0.0466, 0.0186, 0.0399, 0.0712,\n","                      0.0430, 0.0550, 0.0322, 0.0850, 0.4784, 0.0238, 0.0697, 0.2309, 0.0235,\n","                      0.0077, 0.0132, 0.1210, 0.2020, 0.0517, 0.0487, 0.0106, 0.0586, 0.0437,\n","                      0.0353, 0.0226, 0.0532, 0.1073, 0.0230, 0.0179, 0.1913, 0.0139, 0.0431,\n","                      0.0402, 0.0161, 0.0611, 0.0372, 0.0133, 0.0243])),\n","             ('conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept1.conv1.conv.weight', tensor([[[[-0.0700]],\n","              \n","                       [[ 0.0609]],\n","              \n","                       [[ 0.0890]],\n","              \n","                       ...,\n","              \n","                       [[-0.0229]],\n","              \n","                       [[ 0.0349]],\n","              \n","                       [[-0.0390]]],\n","              \n","              \n","                      [[[ 0.0154]],\n","              \n","                       [[-0.0844]],\n","              \n","                       [[-0.0200]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0839]],\n","              \n","                       [[ 0.0984]],\n","              \n","                       [[ 0.0702]]],\n","              \n","              \n","                      [[[-0.0836]],\n","              \n","                       [[-0.0194]],\n","              \n","                       [[-0.0932]],\n","              \n","                       ...,\n","              \n","                       [[-0.0342]],\n","              \n","                       [[-0.0871]],\n","              \n","                       [[-0.0002]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 0.0296]],\n","              \n","                       [[ 0.0584]],\n","              \n","                       [[-0.1180]],\n","              \n","                       ...,\n","              \n","                       [[-0.0213]],\n","              \n","                       [[-0.0196]],\n","              \n","                       [[ 0.0732]]],\n","              \n","              \n","                      [[[-0.0376]],\n","              \n","                       [[ 0.0050]],\n","              \n","                       [[-0.0760]],\n","              \n","                       ...,\n","              \n","                       [[-0.0429]],\n","              \n","                       [[-0.0121]],\n","              \n","                       [[ 0.0367]]],\n","              \n","              \n","                      [[[ 0.0006]],\n","              \n","                       [[-0.0210]],\n","              \n","                       [[-0.0112]],\n","              \n","                       ...,\n","              \n","                       [[-0.0653]],\n","              \n","                       [[-0.0008]],\n","              \n","                       [[-0.0375]]]])),\n","             ('incept1.conv1.conv.bias',\n","              tensor([ 0.0307,  0.0872,  0.0927,  0.0348,  0.0627,  0.0568,  0.0117,  0.0814,\n","                      -0.0124, -0.0461, -0.0900, -0.0121,  0.0329, -0.0605, -0.0584, -0.0444,\n","                      -0.0169, -0.0066, -0.0216, -0.0004, -0.0609,  0.0444,  0.0084,  0.0225,\n","                       0.0057,  0.0129, -0.0769,  0.0669, -0.0294, -0.0583, -0.0174, -0.0664])),\n","             ('incept1.conv1.bn.weight',\n","              tensor([7.1423e-01, 4.9962e-02, 6.7442e-02, 1.3754e-01, 3.7832e-01, 3.7825e-01,\n","                      8.8599e-01, 7.7832e-01, 3.9829e-01, 8.2223e-01, 6.8032e-01, 2.4468e-01,\n","                      1.2299e-01, 9.1092e-01, 2.7869e-01, 4.7607e-01, 3.3139e-01, 5.9433e-01,\n","                      8.4791e-04, 2.9077e-01, 3.8381e-01, 3.7918e-02, 8.8765e-01, 2.5041e-01,\n","                      8.4028e-01, 5.2440e-01, 8.2957e-01, 7.8362e-01, 7.9454e-01, 8.1965e-01,\n","                      2.5058e-01, 8.6364e-01])),\n","             ('incept1.conv1.bn.bias',\n","              tensor([ 0.0794,  0.0167,  0.0247,  0.0304, -0.0816,  0.0129,  0.0485, -0.0643,\n","                      -0.0480,  0.0017, -0.0973, -0.0043,  0.0670,  0.0193,  0.0174, -0.0258,\n","                      -0.0706,  0.0170, -0.0060,  0.0399, -0.0445,  0.0282,  0.0560, -0.0697,\n","                       0.0480,  0.0068,  0.0717,  0.1058,  0.0906, -0.0822, -0.0004,  0.0071])),\n","             ('incept1.conv1.bn.running_mean',\n","              tensor([-0.5444,  0.2018,  0.0772, -0.1679,  0.5369,  0.2081, -0.3700, -0.2916,\n","                       0.3190, -0.3646, -0.2632,  0.2763,  0.0594, -0.2974, -0.0228, -0.4288,\n","                       0.1542,  0.1601, -0.1010,  0.0282,  0.0551,  0.0308, -0.3658,  0.1360,\n","                      -0.2332, -0.1885, -0.3378,  0.0482, -0.4319, -0.4392, -0.2569, -0.5325])),\n","             ('incept1.conv1.bn.running_var',\n","              tensor([0.2307, 0.0495, 0.0377, 0.0322, 0.1009, 0.1097, 0.2509, 0.1497, 0.0821,\n","                      0.1832, 0.1246, 0.0528, 0.0405, 0.2065, 0.0475, 0.1133, 0.0507, 0.1179,\n","                      0.0283, 0.0646, 0.0713, 0.0287, 0.2781, 0.0514, 0.2611, 0.0992, 0.2688,\n","                      0.2438, 0.2173, 0.2132, 0.0482, 0.2215])),\n","             ('incept1.conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept1.conv3.conv.weight',\n","              tensor([[[[ 2.2341e-02,  3.8276e-03, -2.7121e-02],\n","                        [ 1.9024e-02,  2.2500e-02,  2.7256e-02],\n","                        [ 4.5630e-03,  2.4094e-02, -2.3292e-02]],\n","              \n","                       [[ 1.2199e-02, -2.5879e-02,  1.6203e-02],\n","                        [-1.5863e-02,  4.9364e-02, -3.3542e-03],\n","                        [-1.3404e-03,  3.3223e-02,  3.7132e-02]],\n","              \n","                       [[-7.3910e-02, -6.1094e-02, -2.4513e-02],\n","                        [ 6.0260e-03, -7.1954e-02, -3.1525e-02],\n","                        [-1.7669e-02,  2.4061e-02,  1.2000e-02]],\n","              \n","                       ...,\n","              \n","                       [[-1.5832e-02, -1.2939e-02,  8.1239e-03],\n","                        [-5.1511e-03, -6.1341e-03,  3.5959e-02],\n","                        [ 3.0080e-02, -6.6607e-03,  2.9412e-02]],\n","              \n","                       [[ 4.0209e-02,  3.8172e-03, -2.6906e-02],\n","                        [-2.1027e-02, -3.1952e-02,  7.4044e-03],\n","                        [-1.2763e-02,  1.4206e-02, -2.8196e-02]],\n","              \n","                       [[-1.5068e-02, -9.9283e-04, -2.1892e-02],\n","                        [-8.9633e-03, -4.6431e-02,  7.6449e-03],\n","                        [-3.7751e-02, -8.2672e-03, -6.6602e-02]]],\n","              \n","              \n","                      [[[-1.3075e-02,  6.8864e-03,  7.3601e-02],\n","                        [-4.9214e-04, -1.6184e-02,  5.0400e-02],\n","                        [-5.5553e-02,  1.1618e-02,  6.6341e-02]],\n","              \n","                       [[-5.5693e-02, -4.8112e-02, -9.3530e-03],\n","                        [-3.3626e-02, -6.8526e-02, -3.7839e-02],\n","                        [ 4.7897e-02, -1.1411e-02, -8.7410e-03]],\n","              \n","                       [[-7.5427e-03, -4.8703e-03,  8.3367e-05],\n","                        [-4.7332e-02, -1.0242e-02, -1.6510e-02],\n","                        [-6.4315e-02, -4.4666e-02, -1.9459e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 1.5532e-02, -1.9864e-02, -2.3488e-02],\n","                        [-7.8557e-03,  7.6611e-03, -1.8668e-02],\n","                        [-2.4569e-02,  2.1549e-02, -2.8372e-03]],\n","              \n","                       [[-2.9805e-02,  2.6968e-03, -1.3479e-02],\n","                        [-2.6806e-02, -2.9389e-02,  2.4319e-03],\n","                        [-5.9382e-03,  3.4008e-02, -3.6549e-02]],\n","              \n","                       [[-1.9838e-02, -2.1870e-02, -1.6222e-03],\n","                        [ 4.9169e-03,  5.6742e-02,  3.8778e-02],\n","                        [ 1.6133e-02, -2.4747e-02,  8.5742e-03]]],\n","              \n","              \n","                      [[[-5.8560e-02,  2.3922e-02, -2.3271e-02],\n","                        [-2.1698e-02, -2.5051e-02,  4.0468e-02],\n","                        [ 1.4071e-02, -2.0680e-02,  3.7429e-02]],\n","              \n","                       [[-2.8168e-02,  3.9901e-02,  7.2555e-03],\n","                        [-2.7004e-04, -8.5762e-03, -1.7411e-02],\n","                        [ 3.5784e-02, -1.0344e-02, -4.8004e-02]],\n","              \n","                       [[-4.3633e-02,  2.4074e-02,  1.6930e-02],\n","                        [-2.4186e-02,  1.2253e-02, -4.1500e-03],\n","                        [-1.8044e-02,  8.1482e-03, -4.0565e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 3.2967e-02, -3.2414e-03, -2.4261e-02],\n","                        [ 1.3085e-02,  1.1640e-02,  2.8729e-02],\n","                        [ 2.5583e-02, -3.6422e-02,  1.8548e-02]],\n","              \n","                       [[ 1.9999e-02,  2.5188e-02,  5.7092e-03],\n","                        [ 1.2405e-02, -9.5057e-03,  1.6908e-02],\n","                        [-9.5676e-03,  1.9596e-02, -2.0376e-03]],\n","              \n","                       [[-6.3429e-02,  1.4088e-02,  2.4981e-02],\n","                        [-1.1042e-02, -4.5940e-04, -2.5103e-02],\n","                        [ 9.5365e-04, -9.6732e-03, -5.5154e-04]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 3.5551e-02,  2.5246e-02,  2.7614e-03],\n","                        [ 3.7570e-02,  2.4801e-02, -3.2659e-02],\n","                        [ 5.8103e-02,  4.4927e-02,  2.7084e-03]],\n","              \n","                       [[-5.1415e-02,  2.1889e-02, -2.5070e-03],\n","                        [-4.1341e-02,  4.6577e-02,  5.4163e-03],\n","                        [ 3.9332e-03,  4.8665e-04, -2.8937e-02]],\n","              \n","                       [[-1.1090e-02,  6.3467e-02,  8.6131e-02],\n","                        [-2.9496e-02, -2.1111e-02,  5.3229e-03],\n","                        [ 1.0023e-02,  2.6835e-03, -7.5679e-03]],\n","              \n","                       ...,\n","              \n","                       [[-3.6116e-02, -4.5320e-02, -2.4430e-02],\n","                        [-1.4174e-02, -3.1472e-02, -4.1618e-02],\n","                        [-2.4389e-02, -3.2213e-02,  1.0962e-02]],\n","              \n","                       [[ 2.4398e-02, -3.8314e-02,  1.8184e-02],\n","                        [ 7.8415e-03, -1.4775e-02, -1.5676e-02],\n","                        [ 1.3164e-02,  3.1848e-02,  1.1196e-04]],\n","              \n","                       [[-1.1890e-02,  1.5862e-02,  2.5403e-03],\n","                        [ 3.7924e-02,  4.1869e-03,  2.4550e-02],\n","                        [ 2.6408e-02,  9.6211e-03, -2.6088e-02]]],\n","              \n","              \n","                      [[[ 1.0583e-03,  1.8486e-02,  1.1377e-02],\n","                        [ 3.7136e-02, -1.3655e-02, -4.4774e-03],\n","                        [ 7.5888e-03, -2.0079e-02,  2.8289e-02]],\n","              \n","                       [[-3.8335e-02,  1.4371e-02, -3.4189e-02],\n","                        [-6.5185e-02, -6.1609e-03,  2.4535e-03],\n","                        [-5.5970e-02, -1.7756e-02,  1.3010e-02]],\n","              \n","                       [[-3.2158e-02,  4.8966e-03, -1.3559e-02],\n","                        [-5.4287e-03, -2.8319e-03, -1.3117e-02],\n","                        [-5.3692e-02, -2.3821e-02, -9.3147e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 1.6656e-02,  1.7111e-03, -3.1186e-02],\n","                        [ 2.6941e-02, -6.5768e-04, -2.8737e-02],\n","                        [-1.0139e-02,  2.8894e-02,  2.7790e-02]],\n","              \n","                       [[ 3.4755e-02,  2.0297e-02, -1.1274e-02],\n","                        [ 4.1371e-02,  2.1173e-02, -3.9587e-02],\n","                        [-2.5189e-02, -3.3521e-02, -3.1398e-02]],\n","              \n","                       [[-4.2572e-02, -5.1689e-02,  8.1939e-03],\n","                        [-3.5520e-02, -4.1912e-02,  2.9762e-02],\n","                        [ 5.1907e-03, -1.9536e-02,  2.8833e-02]]],\n","              \n","              \n","                      [[[-1.7496e-02,  2.0361e-02, -2.8381e-02],\n","                        [-3.6648e-03, -2.3657e-03, -2.8077e-03],\n","                        [ 2.3067e-03, -2.7158e-02,  1.9726e-03]],\n","              \n","                       [[ 6.8433e-03,  1.4186e-02,  3.0949e-02],\n","                        [ 2.0943e-02,  8.7398e-04, -1.5776e-02],\n","                        [ 4.7518e-02,  6.9186e-03,  1.7279e-02]],\n","              \n","                       [[-1.2971e-02, -1.6569e-02, -3.7134e-02],\n","                        [ 3.4520e-02, -1.1149e-02, -6.6114e-02],\n","                        [ 1.8433e-02,  3.9788e-03, -5.5822e-03]],\n","              \n","                       ...,\n","              \n","                       [[-3.2086e-02,  8.3777e-03,  3.2214e-02],\n","                        [-1.8989e-02, -2.1605e-02, -2.9093e-02],\n","                        [-2.5546e-02,  1.0235e-02, -3.7331e-02]],\n","              \n","                       [[-1.0040e-02, -2.7046e-02, -2.0732e-02],\n","                        [-1.4564e-02, -2.8806e-02,  2.4361e-02],\n","                        [-2.6794e-02,  1.2389e-02, -1.7986e-02]],\n","              \n","                       [[ 3.7169e-02,  1.1688e-02, -2.6925e-02],\n","                        [-3.5285e-02,  1.0688e-02, -5.3991e-02],\n","                        [-4.9751e-02,  3.7479e-02, -1.4361e-03]]]])),\n","             ('incept1.conv3.conv.bias',\n","              tensor([ 0.0285, -0.0013, -0.0317,  0.0139, -0.0222, -0.0309,  0.0098,  0.0002,\n","                       0.0327, -0.0068,  0.0020, -0.0051, -0.0105, -0.0228,  0.0186, -0.0251,\n","                       0.0066, -0.0263,  0.0309, -0.0143, -0.0172,  0.0027,  0.0144,  0.0260,\n","                       0.0233,  0.0135,  0.0110,  0.0198,  0.0106,  0.0057,  0.0048, -0.0041])),\n","             ('incept1.conv3.bn.weight',\n","              tensor([0.4113, 0.8376, 0.4939, 0.3842, 0.8274, 0.7510, 0.4393, 0.5109, 0.6735,\n","                      0.0614, 0.4769, 0.3673, 0.3471, 0.5308, 0.3169, 0.0764, 0.8369, 0.0850,\n","                      0.5905, 0.4193, 0.8551, 0.5234, 0.4717, 0.7062, 0.6760, 0.5848, 0.1996,\n","                      0.6466, 0.6539, 0.4761, 0.6475, 0.4087])),\n","             ('incept1.conv3.bn.bias',\n","              tensor([ 0.0183, -0.0057,  0.0304,  0.0172, -0.0457,  0.0690, -0.0392, -0.0511,\n","                       0.1045,  0.0120, -0.0594, -0.0433,  0.0438, -0.0436, -0.0431,  0.0120,\n","                       0.1114,  0.0613,  0.0363, -0.0481,  0.1727,  0.0920, -0.0320,  0.0421,\n","                       0.0065, -0.0494, -0.0349,  0.0016,  0.1255,  0.0124, -0.0629,  0.0406])),\n","             ('incept1.conv3.bn.running_mean',\n","              tensor([-5.2189e-01, -8.7541e-01, -5.4702e-01,  3.1290e-01,  2.0090e-01,\n","                      -3.4741e-01, -3.0330e-01, -3.0875e-01, -7.3073e-01,  7.5562e-04,\n","                      -3.7592e-02, -5.3510e-01, -7.5412e-01, -1.1997e-01, -2.6025e-01,\n","                      -3.1137e-01, -8.1697e-01, -1.5057e-02, -7.1091e-01, -2.9500e-01,\n","                      -6.8261e-01, -3.0054e-01, -6.8099e-01, -8.8716e-01, -6.2401e-01,\n","                      -6.8172e-01, -2.2036e-01, -7.6489e-01, -8.4302e-02, -4.5082e-01,\n","                      -9.4647e-01, -3.1655e-01])),\n","             ('incept1.conv3.bn.running_var',\n","              tensor([0.2476, 1.1378, 0.5246, 0.2189, 1.5694, 0.7324, 0.2980, 0.4083, 0.9273,\n","                      0.0657, 0.3154, 0.1900, 0.2784, 0.4992, 0.1840, 0.0552, 0.7730, 0.0835,\n","                      0.4284, 0.2937, 0.6406, 0.5435, 0.4532, 0.7404, 0.4523, 0.4434, 0.1944,\n","                      0.5977, 0.6202, 0.4949, 0.7123, 0.2592])),\n","             ('incept1.conv3.bn.num_batches_tracked', tensor(4157)),\n","             ('incept2.conv1.conv.weight', tensor([[[[-0.0911]],\n","              \n","                       [[ 0.0615]],\n","              \n","                       [[ 0.0376]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0324]],\n","              \n","                       [[-0.0359]],\n","              \n","                       [[-0.0113]]],\n","              \n","              \n","                      [[[-0.0387]],\n","              \n","                       [[-0.1105]],\n","              \n","                       [[ 0.0213]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0581]],\n","              \n","                       [[ 0.0455]],\n","              \n","                       [[-0.0921]]],\n","              \n","              \n","                      [[[-0.0613]],\n","              \n","                       [[ 0.0558]],\n","              \n","                       [[-0.0062]],\n","              \n","                       ...,\n","              \n","                       [[-0.1025]],\n","              \n","                       [[ 0.0635]],\n","              \n","                       [[-0.0064]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 0.0919]],\n","              \n","                       [[ 0.0484]],\n","              \n","                       [[ 0.0200]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0506]],\n","              \n","                       [[-0.0475]],\n","              \n","                       [[ 0.1185]]],\n","              \n","              \n","                      [[[-0.1117]],\n","              \n","                       [[ 0.0356]],\n","              \n","                       [[ 0.0124]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0611]],\n","              \n","                       [[-0.0371]],\n","              \n","                       [[-0.0736]]],\n","              \n","              \n","                      [[[-0.0924]],\n","              \n","                       [[ 0.0937]],\n","              \n","                       [[-0.1137]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0942]],\n","              \n","                       [[ 0.0868]],\n","              \n","                       [[-0.0786]]]])),\n","             ('incept2.conv1.conv.bias',\n","              tensor([ 0.0415, -0.0902, -0.0841,  0.0724,  0.0732,  0.0643, -0.0175, -0.0801,\n","                      -0.0727, -0.0718,  0.0695,  0.0158,  0.0037, -0.0224, -0.0717,  0.1176,\n","                      -0.1036, -0.0073,  0.1215, -0.0725,  0.0777,  0.0606, -0.1071, -0.0282,\n","                       0.0222, -0.0939,  0.1192,  0.0430,  0.0220, -0.0947,  0.0612,  0.0103])),\n","             ('incept2.conv1.bn.weight',\n","              tensor([0.0567, 0.5178, 0.6640, 0.6208, 0.9298, 0.7214, 0.5165, 0.3138, 0.6524,\n","                      0.8384, 0.3678, 0.6353, 0.0618, 0.4904, 0.3552, 0.6839, 0.7100, 0.2664,\n","                      0.7856, 0.4932, 0.1337, 0.0297, 0.6947, 0.1110, 0.6592, 0.3251, 0.5197,\n","                      0.4085, 0.3207, 0.5074, 0.8323, 0.5018])),\n","             ('incept2.conv1.bn.bias',\n","              tensor([-0.0128, -0.0948, -0.0895, -0.0605, -0.0285, -0.0519, -0.0095, -0.0234,\n","                      -0.0630, -0.0808, -0.0474, -0.0833,  0.0139, -0.0847, -0.0078, -0.1029,\n","                      -0.0404, -0.0215, -0.0736, -0.0476, -0.0217,  0.0157, -0.0093, -0.0124,\n","                      -0.0547, -0.0098, -0.0432, -0.0042, -0.0105, -0.0146, -0.0061, -0.0278])),\n","             ('incept2.conv1.bn.running_mean',\n","              tensor([-0.0205, -0.3390, -0.0465, -0.0134, -0.1203, -0.1280, -0.1160, -0.1312,\n","                      -0.2188, -0.1284, -0.0470,  0.0999, -0.1236, -0.0250, -0.1953,  0.1677,\n","                      -0.0111,  0.0622, -0.0103, -0.1774,  0.1793,  0.0996, -0.1789, -0.1890,\n","                      -0.3484, -0.0627,  0.2439, -0.1670, -0.0338,  0.1370, -0.2903, -0.2118])),\n","             ('incept2.conv1.bn.running_var',\n","              tensor([0.0206, 0.0584, 0.0850, 0.0632, 0.1421, 0.1047, 0.0523, 0.0289, 0.0951,\n","                      0.1109, 0.0431, 0.0685, 0.0463, 0.0701, 0.0433, 0.1190, 0.0911, 0.0310,\n","                      0.0954, 0.0899, 0.0217, 0.0227, 0.0999, 0.0284, 0.0865, 0.0269, 0.0779,\n","                      0.0349, 0.0445, 0.0564, 0.1189, 0.0527])),\n","             ('incept2.conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept2.conv3.conv.weight',\n","              tensor([[[[ 5.0458e-03,  7.3904e-03, -7.9709e-03],\n","                        [-4.9440e-02, -1.3530e-02,  1.6411e-02],\n","                        [-2.0517e-02, -9.1139e-03, -3.7508e-02]],\n","              \n","                       [[-2.5250e-02, -2.8692e-02,  4.0825e-02],\n","                        [-2.5170e-03, -4.3232e-03, -6.1342e-03],\n","                        [ 2.6752e-02,  1.5152e-02,  3.0389e-02]],\n","              \n","                       [[-2.2764e-02,  1.0112e-02,  4.0965e-02],\n","                        [ 7.2091e-03, -1.3832e-03,  5.9142e-03],\n","                        [ 3.2166e-02,  2.1478e-02, -2.7881e-02]],\n","              \n","                       ...,\n","              \n","                       [[-1.3577e-02,  3.5194e-02, -6.1461e-03],\n","                        [ 2.7204e-04,  2.7418e-02,  1.7023e-02],\n","                        [-7.6329e-03, -4.2064e-02,  5.3373e-02]],\n","              \n","                       [[-1.5669e-02, -1.5239e-02,  2.8325e-02],\n","                        [-4.0024e-02,  3.9702e-03, -2.6717e-02],\n","                        [ 1.2755e-02, -5.2120e-02, -1.5052e-02]],\n","              \n","                       [[ 1.3772e-02,  2.8717e-02,  3.4941e-02],\n","                        [ 5.9554e-03,  4.8663e-02, -6.7242e-03],\n","                        [-2.4448e-02, -9.6652e-03, -1.3584e-02]]],\n","              \n","              \n","                      [[[ 3.7506e-02,  5.0602e-02, -3.7336e-02],\n","                        [-3.9315e-02,  1.3191e-02,  1.9973e-02],\n","                        [-1.2485e-03, -3.1179e-02,  8.4987e-03]],\n","              \n","                       [[-3.4647e-02,  8.5610e-03, -3.5460e-02],\n","                        [ 3.6777e-02, -2.9890e-02, -4.2529e-02],\n","                        [-4.5080e-03, -3.5995e-02, -3.8587e-02]],\n","              \n","                       [[ 6.3732e-03, -1.5171e-02,  1.5637e-02],\n","                        [-3.0335e-02, -2.1729e-02,  3.7244e-02],\n","                        [ 3.6451e-02, -5.3595e-03, -1.0943e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 3.9361e-02, -3.4523e-02, -3.3739e-02],\n","                        [ 1.4063e-02,  2.8781e-02,  5.0900e-02],\n","                        [ 2.6521e-02,  7.9772e-02,  1.6257e-02]],\n","              \n","                       [[-5.0640e-02, -1.9634e-02, -8.9806e-03],\n","                        [ 1.2151e-02, -5.0848e-02,  1.6758e-02],\n","                        [-6.9923e-03,  5.8509e-02,  4.9112e-02]],\n","              \n","                       [[ 1.4527e-02,  4.4092e-02, -1.1696e-02],\n","                        [-1.8631e-03,  9.8834e-03,  4.2629e-02],\n","                        [-5.2384e-02, -4.0191e-03,  7.2094e-03]]],\n","              \n","              \n","                      [[[ 4.1882e-02,  2.1877e-02,  5.8862e-02],\n","                        [-2.5200e-04,  1.8409e-02,  1.4879e-02],\n","                        [-8.2222e-02, -2.1356e-02, -2.2129e-02]],\n","              \n","                       [[ 3.0550e-02, -2.1529e-02, -6.4213e-03],\n","                        [-4.2773e-02, -4.3379e-02,  1.9632e-03],\n","                        [-1.4754e-02, -1.1527e-02,  2.4697e-02]],\n","              \n","                       [[ 4.4083e-02, -3.9542e-03, -3.4690e-02],\n","                        [ 1.6562e-02, -3.2984e-02, -2.3357e-02],\n","                        [ 8.2087e-04, -7.5659e-06, -1.6228e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 2.3803e-02,  4.9969e-02, -1.0299e-02],\n","                        [-1.8365e-02,  1.9723e-02, -1.9841e-02],\n","                        [-8.3400e-03,  1.4736e-02,  3.2741e-03]],\n","              \n","                       [[ 1.9529e-02, -8.9101e-03, -9.6403e-04],\n","                        [-2.2712e-02,  5.5066e-02, -1.2042e-02],\n","                        [ 2.6288e-03,  3.6755e-02,  8.0690e-02]],\n","              \n","                       [[-3.3075e-02, -4.6797e-02,  3.4845e-03],\n","                        [-3.7242e-02, -5.0297e-02,  2.4246e-03],\n","                        [ 2.7884e-02,  2.7276e-02,  2.3431e-02]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 5.6671e-02,  1.0205e-01,  5.3889e-02],\n","                        [ 1.4810e-02,  7.4076e-02,  7.9156e-02],\n","                        [ 4.3051e-02, -3.0481e-02,  4.1086e-02]],\n","              \n","                       [[-1.8750e-02,  4.6008e-03,  2.0668e-03],\n","                        [-2.7835e-02,  1.6591e-02, -2.5670e-02],\n","                        [-1.1241e-02,  2.1853e-03, -2.1903e-02]],\n","              \n","                       [[ 2.2705e-02, -2.0523e-02,  2.3766e-02],\n","                        [-2.7854e-02, -2.2072e-02, -7.7120e-03],\n","                        [-3.7616e-02, -9.0016e-03,  2.6269e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 4.8098e-04, -4.5373e-02, -1.6529e-02],\n","                        [ 5.3467e-02,  2.6812e-03,  4.2575e-02],\n","                        [ 1.9552e-02,  4.1262e-02,  3.9283e-02]],\n","              \n","                       [[-3.5830e-02,  1.1880e-02,  1.2674e-02],\n","                        [ 1.3382e-02, -5.4235e-02, -1.4314e-02],\n","                        [ 2.0219e-02, -2.6672e-02,  8.3507e-03]],\n","              \n","                       [[ 2.3088e-03,  5.9596e-02,  4.1831e-02],\n","                        [-4.7037e-02, -1.6615e-02,  6.8564e-02],\n","                        [-5.0212e-02, -9.2642e-03,  6.0723e-02]]],\n","              \n","              \n","                      [[[-4.0175e-02, -3.0095e-02,  2.3251e-02],\n","                        [-2.1590e-02,  1.6961e-02, -5.5077e-03],\n","                        [-1.0091e-02,  3.5228e-02,  2.5208e-02]],\n","              \n","                       [[-1.7228e-02, -3.9191e-02, -1.8048e-02],\n","                        [-1.0438e-02, -3.8119e-02,  4.6684e-03],\n","                        [-1.7037e-05, -8.9671e-03,  9.3871e-03]],\n","              \n","                       [[ 3.1943e-02,  7.8790e-03,  2.4275e-02],\n","                        [-2.0492e-02, -3.5316e-02,  1.0155e-02],\n","                        [ 1.5490e-02,  2.0390e-02, -3.3665e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 3.5059e-02,  2.2403e-02, -2.8602e-02],\n","                        [-7.3419e-03, -2.7200e-03, -1.7592e-02],\n","                        [ 3.5957e-02,  9.2915e-03, -4.4648e-02]],\n","              \n","                       [[ 1.8314e-02,  1.7950e-02, -3.7515e-02],\n","                        [-3.0367e-02,  3.8620e-02,  4.1971e-02],\n","                        [-3.1645e-02,  7.6394e-03,  6.0557e-02]],\n","              \n","                       [[ 2.7038e-02,  1.0063e-02,  1.4127e-02],\n","                        [-1.7719e-02,  5.3192e-04, -1.1244e-02],\n","                        [ 3.1209e-02, -1.0064e-03,  2.3204e-02]]],\n","              \n","              \n","                      [[[-1.7806e-02,  3.3819e-02,  2.1928e-02],\n","                        [-3.4342e-02, -4.2401e-02,  3.9897e-02],\n","                        [-4.6548e-02, -2.9009e-02, -1.6264e-02]],\n","              \n","                       [[-3.4322e-02, -4.2325e-02, -4.8853e-03],\n","                        [-2.7986e-02,  2.5941e-02,  7.0102e-03],\n","                        [-6.3701e-03, -2.9843e-02, -1.7564e-02]],\n","              \n","                       [[-3.1109e-02,  9.8407e-03,  1.1436e-02],\n","                        [ 1.6100e-04, -3.7852e-02, -2.1701e-02],\n","                        [ 9.9465e-04,  8.4232e-03, -1.2952e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 2.4075e-02,  4.4023e-02, -3.7099e-02],\n","                        [ 2.2943e-02, -2.5938e-02, -3.3001e-02],\n","                        [ 6.9814e-03,  2.4473e-02,  3.8840e-02]],\n","              \n","                       [[-8.5797e-03,  3.0423e-03, -5.4918e-02],\n","                        [ 1.5320e-02, -2.2604e-02, -1.8919e-02],\n","                        [-3.0504e-02, -2.0018e-02,  8.1390e-04]],\n","              \n","                       [[ 2.8305e-02,  8.6280e-03,  2.7298e-02],\n","                        [-3.4013e-02,  7.0326e-03, -1.8279e-02],\n","                        [-8.7309e-03, -3.5612e-02, -2.8448e-02]]]])),\n","             ('incept2.conv3.conv.bias',\n","              tensor([-0.0084, -0.0353,  0.0207, -0.0054,  0.0055, -0.0384,  0.0154,  0.0253,\n","                      -0.0013, -0.0250, -0.0161, -0.0032, -0.0091, -0.0010, -0.0229,  0.0143,\n","                       0.0315,  0.0147,  0.0130,  0.0191,  0.0019,  0.0082,  0.0403,  0.0270,\n","                      -0.0204,  0.0318, -0.0213,  0.0063, -0.0229, -0.0367,  0.0121, -0.0088,\n","                       0.0306,  0.0319, -0.0178, -0.0382, -0.0024, -0.0039, -0.0252, -0.0032,\n","                      -0.0021, -0.0025, -0.0243, -0.0312, -0.0140, -0.0270,  0.0115,  0.0375])),\n","             ('incept2.conv3.bn.weight',\n","              tensor([0.1632, 0.7393, 0.4515, 0.5583, 0.2036, 0.1113, 0.5701, 0.7491, 0.5915,\n","                      0.5723, 0.3030, 0.1824, 0.1410, 0.4539, 0.3341, 0.2251, 0.3974, 0.6183,\n","                      0.6615, 0.3067, 0.3352, 0.4214, 0.6729, 0.6299, 0.5798, 0.6891, 0.3733,\n","                      0.3671, 0.2000, 0.0665, 0.6760, 0.6520, 0.2721, 0.2870, 0.1006, 0.8617,\n","                      0.6561, 0.1528, 0.6128, 0.3490, 0.3972, 0.6986, 0.4366, 0.2282, 0.6764,\n","                      0.7894, 0.2201, 0.5350])),\n","             ('incept2.conv3.bn.bias',\n","              tensor([ 0.0014, -0.0251, -0.0575, -0.0486, -0.0410, -0.0160, -0.0630, -0.0717,\n","                      -0.0566, -0.0092, -0.0265, -0.0095, -0.0051, -0.0325, -0.0557, -0.0301,\n","                      -0.0614, -0.0792, -0.0105, -0.0487, -0.0303, -0.0813, -0.1030, -0.0833,\n","                      -0.0926, -0.0491, -0.0042, -0.0308, -0.0010, -0.0256, -0.0867, -0.0647,\n","                      -0.0567, -0.0357, -0.0193, -0.0699, -0.0207, -0.0257, -0.0359, -0.0335,\n","                      -0.0648, -0.0630, -0.0633, -0.0033, -0.0762, -0.0610, -0.0363, -0.0308])),\n","             ('incept2.conv3.bn.running_mean',\n","              tensor([-0.1898, -0.1924, -0.4715, -0.4334,  0.1376, -0.4256, -0.3419, -0.3622,\n","                      -0.5896, -0.6471, -0.0714,  0.0415, -0.0836,  0.0289,  0.3689,  0.1179,\n","                       0.1045, -0.1902, -0.1493,  0.3054, -0.2080,  0.1648, -0.6662, -0.3761,\n","                      -0.3246, -0.4138, -0.0641, -0.0281, -0.2071,  0.0439, -0.3322, -0.3278,\n","                      -0.3319, -0.0195,  0.0017, -0.5413, -0.3776,  0.0226, -0.3496, -0.1566,\n","                       0.3285,  0.0126, -0.4707,  0.1319, -0.4707, -0.5143,  0.0391, -0.7656])),\n","             ('incept2.conv3.bn.running_var',\n","              tensor([0.0514, 0.3436, 0.1420, 0.3416, 0.0510, 0.0421, 0.2603, 0.4040, 0.3392,\n","                      0.2274, 0.0895, 0.0505, 0.0660, 0.1178, 0.1313, 0.0916, 0.1300, 0.5103,\n","                      0.3032, 0.0921, 0.1076, 0.1915, 0.2505, 0.2034, 0.2064, 0.4911, 0.1275,\n","                      0.1048, 0.0534, 0.0338, 0.3866, 0.2819, 0.0884, 0.1061, 0.0447, 0.6648,\n","                      0.3858, 0.0422, 0.2861, 0.1336, 0.1342, 0.2933, 0.2149, 0.0650, 0.3233,\n","                      0.6522, 0.0535, 0.1962])),\n","             ('incept2.conv3.bn.num_batches_tracked', tensor(4157)),\n","             ('downsample1.conv.conv.weight',\n","              tensor([[[[-1.7540e-02,  3.1655e-02, -2.1999e-02],\n","                        [-7.9466e-03, -1.5674e-02,  3.0853e-02],\n","                        [ 1.9224e-02, -3.0245e-02,  2.8989e-02]],\n","              \n","                       [[-4.6498e-02, -2.3339e-02, -1.4465e-02],\n","                        [ 1.3957e-02, -4.5758e-02,  8.4876e-03],\n","                        [-3.2835e-02, -6.8343e-02, -1.4186e-02]],\n","              \n","                       [[-4.0682e-02,  8.4831e-03, -2.1353e-02],\n","                        [-8.4773e-03, -5.9770e-02,  3.4985e-02],\n","                        [-4.3047e-02,  9.1597e-03,  3.7318e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 8.6718e-03, -3.3994e-02, -4.7948e-02],\n","                        [ 2.9442e-02, -9.8771e-03, -9.2279e-03],\n","                        [ 7.4003e-03, -4.0719e-02,  2.9900e-02]],\n","              \n","                       [[ 9.5541e-03,  7.8728e-03, -1.2519e-02],\n","                        [ 1.3729e-02,  1.1511e-02,  1.8940e-03],\n","                        [-7.5734e-03, -2.4744e-02,  6.8937e-03]],\n","              \n","                       [[-3.0698e-02, -2.4402e-02, -3.7960e-02],\n","                        [ 6.0129e-02,  2.4720e-02,  1.3486e-03],\n","                        [-4.6618e-02,  1.1355e-02, -2.2971e-02]]],\n","              \n","              \n","                      [[[ 9.6226e-03,  1.8990e-03,  1.5928e-02],\n","                        [ 2.4328e-03,  2.3233e-02,  1.6879e-02],\n","                        [ 3.3967e-02,  3.4762e-02,  6.9207e-03]],\n","              \n","                       [[-4.9968e-02,  1.7403e-02,  1.5385e-02],\n","                        [ 8.0616e-03,  4.1368e-02,  5.1266e-03],\n","                        [ 3.4169e-02, -1.5097e-02,  1.8915e-03]],\n","              \n","                       [[-1.2121e-02, -2.5774e-02, -2.0310e-03],\n","                        [ 5.7467e-03,  4.5853e-02,  2.6566e-02],\n","                        [ 5.3312e-02,  8.8822e-03, -2.6614e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 5.2201e-02, -1.0659e-02,  4.7399e-02],\n","                        [ 8.2472e-03,  6.8597e-02, -1.7862e-02],\n","                        [ 2.4902e-02,  2.1792e-03,  5.0325e-02]],\n","              \n","                       [[ 1.7025e-02, -3.7001e-04, -2.7713e-03],\n","                        [ 1.2737e-02, -2.2039e-02,  1.3792e-02],\n","                        [-3.8371e-03,  3.6812e-02,  2.8111e-02]],\n","              \n","                       [[ 4.6057e-02,  4.7340e-03,  1.1725e-02],\n","                        [-2.6222e-02,  3.9828e-02, -1.1337e-02],\n","                        [ 2.0788e-02,  5.5738e-02, -2.5272e-02]]],\n","              \n","              \n","                      [[[-2.2992e-02,  1.8018e-02,  2.0177e-02],\n","                        [ 1.0433e-02, -2.0504e-02, -1.0701e-02],\n","                        [-3.5199e-02,  8.7802e-03, -2.2039e-02]],\n","              \n","                       [[-6.6656e-03, -1.6704e-02,  3.5190e-02],\n","                        [ 2.1382e-02, -3.1180e-02,  1.1968e-02],\n","                        [ 1.5578e-02,  3.1710e-02,  3.3993e-02]],\n","              \n","                       [[-1.9292e-02,  3.2324e-02, -2.1564e-03],\n","                        [ 3.5573e-03, -3.6591e-02,  2.0836e-02],\n","                        [ 7.8789e-03,  1.0449e-02, -2.4277e-02]],\n","              \n","                       ...,\n","              \n","                       [[-1.7965e-02, -2.8555e-02, -5.7848e-03],\n","                        [-1.9525e-02,  3.0222e-02,  2.8591e-02],\n","                        [ 2.1182e-02, -1.6518e-02, -1.1645e-03]],\n","              \n","                       [[-3.7309e-03,  2.0766e-02,  3.3549e-02],\n","                        [ 9.3193e-03, -9.5445e-03, -1.2704e-02],\n","                        [-6.4507e-03, -2.2509e-02, -2.9881e-02]],\n","              \n","                       [[ 3.2153e-02, -7.7146e-03, -3.4602e-03],\n","                        [-2.4242e-02, -1.7326e-02, -1.7046e-02],\n","                        [ 9.2661e-03,  1.5023e-02,  2.6761e-02]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 1.4231e-02, -1.9907e-02, -3.1558e-03],\n","                        [-9.2814e-03,  3.2191e-02,  5.0958e-04],\n","                        [-3.4683e-02, -3.3664e-02,  2.2993e-02]],\n","              \n","                       [[-8.4914e-03,  1.9414e-02, -1.3303e-02],\n","                        [-3.5167e-02,  1.8256e-02, -2.4245e-02],\n","                        [ 2.8203e-02, -1.4113e-02, -3.6963e-02]],\n","              \n","                       [[ 3.1204e-02, -3.1264e-03,  1.7553e-02],\n","                        [ 2.9956e-02,  2.2338e-03,  1.7618e-02],\n","                        [ 9.5521e-05,  3.3574e-02, -3.0917e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 2.2935e-02,  1.8079e-02,  1.6103e-02],\n","                        [-3.5577e-02,  3.8683e-02, -2.4759e-02],\n","                        [ 1.6972e-02,  2.5075e-02,  7.8336e-03]],\n","              \n","                       [[ 2.0417e-03,  2.8635e-02, -2.9563e-02],\n","                        [ 5.7857e-03,  1.5469e-02,  2.7016e-03],\n","                        [ 3.5610e-02, -1.5927e-02,  2.8349e-03]],\n","              \n","                       [[ 2.1165e-02, -1.3038e-02,  1.9212e-02],\n","                        [ 1.7331e-02,  1.1389e-02, -2.3558e-03],\n","                        [ 1.2888e-02,  3.0941e-02,  3.8224e-03]]],\n","              \n","              \n","                      [[[ 3.6790e-02,  3.1792e-02, -1.7912e-02],\n","                        [-1.1733e-02,  7.4242e-03,  3.6729e-03],\n","                        [ 1.7673e-02,  1.9344e-02, -6.9545e-03]],\n","              \n","                       [[-3.2176e-02, -1.5662e-02,  4.7573e-03],\n","                        [-7.6895e-03,  3.8937e-02,  2.2245e-02],\n","                        [-1.8953e-02, -4.0071e-03, -8.8180e-03]],\n","              \n","                       [[-4.5377e-02, -4.6518e-02, -2.6419e-02],\n","                        [-5.2986e-02, -1.6555e-02,  1.0377e-03],\n","                        [ 1.6268e-02,  5.7773e-02, -2.7394e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 3.4629e-02,  1.4786e-02, -5.0581e-02],\n","                        [-1.9189e-02, -3.0259e-03,  3.2717e-02],\n","                        [-8.7194e-02, -2.9834e-02,  4.1151e-02]],\n","              \n","                       [[ 1.4693e-04, -2.5937e-02, -1.2650e-02],\n","                        [ 1.5761e-02,  3.1783e-02,  4.4962e-03],\n","                        [-2.3314e-02,  3.1723e-02,  2.5150e-02]],\n","              \n","                       [[-1.9131e-02,  1.9924e-02, -1.0066e-02],\n","                        [-5.6211e-03,  2.5571e-02,  5.6906e-02],\n","                        [ 3.5489e-02,  2.9749e-02,  3.7404e-02]]],\n","              \n","              \n","                      [[[ 3.5682e-02, -1.4685e-02, -3.0362e-02],\n","                        [ 1.0364e-02,  5.0332e-03,  3.2017e-03],\n","                        [ 6.3839e-03,  1.6134e-03, -7.3226e-03]],\n","              \n","                       [[ 4.2146e-02, -1.0130e-02, -1.1546e-03],\n","                        [-2.8636e-02, -1.2979e-02,  1.4865e-02],\n","                        [ 1.2317e-03,  1.4076e-02,  2.3157e-03]],\n","              \n","                       [[-4.3145e-02,  1.1734e-04,  2.8843e-02],\n","                        [-4.3532e-02, -1.8725e-02,  1.9148e-02],\n","                        [-4.3423e-02,  7.8278e-03, -3.1980e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 2.4533e-02, -1.8812e-02,  3.0041e-02],\n","                        [ 2.1946e-02, -2.5951e-02, -5.2120e-02],\n","                        [ 3.6189e-02,  6.4870e-03, -1.7106e-02]],\n","              \n","                       [[-3.4396e-02,  3.0348e-03, -7.9649e-03],\n","                        [ 2.7554e-02, -3.1882e-03,  9.5314e-03],\n","                        [ 1.6260e-02,  1.5431e-02, -1.9353e-02]],\n","              \n","                       [[ 2.4162e-02, -5.9557e-03,  2.9160e-02],\n","                        [-2.4853e-02,  1.8472e-02, -2.1101e-02],\n","                        [-2.2302e-02, -1.2093e-02, -1.6633e-03]]]])),\n","             ('downsample1.conv.conv.bias',\n","              tensor([ 0.0352, -0.0246, -0.0126,  0.0315,  0.0343, -0.0026,  0.0274,  0.0243,\n","                       0.0256,  0.0040,  0.0299,  0.0191, -0.0087, -0.0174, -0.0073, -0.0048,\n","                      -0.0010,  0.0326, -0.0034, -0.0276,  0.0287, -0.0310, -0.0326,  0.0142,\n","                      -0.0257,  0.0291,  0.0272, -0.0009, -0.0095, -0.0352, -0.0201, -0.0297,\n","                       0.0219, -0.0320,  0.0125, -0.0323,  0.0180, -0.0148,  0.0014, -0.0092,\n","                       0.0068, -0.0226, -0.0228, -0.0216,  0.0259, -0.0064, -0.0017,  0.0148,\n","                       0.0073, -0.0343,  0.0291,  0.0281, -0.0124, -0.0076, -0.0148, -0.0002,\n","                       0.0298, -0.0005,  0.0023,  0.0205, -0.0231,  0.0032, -0.0326,  0.0230,\n","                      -0.0133,  0.0300,  0.0158, -0.0117, -0.0276, -0.0039, -0.0049,  0.0064,\n","                       0.0318,  0.0001, -0.0328,  0.0175,  0.0372,  0.0154, -0.0029, -0.0323])),\n","             ('downsample1.conv.bn.weight',\n","              tensor([7.8726e-01, 8.1739e-01, 3.9148e-02, 3.5059e-01, 1.9962e-01, 9.4520e-01,\n","                      6.5123e-01, 2.3201e-01, 4.0901e-04, 4.9680e-01, 2.5741e-01, 1.3294e-01,\n","                      2.9973e-01, 3.6790e-01, 5.4053e-01, 1.2293e-01, 4.0937e-01, 5.2150e-01,\n","                      4.3835e-01, 3.2422e-01, 6.7556e-01, 7.3121e-01, 7.5594e-01, 4.1245e-01,\n","                      2.9756e-01, 3.1456e-01, 8.7947e-01, 5.6892e-01, 5.7332e-01, 6.0665e-01,\n","                      2.8694e-01, 3.5552e-01, 5.7951e-01, 7.7777e-01, 4.8577e-01, 7.1343e-01,\n","                      7.3538e-01, 8.1778e-01, 7.7101e-01, 6.1551e-01, 3.6649e-01, 2.0350e-01,\n","                      6.8473e-01, 5.4156e-01, 3.3664e-02, 1.8741e-01, 8.6201e-01, 1.9796e-01,\n","                      9.6377e-01, 9.9415e-01, 9.3266e-01, 8.9893e-01, 2.1857e-01, 9.7604e-01,\n","                      5.9062e-01, 8.9458e-01, 7.4308e-01, 3.4518e-01, 8.5959e-01, 8.3640e-01,\n","                      8.1974e-02, 4.8488e-01, 5.5920e-01, 3.7225e-01, 3.5557e-01, 9.5308e-01,\n","                      2.5076e-01, 7.9238e-01, 7.8879e-01, 7.0720e-01, 6.8515e-01, 1.7522e-01,\n","                      5.5721e-01, 8.7204e-01, 9.6092e-01, 1.7900e-01, 5.0075e-01, 4.1755e-02,\n","                      8.1739e-01, 3.4804e-01])),\n","             ('downsample1.conv.bn.bias',\n","              tensor([-0.0343, -0.0437,  0.0061,  0.0039,  0.0032, -0.0492, -0.0273,  0.0140,\n","                      -0.0030,  0.0083,  0.0132,  0.0148, -0.0198,  0.0211, -0.0118, -0.0040,\n","                       0.0004,  0.0172,  0.0232,  0.0064, -0.0010, -0.0422, -0.0010, -0.0013,\n","                       0.0170, -0.0112, -0.0659, -0.0220,  0.0001, -0.0651, -0.0111, -0.0093,\n","                      -0.0180, -0.0123, -0.0216, -0.0092, -0.0176, -0.0277, -0.0292, -0.0140,\n","                      -0.0105,  0.0105, -0.0137, -0.0186, -0.0138,  0.0029, -0.0409, -0.0022,\n","                      -0.0491, -0.0085, -0.0590, -0.0516,  0.0081, -0.0350, -0.0104, -0.0288,\n","                      -0.0446,  0.0130, -0.0451, -0.0396, -0.0144, -0.0290,  0.0177, -0.0188,\n","                      -0.0056, -0.0916,  0.0125, -0.0080,  0.0111, -0.0333,  0.0115, -0.0036,\n","                      -0.0390, -0.0531, -0.0527, -0.0129,  0.0128, -0.0050, -0.0258, -0.0248])),\n","             ('downsample1.conv.bn.running_mean',\n","              tensor([-0.1410,  0.6894,  0.0985,  0.2095, -0.0623,  0.0403,  0.0930,  0.0851,\n","                      -0.0405,  0.2667, -0.1455,  0.0247, -0.0061,  0.0234, -0.0950,  0.0528,\n","                      -0.0252,  0.0308, -0.5914, -0.1576, -0.2073,  0.4668, -0.4334,  0.0264,\n","                      -0.0986,  0.0213,  0.1708,  0.0282, -0.7492,  0.3423,  0.1157, -0.0221,\n","                       0.2280, -0.0560, -0.0491, -0.3879, -0.0109, -0.1004, -0.0958, -0.0056,\n","                       0.0496, -0.0822, -0.1172,  0.3215,  0.0895,  0.0449,  0.3142, -0.1592,\n","                       0.1661, -0.5012,  0.2377, -0.0193,  0.0475, -0.5686, -0.2899,  0.1581,\n","                       0.0106,  0.1241, -0.1382, -0.2586,  0.0639,  0.1311, -0.0371, -0.0793,\n","                       0.1668, -0.1758,  0.1520, -0.0832, -0.5458, -0.2597, -0.5297, -0.0602,\n","                       0.1568, -0.1467, -0.4623, -0.2035,  0.2002,  0.1372, -0.5232, -0.2547])),\n","             ('downsample1.conv.bn.running_var',\n","              tensor([0.1457, 0.1723, 0.0277, 0.0542, 0.0416, 0.2697, 0.1149, 0.0376, 0.0261,\n","                      0.0841, 0.0342, 0.0302, 0.0407, 0.0663, 0.0765, 0.0320, 0.0545, 0.0704,\n","                      0.0731, 0.0342, 0.0911, 0.1206, 0.1356, 0.0738, 0.0359, 0.0407, 0.1656,\n","                      0.1110, 0.1135, 0.1028, 0.0559, 0.0624, 0.1121, 0.1071, 0.1015, 0.1203,\n","                      0.1115, 0.1633, 0.1251, 0.1152, 0.0540, 0.0349, 0.1442, 0.0963, 0.0279,\n","                      0.0394, 0.1449, 0.0374, 0.1734, 0.2176, 0.1284, 0.1650, 0.0409, 0.1682,\n","                      0.0870, 0.1593, 0.1250, 0.0660, 0.1371, 0.1526, 0.0279, 0.0824, 0.1004,\n","                      0.0562, 0.0441, 0.1787, 0.0510, 0.1493, 0.1199, 0.1200, 0.1180, 0.0351,\n","                      0.1271, 0.1723, 0.1362, 0.0379, 0.1000, 0.0282, 0.1554, 0.0533])),\n","             ('downsample1.conv.bn.num_batches_tracked', tensor(4157)),\n","             ('incept3.conv1.conv.weight', tensor([[[[-0.0576]],\n","              \n","                       [[-0.0913]],\n","              \n","                       [[-0.0587]],\n","              \n","                       ...,\n","              \n","                       [[ 0.1118]],\n","              \n","                       [[ 0.0715]],\n","              \n","                       [[ 0.0282]]],\n","              \n","              \n","                      [[[-0.1026]],\n","              \n","                       [[-0.1081]],\n","              \n","                       [[ 0.0543]],\n","              \n","                       ...,\n","              \n","                       [[ 0.1305]],\n","              \n","                       [[ 0.0385]],\n","              \n","                       [[ 0.0146]]],\n","              \n","              \n","                      [[[-0.0042]],\n","              \n","                       [[ 0.0777]],\n","              \n","                       [[-0.0727]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0572]],\n","              \n","                       [[-0.0300]],\n","              \n","                       [[-0.0031]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[-0.1306]],\n","              \n","                       [[-0.1012]],\n","              \n","                       [[ 0.0267]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0846]],\n","              \n","                       [[-0.0551]],\n","              \n","                       [[-0.1052]]],\n","              \n","              \n","                      [[[ 0.0693]],\n","              \n","                       [[-0.0554]],\n","              \n","                       [[ 0.0006]],\n","              \n","                       ...,\n","              \n","                       [[-0.0049]],\n","              \n","                       [[ 0.0733]],\n","              \n","                       [[-0.0076]]],\n","              \n","              \n","                      [[[-0.0477]],\n","              \n","                       [[-0.0209]],\n","              \n","                       [[ 0.0544]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0303]],\n","              \n","                       [[-0.0136]],\n","              \n","                       [[-0.0164]]]])),\n","             ('incept3.conv1.conv.bias',\n","              tensor([-0.0269, -0.0466, -0.0563,  0.0457,  0.0712,  0.0021, -0.0267, -0.0535,\n","                      -0.0485, -0.0720, -0.0431, -0.0446,  0.0673,  0.0612,  0.0401,  0.0622,\n","                       0.0338,  0.0261,  0.0659,  0.0635,  0.0163, -0.0757, -0.0446,  0.0282,\n","                       0.0123, -0.0421,  0.0059, -0.0677, -0.0572,  0.0416, -0.0022, -0.0370,\n","                       0.0293, -0.0776,  0.0288,  0.0137,  0.0311, -0.0687, -0.0013,  0.0659,\n","                       0.0064,  0.0399,  0.0595,  0.0039,  0.0221,  0.0657, -0.0515, -0.0584,\n","                       0.0194,  0.0288,  0.0368,  0.0683, -0.0658, -0.0332,  0.0754,  0.0134,\n","                       0.0011,  0.0638,  0.0697, -0.0703, -0.0305, -0.0407,  0.0331,  0.0109,\n","                       0.0522, -0.0073, -0.0721,  0.0078, -0.0149, -0.0315,  0.0553, -0.0060,\n","                       0.0429, -0.0121,  0.0626, -0.0394, -0.0154, -0.0552, -0.0082, -0.0257,\n","                       0.0743, -0.0444,  0.0724, -0.0016,  0.0381,  0.0368, -0.0021, -0.0317,\n","                       0.0095,  0.0142,  0.0625, -0.0696,  0.0067,  0.0261,  0.0644,  0.0091,\n","                      -0.0661, -0.0139,  0.0454,  0.0596, -0.0508, -0.0536,  0.0638,  0.0190,\n","                       0.0779, -0.0588, -0.0027, -0.0665, -0.0428, -0.0212,  0.0372, -0.0477])),\n","             ('incept3.conv1.bn.weight',\n","              tensor([0.8766, 0.8027, 0.0706, 0.7182, 0.7458, 0.8193, 0.7659, 0.5171, 0.2936,\n","                      0.6695, 0.6454, 0.2571, 0.8639, 0.1951, 0.4643, 0.5287, 0.4552, 0.4478,\n","                      0.2082, 0.0336, 0.1868, 0.4326, 0.6160, 0.7735, 0.2682, 0.4661, 0.5001,\n","                      0.6293, 0.7448, 0.8377, 0.5808, 0.0452, 0.8249, 0.6255, 0.2455, 0.8061,\n","                      0.4291, 0.8191, 0.0814, 0.6181, 0.9540, 0.2444, 0.5577, 0.5862, 0.1892,\n","                      0.6005, 0.1635, 0.2751, 0.3488, 0.8131, 0.9380, 0.0060, 0.6469, 0.4592,\n","                      0.8825, 0.8232, 0.4983, 0.8838, 0.0937, 0.3404, 0.0265, 0.6684, 0.2431,\n","                      0.8410, 0.3773, 0.6721, 0.9429, 0.3322, 0.6698, 0.3612, 0.4122, 0.5256,\n","                      0.0277, 0.5858, 0.7496, 0.4563, 0.0461, 0.7475, 0.1211, 0.6739, 0.7286,\n","                      0.6180, 0.4969, 0.3817, 0.5549, 0.3074, 0.3997, 0.6617, 0.7166, 0.6009,\n","                      0.1178, 0.5222, 0.7948, 0.4669, 0.5080, 0.5181, 0.0326, 0.4966, 0.3055,\n","                      0.5874, 0.3649, 0.7861, 0.6940, 0.8841, 0.1664, 0.8241, 0.2341, 0.7711,\n","                      0.6105, 0.7106, 0.5319, 0.4153])),\n","             ('incept3.conv1.bn.bias',\n","              tensor([-0.1069, -0.0482,  0.0100, -0.0011, -0.0449, -0.0689, -0.0708, -0.0080,\n","                       0.0034, -0.0436, -0.0585, -0.0222, -0.0626,  0.0017, -0.0293, -0.0141,\n","                      -0.0527, -0.0365,  0.0238, -0.0289, -0.0046, -0.0074, -0.0368, -0.0263,\n","                       0.0017,  0.0099, -0.0616, -0.1039, -0.0874, -0.0714, -0.0299, -0.0052,\n","                      -0.0399, -0.0386,  0.0287, -0.0420, -0.0145, -0.0990,  0.0128, -0.0052,\n","                      -0.0644, -0.0164,  0.0002, -0.0524,  0.0210, -0.0399, -0.0112, -0.0129,\n","                       0.0222, -0.0618, -0.0456, -0.0076, -0.0323, -0.0346, -0.0606, -0.0987,\n","                      -0.0567, -0.0691, -0.0030, -0.0249,  0.0117, -0.0654, -0.0129, -0.1448,\n","                      -0.0316, -0.0797, -0.0471,  0.0222, -0.0599, -0.0114, -0.0275, -0.0979,\n","                      -0.0181, -0.0370, -0.0324, -0.0547,  0.0209, -0.0113,  0.0087, -0.0076,\n","                      -0.0193, -0.0902, -0.0518, -0.0087, -0.0245,  0.0242,  0.0179, -0.0177,\n","                       0.0014, -0.0274,  0.0155, -0.0187, -0.0496, -0.0597, -0.0338, -0.0431,\n","                      -0.0181, -0.0308,  0.0010, -0.0351, -0.0303, -0.0688, -0.0644, -0.0358,\n","                       0.0177, -0.0580, -0.0181, -0.0944, -0.0621, -0.0610, -0.0365, -0.0197])),\n","             ('incept3.conv1.bn.running_mean',\n","              tensor([ 0.9727, -0.1346,  0.0053, -0.2934, -0.6001, -0.7716, -0.2573, -0.2751,\n","                      -0.3743,  0.1332, -0.3205,  0.0515, -0.2594, -0.1371,  0.2141,  0.2246,\n","                      -0.1766,  0.1563,  0.0915, -0.2067, -0.0551, -0.3449, -0.3229, -0.5731,\n","                      -0.1137, -0.0743,  0.6690,  0.3158,  0.3683,  0.2513, -0.0184, -0.0719,\n","                      -0.1807, -0.2362, -0.1166,  0.3599,  0.2222,  0.8455,  0.2429, -0.0664,\n","                      -0.2897, -0.2553,  0.0283,  0.2269,  0.1778,  0.0756, -0.0778,  0.1738,\n","                       0.1301,  0.6532, -0.0461,  0.0525, -0.2326, -0.0602, -0.1140,  0.7281,\n","                       0.3288, -0.5991, -0.0392,  0.1483, -0.5102,  0.0695,  0.1339,  0.1333,\n","                       0.1041,  0.5351, -0.3129,  0.1974, -0.6484, -0.3174,  0.0479,  0.5501,\n","                       0.1370,  0.6022, -0.5935,  0.4267, -0.2902, -0.9261, -0.2178, -0.7089,\n","                      -0.3871,  0.2769,  0.0677, -0.2794, -0.7796, -0.1464, -0.1796, -0.0442,\n","                      -0.3163,  0.6275, -0.2293, -0.6611, -0.4598,  0.1269, -0.3304,  0.2680,\n","                      -0.4379,  0.2233,  0.1365, -0.5962,  0.1392, -0.4360,  0.2188, -0.3046,\n","                      -0.0153, -0.7072, -0.1155, -0.0089,  0.1930,  0.2238,  0.4021, -0.3113])),\n","             ('incept3.conv1.bn.running_var',\n","              tensor([0.2368, 0.1537, 0.0639, 0.1491, 0.1735, 0.1566, 0.1301, 0.0837, 0.0500,\n","                      0.0950, 0.1039, 0.0534, 0.2007, 0.0580, 0.0474, 0.0671, 0.0659, 0.0561,\n","                      0.0317, 0.0445, 0.0529, 0.0768, 0.1076, 0.1372, 0.0480, 0.0826, 0.1102,\n","                      0.1129, 0.1361, 0.1594, 0.1049, 0.0687, 0.1524, 0.1000, 0.0528, 0.1428,\n","                      0.0807, 0.2213, 0.0548, 0.1007, 0.1671, 0.0619, 0.0928, 0.1101, 0.0404,\n","                      0.1348, 0.0371, 0.0437, 0.0527, 0.1433, 0.2153, 0.0514, 0.1067, 0.0931,\n","                      0.1722, 0.2109, 0.0753, 0.2122, 0.0496, 0.0564, 0.0934, 0.1389, 0.0433,\n","                      0.1419, 0.0699, 0.1199, 0.1819, 0.0546, 0.1468, 0.0426, 0.0678, 0.0996,\n","                      0.0664, 0.1132, 0.1325, 0.0745, 0.0640, 0.1494, 0.0405, 0.1329, 0.1441,\n","                      0.1052, 0.0690, 0.0695, 0.1490, 0.0630, 0.0605, 0.0837, 0.1343, 0.1207,\n","                      0.0578, 0.0860, 0.1490, 0.0908, 0.0860, 0.0869, 0.0753, 0.1070, 0.0538,\n","                      0.1096, 0.0580, 0.1462, 0.1091, 0.1175, 0.0368, 0.1533, 0.0504, 0.1408,\n","                      0.1267, 0.1068, 0.0991, 0.0616])),\n","             ('incept3.conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept3.conv3.conv.weight',\n","              tensor([[[[-2.9167e-02, -2.1241e-02,  3.3456e-03],\n","                        [-6.1781e-03, -1.5023e-02, -1.4475e-02],\n","                        [ 2.2485e-03, -2.4069e-02,  1.4232e-02]],\n","              \n","                       [[ 1.9840e-02,  1.9676e-02, -2.4174e-02],\n","                        [ 1.0924e-02, -1.9067e-02,  3.2859e-03],\n","                        [-3.6607e-03,  2.5908e-02,  7.0943e-03]],\n","              \n","                       [[ 5.6196e-03,  2.6589e-02,  1.3994e-02],\n","                        [-2.6816e-03,  1.5646e-02, -1.9670e-02],\n","                        [-1.1289e-02, -1.1653e-02,  2.1496e-03]],\n","              \n","                       ...,\n","              \n","                       [[-1.6774e-02, -2.1690e-02,  5.3079e-03],\n","                        [ 1.9247e-02,  1.6970e-02,  5.6258e-03],\n","                        [ 2.9318e-03, -2.3285e-02, -3.4363e-03]],\n","              \n","                       [[ 1.9520e-02,  1.5325e-02,  5.0002e-03],\n","                        [-2.3342e-02, -3.1803e-03,  1.1889e-02],\n","                        [ 9.8853e-03,  1.8072e-02,  6.8510e-03]],\n","              \n","                       [[ 2.8604e-02,  9.8452e-03, -6.0978e-04],\n","                        [ 2.1434e-02,  2.4879e-02,  5.4705e-03],\n","                        [-1.5637e-02,  1.5564e-02, -6.9076e-03]]],\n","              \n","              \n","                      [[[ 4.5002e-02,  2.4635e-02, -2.4243e-02],\n","                        [-3.6527e-03,  4.1690e-04, -2.6645e-02],\n","                        [-7.9336e-03,  1.0731e-02, -4.8306e-02]],\n","              \n","                       [[-3.5325e-03,  2.4359e-03, -4.8119e-02],\n","                        [ 7.6803e-03, -2.2211e-02, -2.2513e-02],\n","                        [ 9.2442e-03,  2.8644e-02, -5.3383e-03]],\n","              \n","                       [[-1.3076e-02, -2.1978e-02, -2.4368e-02],\n","                        [ 2.6332e-03,  2.5675e-03, -1.0689e-02],\n","                        [-1.1217e-03,  1.3462e-02, -5.2978e-03]],\n","              \n","                       ...,\n","              \n","                       [[-4.4706e-03, -2.2211e-02,  7.5894e-02],\n","                        [-2.4200e-02, -1.2077e-02,  1.0356e-01],\n","                        [-2.9064e-03,  2.1853e-02,  5.7318e-02]],\n","              \n","                       [[ 5.3504e-03, -2.1235e-02, -1.6746e-02],\n","                        [ 1.1969e-02, -2.4598e-02,  1.3137e-02],\n","                        [-3.5128e-02, -3.5868e-03,  3.5316e-02]],\n","              \n","                       [[ 2.1116e-04,  1.6496e-02,  2.2537e-02],\n","                        [-1.7206e-02,  8.2113e-03,  2.2440e-02],\n","                        [ 1.7171e-02,  3.0388e-03,  4.7478e-03]]],\n","              \n","              \n","                      [[[-2.2206e-03, -2.2427e-02,  8.8851e-03],\n","                        [ 1.6707e-03,  7.7165e-03, -1.8023e-02],\n","                        [ 6.9430e-03,  2.1473e-03,  1.1196e-02]],\n","              \n","                       [[-5.5643e-03, -4.7968e-03, -3.5441e-02],\n","                        [ 9.0279e-03,  3.3238e-03,  2.3332e-02],\n","                        [ 1.0754e-02,  9.5578e-03, -9.8143e-03]],\n","              \n","                       [[-1.4234e-02,  3.0677e-03, -2.2917e-03],\n","                        [-2.3323e-02,  2.7774e-03,  4.8839e-03],\n","                        [-2.2673e-02, -1.6117e-02,  1.4992e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 6.1409e-03,  4.3053e-03,  1.9635e-02],\n","                        [ 6.6684e-03,  4.7235e-03, -3.0068e-03],\n","                        [ 3.2446e-02,  3.6953e-02,  6.1789e-03]],\n","              \n","                       [[ 2.3357e-02, -8.2136e-03,  1.9391e-02],\n","                        [ 1.5785e-03, -7.5391e-03,  1.9489e-02],\n","                        [-1.6850e-02,  1.0263e-02, -1.0975e-02]],\n","              \n","                       [[ 1.4482e-02, -1.6356e-03, -3.4246e-02],\n","                        [-3.1839e-02, -1.4113e-02,  1.6084e-02],\n","                        [ 5.3620e-03,  6.5785e-03, -5.1431e-03]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 2.4292e-02, -4.0488e-02,  1.5968e-02],\n","                        [-1.4397e-02, -2.2215e-02,  2.1831e-02],\n","                        [-2.7416e-02, -2.9590e-02, -1.0332e-02]],\n","              \n","                       [[-2.9112e-02,  2.0052e-03,  1.6768e-02],\n","                        [ 4.2631e-02, -3.1588e-03,  3.5913e-02],\n","                        [-2.4485e-02, -9.2364e-03, -9.8032e-03]],\n","              \n","                       [[-2.2399e-03, -3.3799e-03, -1.5948e-02],\n","                        [-4.5021e-04,  1.9338e-02,  7.6401e-05],\n","                        [ 1.0123e-02,  2.5767e-03, -2.2342e-02]],\n","              \n","                       ...,\n","              \n","                       [[-1.3781e-02, -1.2586e-02, -5.0606e-02],\n","                        [-2.1573e-03,  2.0735e-03, -4.8115e-02],\n","                        [-1.0120e-02, -3.1871e-02, -4.7841e-02]],\n","              \n","                       [[ 1.4087e-04,  1.6488e-02, -1.7836e-02],\n","                        [ 9.3424e-03,  3.2214e-02,  7.6947e-03],\n","                        [-7.7724e-03,  3.6529e-03, -8.5296e-03]],\n","              \n","                       [[ 3.3029e-02,  5.3641e-02,  6.6372e-02],\n","                        [-5.1705e-03,  3.2951e-02,  3.3137e-02],\n","                        [ 2.8654e-03, -2.7707e-02,  1.6951e-02]]],\n","              \n","              \n","                      [[[-1.9042e-03, -6.9391e-03,  2.1441e-02],\n","                        [ 1.6568e-02, -1.3191e-02, -2.9286e-03],\n","                        [-5.0533e-02, -1.9185e-02, -1.2498e-02]],\n","              \n","                       [[-5.0171e-04,  3.6137e-02, -4.3217e-02],\n","                        [ 6.7220e-04,  2.7100e-04, -1.6091e-02],\n","                        [-1.6169e-02, -1.8811e-02, -2.7077e-02]],\n","              \n","                       [[ 3.4529e-03,  2.0336e-02, -9.9916e-04],\n","                        [ 2.6744e-02, -4.8507e-03, -1.3408e-02],\n","                        [-2.6127e-02,  9.8139e-03,  1.2341e-02]],\n","              \n","                       ...,\n","              \n","                       [[-2.4313e-02,  3.1516e-02, -3.0158e-02],\n","                        [-3.9794e-02, -2.3759e-03,  4.0972e-02],\n","                        [-2.9503e-02, -7.8145e-04,  3.9149e-02]],\n","              \n","                       [[ 1.2844e-02,  1.6410e-03, -7.1544e-04],\n","                        [ 3.1668e-04, -1.1982e-02, -2.3816e-02],\n","                        [ 7.5918e-03, -2.0553e-02, -2.5148e-02]],\n","              \n","                       [[-7.5144e-03,  2.4280e-02,  2.5171e-02],\n","                        [ 9.8964e-03,  1.1335e-03,  6.0579e-03],\n","                        [-4.2241e-02, -1.0016e-02,  1.3985e-02]]],\n","              \n","              \n","                      [[[-8.1515e-03,  1.2636e-02, -7.7034e-03],\n","                        [-5.3571e-03, -2.5552e-02, -1.3005e-02],\n","                        [ 3.7174e-02, -3.0250e-02, -6.1725e-03]],\n","              \n","                       [[-1.3511e-02, -3.2193e-02, -3.0925e-02],\n","                        [-1.5864e-02, -3.4228e-02, -3.7977e-02],\n","                        [-7.8120e-03, -1.4629e-03, -1.7033e-02]],\n","              \n","                       [[ 4.3404e-03, -1.4818e-02,  6.5889e-03],\n","                        [-1.5338e-02,  2.5151e-02, -1.7227e-02],\n","                        [ 1.1742e-02,  1.7745e-02, -8.5079e-03]],\n","              \n","                       ...,\n","              \n","                       [[-3.9591e-03,  3.8638e-03,  3.7749e-02],\n","                        [-5.1911e-02,  2.2429e-02,  2.0352e-02],\n","                        [-2.5584e-02,  8.0287e-03,  7.7136e-02]],\n","              \n","                       [[-8.3281e-03,  2.5722e-02,  1.7841e-02],\n","                        [-1.0464e-02, -2.4467e-02,  9.7112e-04],\n","                        [ 3.5764e-03, -3.1086e-02,  7.2911e-03]],\n","              \n","                       [[-2.4352e-02, -2.6270e-02, -3.8765e-02],\n","                        [-2.3538e-02, -7.7324e-03, -2.4051e-02],\n","                        [ 3.0147e-03, -1.3699e-02,  1.6799e-02]]]])),\n","             ('incept3.conv3.conv.bias',\n","              tensor([-0.0043, -0.0175,  0.0158, -0.0160,  0.0261,  0.0043, -0.0221,  0.0083,\n","                       0.0008,  0.0211,  0.0098,  0.0071,  0.0066,  0.0101, -0.0012, -0.0244,\n","                      -0.0246, -0.0189,  0.0223, -0.0262, -0.0253, -0.0163, -0.0121, -0.0053,\n","                       0.0151, -0.0149, -0.0069, -0.0088, -0.0239, -0.0159,  0.0099,  0.0249,\n","                      -0.0225, -0.0218,  0.0153, -0.0191,  0.0178,  0.0158, -0.0056, -0.0061,\n","                      -0.0230,  0.0216, -0.0091, -0.0009, -0.0232,  0.0055, -0.0004, -0.0111])),\n","             ('incept3.conv3.bn.weight',\n","              tensor([0.2218, 0.7143, 0.2154, 0.2284, 0.7612, 0.8129, 0.0814, 0.1997, 0.3016,\n","                      0.5213, 0.2792, 0.2632, 0.2218, 0.7065, 0.1293, 0.3087, 0.4921, 0.0627,\n","                      0.2021, 0.0406, 0.9283, 0.3354, 0.4901, 0.5982, 0.2272, 0.6579, 0.0596,\n","                      0.4649, 0.1618, 0.9687, 0.9825, 0.9213, 0.5690, 0.5339, 0.8554, 0.2886,\n","                      0.2799, 0.9066, 0.6561, 0.4926, 0.6792, 0.5835, 0.7965, 0.6161, 0.7291,\n","                      0.6545, 0.5695, 0.4519])),\n","             ('incept3.conv3.bn.bias',\n","              tensor([-0.0306, -0.0483, -0.0272,  0.0096, -0.0426, -0.0622,  0.0032, -0.0149,\n","                      -0.0048,  0.0234, -0.0413,  0.0080, -0.0272, -0.0416,  0.0112, -0.0278,\n","                      -0.0356,  0.0011,  0.0125, -0.0048, -0.0194,  0.0015, -0.0554, -0.0047,\n","                      -0.0065, -0.0791,  0.0040, -0.0529,  0.0267, -0.0353, -0.0576, -0.0182,\n","                      -0.0376, -0.0840, -0.0635, -0.0028,  0.0187, -0.0894, -0.0050,  0.0136,\n","                      -0.0482, -0.0240, -0.0908, -0.0250, -0.0481, -0.0683, -0.0285,  0.0086])),\n","             ('incept3.conv3.bn.running_mean',\n","              tensor([ 0.1339,  0.0196,  0.1673,  0.1381, -1.7804, -0.2114, -0.1486, -0.1269,\n","                       0.4422,  0.0294, -0.0932,  0.1410, -0.1746, -0.1506, -0.1162,  0.2378,\n","                       0.0369, -0.1941,  0.1105, -0.0411, -1.1904,  0.5199,  0.0598, -0.4404,\n","                       0.4493, -0.5675, -0.3269, -0.0179, -0.2413, -0.2073, -2.6042, -0.6252,\n","                      -1.1427, -0.2773, -0.4316,  0.6731, -0.4155, -1.2311,  0.3002, -0.9175,\n","                      -0.5968, -0.0312, -0.2484, -0.9015,  0.2000, -0.3715, -0.1339,  0.0804])),\n","             ('incept3.conv3.bn.running_var',\n","              tensor([0.0878, 0.5738, 0.0888, 0.1090, 0.8182, 0.7991, 0.0537, 0.0896, 0.1732,\n","                      0.3153, 0.2618, 0.1286, 0.1041, 0.5723, 0.0688, 0.1243, 0.3856, 0.0499,\n","                      0.0870, 0.0434, 0.8142, 0.1571, 0.3313, 0.5812, 0.0886, 0.5437, 0.0543,\n","                      0.3149, 0.0945, 1.1725, 1.2189, 0.9700, 0.3280, 0.5519, 0.7086, 0.1488,\n","                      0.1502, 1.1105, 0.4035, 0.3124, 0.5133, 0.4064, 0.7125, 0.3480, 0.6549,\n","                      0.5086, 0.3547, 0.4006])),\n","             ('incept3.conv3.bn.num_batches_tracked', tensor(4157)),\n","             ('incept4.conv1.conv.weight', tensor([[[[-0.0805]],\n","              \n","                       [[ 0.0184]],\n","              \n","                       [[-0.0701]],\n","              \n","                       ...,\n","              \n","                       [[-0.0815]],\n","              \n","                       [[ 0.0389]],\n","              \n","                       [[ 0.0248]]],\n","              \n","              \n","                      [[[-0.0464]],\n","              \n","                       [[ 0.0474]],\n","              \n","                       [[-0.0491]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0459]],\n","              \n","                       [[-0.0362]],\n","              \n","                       [[ 0.0761]]],\n","              \n","              \n","                      [[[-0.0305]],\n","              \n","                       [[ 0.0331]],\n","              \n","                       [[-0.0164]],\n","              \n","                       ...,\n","              \n","                       [[-0.0236]],\n","              \n","                       [[ 0.0716]],\n","              \n","                       [[-0.0438]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[-0.0354]],\n","              \n","                       [[ 0.0043]],\n","              \n","                       [[-0.0593]],\n","              \n","                       ...,\n","              \n","                       [[-0.0812]],\n","              \n","                       [[-0.0958]],\n","              \n","                       [[-0.0103]]],\n","              \n","              \n","                      [[[-0.0755]],\n","              \n","                       [[ 0.0576]],\n","              \n","                       [[-0.0624]],\n","              \n","                       ...,\n","              \n","                       [[-0.0066]],\n","              \n","                       [[ 0.0150]],\n","              \n","                       [[ 0.0258]]],\n","              \n","              \n","                      [[[-0.0116]],\n","              \n","                       [[-0.0528]],\n","              \n","                       [[-0.0254]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0131]],\n","              \n","                       [[ 0.0369]],\n","              \n","                       [[-0.0012]]]])),\n","             ('incept4.conv1.conv.bias',\n","              tensor([ 0.0128,  0.0726, -0.0399,  0.0616,  0.0424, -0.0201,  0.0375,  0.0287,\n","                      -0.0235, -0.0457, -0.0426, -0.0474,  0.0040, -0.0543, -0.0663,  0.0230,\n","                      -0.0221,  0.0113, -0.0776, -0.0137, -0.0445, -0.0715, -0.0069,  0.0206,\n","                       0.0083,  0.0501, -0.0294, -0.0633,  0.0770,  0.0313, -0.0485, -0.0552,\n","                      -0.0700, -0.0418,  0.0045, -0.0137,  0.0738, -0.0497,  0.0384,  0.0551,\n","                       0.0725,  0.0287, -0.0581, -0.0301, -0.0201, -0.0692, -0.0011, -0.0222,\n","                       0.0367,  0.0231, -0.0392, -0.0539, -0.0012, -0.0489,  0.0398, -0.0109,\n","                      -0.0714,  0.0460,  0.0783, -0.0055,  0.0054,  0.0321,  0.0279,  0.0401,\n","                      -0.0590, -0.0753, -0.0353,  0.0762,  0.0416, -0.0072, -0.0537,  0.0110,\n","                      -0.0123, -0.0393, -0.0346, -0.0785,  0.0468, -0.0239, -0.0562, -0.0240,\n","                       0.0630, -0.0051, -0.0600, -0.0198, -0.0082,  0.0741,  0.0788,  0.0029,\n","                       0.0072, -0.0163, -0.0681,  0.0275, -0.0607,  0.0624, -0.0377,  0.0443])),\n","             ('incept4.conv1.bn.weight',\n","              tensor([0.8005, 0.4584, 0.4957, 0.6861, 0.1254, 0.6765, 0.8376, 0.9038, 0.6291,\n","                      0.2401, 0.4300, 0.1471, 0.1493, 0.1558, 0.7534, 0.4575, 0.0610, 0.1530,\n","                      0.7317, 0.1265, 0.5010, 0.3558, 0.4117, 0.5920, 0.7790, 0.3021, 0.3660,\n","                      0.1031, 0.3602, 0.0009, 0.6896, 0.3193, 0.3583, 0.0664, 0.6172, 0.7043,\n","                      0.7306, 0.7064, 0.2305, 0.8027, 0.3443, 0.6356, 0.7089, 0.1136, 0.7548,\n","                      0.0794, 0.5916, 0.3997, 0.3939, 0.7961, 0.6388, 0.7015, 0.3298, 0.7353,\n","                      0.4460, 0.6072, 0.2021, 0.6635, 0.2842, 0.1642, 0.2208, 0.6501, 0.5251,\n","                      0.5611, 0.0926, 0.8488, 0.8443, 0.2750, 0.2918, 0.0231, 0.5585, 0.1320,\n","                      0.3585, 0.6570, 0.7163, 0.5383, 0.5760, 0.3202, 0.7215, 0.9073, 0.7034,\n","                      0.1540, 0.2767, 0.3672, 0.4781, 0.3069, 0.5248, 0.7236, 0.8523, 0.1327,\n","                      0.8294, 0.7110, 0.5713, 0.9125, 0.0011, 0.5520])),\n","             ('incept4.conv1.bn.bias',\n","              tensor([-0.0581, -0.0408, -0.0708, -0.0728, -0.0122, -0.0459, -0.0741, -0.0419,\n","                      -0.0340,  0.0289,  0.0061,  0.0031,  0.0015, -0.0194, -0.0646, -0.0093,\n","                       0.0052,  0.0202, -0.1010, -0.0178, -0.0328, -0.0077, -0.0154, -0.0462,\n","                      -0.0750,  0.0026, -0.0048, -0.0048,  0.0099, -0.0037, -0.0705, -0.0175,\n","                      -0.0058,  0.0168, -0.0560, -0.1119, -0.0598, -0.0798, -0.0023, -0.0505,\n","                      -0.0011, -0.0730, -0.0732, -0.0131, -0.0789,  0.0007, -0.0667, -0.0383,\n","                       0.0050, -0.0766, -0.0093, -0.0756, -0.0463, -0.0579, -0.0243, -0.0135,\n","                      -0.0163, -0.0655, -0.0141, -0.0081, -0.0147, -0.0881, -0.0310, -0.0179,\n","                       0.0256, -0.0776, -0.0947,  0.0028,  0.0301,  0.0144, -0.0388,  0.0124,\n","                       0.0116, -0.0493, -0.0589, -0.0369, -0.0509, -0.0016, -0.0144, -0.0914,\n","                      -0.0459, -0.0055,  0.0227, -0.0235, -0.0400, -0.0185, -0.0168, -0.0797,\n","                      -0.0835,  0.0062, -0.0917, -0.0590, -0.0544, -0.0730, -0.0056, -0.0434])),\n","             ('incept4.conv1.bn.running_mean',\n","              tensor([ 0.0106,  0.0516, -0.1862, -0.2291,  0.0678, -0.3040, -0.0613,  0.0058,\n","                      -0.1171, -0.4410, -0.1258, -0.0239, -0.0188, -0.0367, -0.1414,  0.1967,\n","                      -0.0615, -0.1377, -0.1850, -0.2002, -0.0800,  0.0334,  0.0124, -0.0213,\n","                      -0.7319,  0.0307, -0.0320,  0.0746,  0.2651, -0.0947,  0.2353, -0.1551,\n","                      -0.2250,  0.0057,  0.1539,  0.0889,  0.0221, -0.2054,  0.1049,  0.0203,\n","                       0.0664, -0.2437, -0.1197, -0.0365,  0.2370, -0.1773, -0.3409, -0.0466,\n","                       0.0759,  0.0463, -0.1477,  0.4797, -0.1627, -0.3503,  0.0216, -0.2557,\n","                      -0.2509,  0.0972,  0.1259, -0.1352, -0.0862,  0.0086, -0.1522,  0.0571,\n","                      -0.3292,  0.2039, -0.3104, -0.1271,  0.0381, -0.0536, -0.3056, -0.0880,\n","                      -0.1615, -0.1096, -0.0746,  0.2295, -0.0190, -0.1080, -0.0176, -0.1876,\n","                       0.0211, -0.0096, -0.0051,  0.3227,  0.1630,  0.2710,  0.2297, -0.6379,\n","                      -0.2462, -0.1831, -0.3860, -0.1779, -0.0606, -0.0154, -0.1861,  0.1487])),\n","             ('incept4.conv1.bn.running_var',\n","              tensor([0.1000, 0.0387, 0.0503, 0.0824, 0.0310, 0.0765, 0.0844, 0.1056, 0.0657,\n","                      0.0317, 0.0353, 0.0375, 0.0502, 0.0286, 0.1139, 0.0404, 0.0261, 0.0229,\n","                      0.0870, 0.0299, 0.0680, 0.0479, 0.0337, 0.0628, 0.1131, 0.0280, 0.0505,\n","                      0.0303, 0.0422, 0.0335, 0.0737, 0.0297, 0.0457, 0.0399, 0.0555, 0.0844,\n","                      0.0926, 0.0676, 0.0338, 0.0710, 0.0401, 0.0648, 0.0794, 0.0312, 0.0957,\n","                      0.0365, 0.0535, 0.0440, 0.0434, 0.1037, 0.0550, 0.0811, 0.0372, 0.1095,\n","                      0.0486, 0.0505, 0.0293, 0.0522, 0.0289, 0.0404, 0.0351, 0.0738, 0.0480,\n","                      0.0589, 0.0208, 0.1080, 0.0748, 0.0305, 0.0325, 0.0243, 0.0574, 0.0397,\n","                      0.0434, 0.0748, 0.0726, 0.0617, 0.0640, 0.0358, 0.0695, 0.1435, 0.1003,\n","                      0.0397, 0.0353, 0.0353, 0.0501, 0.0319, 0.0519, 0.0921, 0.1087, 0.0285,\n","                      0.1156, 0.0630, 0.0677, 0.1203, 0.0413, 0.0680])),\n","             ('incept4.conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept4.conv3.conv.weight',\n","              tensor([[[[ 7.8787e-02,  4.3003e-03, -7.0771e-03],\n","                        [ 1.6455e-02,  5.1374e-03, -1.0039e-02],\n","                        [-2.2553e-02, -3.0829e-02, -8.3278e-05]],\n","              \n","                       [[-2.0968e-02, -7.5062e-02, -9.7103e-02],\n","                        [-1.1390e-02,  3.1922e-02, -3.7755e-02],\n","                        [ 1.3025e-02,  1.4698e-02, -5.0225e-03]],\n","              \n","                       [[ 5.8889e-03,  1.0853e-02, -1.3484e-02],\n","                        [ 8.3773e-03,  8.8036e-03, -1.0739e-02],\n","                        [-1.9393e-03, -1.6481e-02, -1.9355e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 1.0158e-02,  4.0669e-02,  5.4057e-02],\n","                        [ 1.2756e-02,  3.3107e-02,  2.8513e-03],\n","                        [-3.6042e-02,  8.6167e-03,  2.8663e-02]],\n","              \n","                       [[ 2.3732e-03,  2.8620e-03,  1.8236e-02],\n","                        [-7.1599e-03, -1.0737e-02,  1.6207e-02],\n","                        [-1.9363e-03, -1.9690e-02,  2.2850e-03]],\n","              \n","                       [[ 3.5475e-02,  1.3400e-02, -2.4019e-02],\n","                        [ 1.8627e-02, -2.1704e-02, -2.3876e-02],\n","                        [ 2.0661e-02,  3.3208e-02, -4.6276e-03]]],\n","              \n","              \n","                      [[[-4.1605e-03, -2.4266e-03, -1.8378e-02],\n","                        [-1.7850e-02, -2.7471e-02, -4.3493e-02],\n","                        [-2.8601e-02, -4.3279e-02, -1.0427e-02]],\n","              \n","                       [[ 1.3783e-02,  3.1467e-02,  9.2487e-03],\n","                        [ 2.1058e-02,  5.9283e-03, -1.7676e-02],\n","                        [-2.0502e-02, -1.5189e-02,  6.8998e-03]],\n","              \n","                       [[-2.2416e-02, -2.6971e-03,  2.6192e-02],\n","                        [-1.6793e-02,  7.8279e-03,  9.4415e-03],\n","                        [-2.2791e-02, -7.3569e-03,  1.9529e-02]],\n","              \n","                       ...,\n","              \n","                       [[-2.7058e-02, -4.1232e-02, -4.7360e-02],\n","                        [-8.6712e-03, -1.2255e-03,  2.5201e-02],\n","                        [ 2.7393e-02, -1.9764e-02, -5.3706e-03]],\n","              \n","                       [[ 3.7881e-03, -4.4283e-02, -4.0163e-02],\n","                        [-1.3784e-02, -3.7522e-02, -2.5225e-02],\n","                        [-6.9233e-03,  3.8143e-03, -4.1247e-02]],\n","              \n","                       [[ 2.8694e-02,  4.5791e-02,  3.3556e-02],\n","                        [ 4.3853e-02,  8.8590e-03,  5.8146e-03],\n","                        [-1.4646e-02, -3.2169e-02, -2.8483e-02]]],\n","              \n","              \n","                      [[[ 9.5005e-03,  6.5774e-02,  4.0080e-02],\n","                        [-3.7601e-02,  2.0151e-02, -1.3072e-03],\n","                        [-5.1729e-02,  7.1950e-03, -1.3309e-02]],\n","              \n","                       [[-1.7536e-03,  2.1820e-02,  1.2909e-02],\n","                        [-3.8716e-02, -1.3952e-02, -1.0300e-02],\n","                        [-1.5551e-02, -1.3739e-02, -2.9621e-02]],\n","              \n","                       [[-1.1984e-02,  1.1430e-02, -5.3539e-04],\n","                        [ 1.0233e-02, -1.1614e-02, -1.4268e-02],\n","                        [-2.4832e-02, -2.4278e-02, -1.8576e-02]],\n","              \n","                       ...,\n","              \n","                       [[-4.3645e-02, -2.8428e-02, -4.2804e-02],\n","                        [ 6.2910e-04, -2.0728e-03, -1.9186e-02],\n","                        [-2.2059e-02, -1.4401e-02, -1.2213e-02]],\n","              \n","                       [[-3.6711e-02,  2.3007e-02, -2.3988e-02],\n","                        [-3.3418e-02,  1.5577e-02,  1.5457e-02],\n","                        [ 4.6778e-03, -6.2400e-05, -2.8125e-02]],\n","              \n","                       [[-1.8687e-02,  1.5184e-02,  4.3338e-02],\n","                        [ 2.5449e-03,  2.2672e-02,  1.2422e-02],\n","                        [-5.6568e-04,  3.2543e-02,  2.1116e-02]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 2.1973e-02,  6.4224e-02,  2.6952e-02],\n","                        [-6.4669e-03,  7.2756e-03,  2.0375e-02],\n","                        [-7.5375e-02, -6.4964e-02, -3.0843e-02]],\n","              \n","                       [[ 5.2065e-02,  7.3591e-03,  4.4251e-02],\n","                        [ 1.1150e-02, -4.0796e-02, -2.7882e-02],\n","                        [ 5.6725e-02, -1.4304e-02, -4.1377e-02]],\n","              \n","                       [[-4.0535e-03,  2.3460e-02, -3.7181e-03],\n","                        [-8.7955e-03, -6.3942e-03,  2.9054e-02],\n","                        [ 2.7552e-03, -1.0118e-02, -1.9599e-02]],\n","              \n","                       ...,\n","              \n","                       [[-1.2692e-03, -2.0545e-02, -2.8896e-02],\n","                        [-2.6190e-02, -2.3314e-02, -2.4365e-02],\n","                        [ 2.2737e-02, -2.5488e-02, -1.3411e-02]],\n","              \n","                       [[ 2.9778e-02, -1.8155e-02,  9.9468e-03],\n","                        [ 1.8954e-03, -6.0848e-03,  3.0297e-02],\n","                        [ 4.7167e-02,  2.3722e-02,  1.7400e-02]],\n","              \n","                       [[ 5.3453e-02, -8.4568e-03,  6.3150e-03],\n","                        [-2.4325e-03,  1.0727e-02,  1.6346e-02],\n","                        [ 2.7903e-02, -5.0681e-03, -4.0899e-02]]],\n","              \n","              \n","                      [[[-2.0644e-02, -5.9619e-03,  1.1987e-02],\n","                        [-6.6280e-02, -4.9492e-02, -2.5844e-02],\n","                        [-2.1293e-02, -2.8164e-02, -2.4306e-02]],\n","              \n","                       [[-8.1278e-02, -5.6804e-03, -3.5975e-03],\n","                        [-3.8601e-02,  1.7673e-02,  3.7996e-02],\n","                        [-4.4956e-02, -2.7839e-02, -1.8050e-02]],\n","              \n","                       [[-2.0215e-02, -1.4053e-03, -2.1919e-02],\n","                        [-2.3653e-02, -1.8202e-02, -6.0435e-03],\n","                        [ 1.6124e-02, -9.2935e-03,  2.3865e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 1.2069e-04,  8.6149e-03, -7.4002e-03],\n","                        [ 2.4815e-02,  1.1940e-02, -1.3099e-02],\n","                        [ 7.9745e-02,  6.5194e-02,  2.6934e-02]],\n","              \n","                       [[-1.2920e-02, -2.2714e-02, -1.7656e-02],\n","                        [ 1.6289e-02, -3.3142e-02, -1.8856e-02],\n","                        [ 2.7126e-02,  1.3959e-03,  1.8923e-02]],\n","              \n","                       [[-1.4923e-02, -4.2311e-02, -3.1809e-02],\n","                        [ 3.6343e-03, -3.8927e-03,  7.0796e-03],\n","                        [-4.3383e-02, -4.9365e-02, -1.1010e-02]]],\n","              \n","              \n","                      [[[-2.3614e-02, -9.0854e-03,  1.8030e-02],\n","                        [-3.4834e-02,  2.2969e-02,  3.1196e-03],\n","                        [ 1.7341e-02,  3.8248e-02, -1.3336e-02]],\n","              \n","                       [[ 1.0637e-02, -2.1869e-02,  5.4378e-03],\n","                        [-3.9070e-03,  4.4569e-03,  3.5053e-03],\n","                        [-2.6484e-04, -1.9738e-02, -2.3335e-02]],\n","              \n","                       [[-2.4681e-02, -2.2501e-02,  9.8059e-03],\n","                        [-1.4812e-02, -8.2391e-03, -2.5387e-02],\n","                        [-1.1295e-03, -9.7766e-03,  1.0795e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 6.3383e-04,  3.2978e-03,  6.6985e-03],\n","                        [ 4.0442e-03,  1.8583e-02,  1.0672e-02],\n","                        [-1.9334e-02,  1.7906e-02, -1.3545e-02]],\n","              \n","                       [[-2.5876e-02, -1.8335e-02, -1.0706e-02],\n","                        [ 1.6748e-02, -2.7979e-03,  4.2200e-04],\n","                        [-2.0106e-02, -4.8912e-03,  2.4375e-02]],\n","              \n","                       [[ 2.1948e-02, -6.7330e-03, -1.5282e-02],\n","                        [-5.5755e-03,  2.2253e-02, -6.5370e-03],\n","                        [ 1.3761e-02,  1.3475e-02, -7.5310e-03]]]])),\n","             ('incept4.conv3.conv.bias',\n","              tensor([-0.0175, -0.0061, -0.0253,  0.0222,  0.0174,  0.0068,  0.0229, -0.0150,\n","                      -0.0009,  0.0257,  0.0108,  0.0103, -0.0045, -0.0249, -0.0061,  0.0180,\n","                       0.0104,  0.0251, -0.0090,  0.0058,  0.0214, -0.0073,  0.0036,  0.0122,\n","                       0.0195,  0.0245,  0.0149,  0.0132, -0.0195, -0.0144, -0.0068, -0.0071,\n","                      -0.0150, -0.0077,  0.0061,  0.0004,  0.0014, -0.0179,  0.0034,  0.0175,\n","                       0.0142,  0.0081,  0.0073, -0.0136, -0.0137, -0.0213, -0.0043,  0.0168,\n","                       0.0112,  0.0263,  0.0208,  0.0212,  0.0196,  0.0090, -0.0206,  0.0007,\n","                       0.0261, -0.0095, -0.0023, -0.0156, -0.0112,  0.0049, -0.0134,  0.0054])),\n","             ('incept4.conv3.bn.weight',\n","              tensor([0.7766, 0.5277, 0.6160, 0.7882, 0.2763, 0.8841, 0.1835, 0.3387, 0.5744,\n","                      0.5403, 0.7507, 0.8200, 0.3749, 0.9428, 0.4663, 0.4682, 0.7019, 0.4242,\n","                      0.3781, 0.6955, 0.1972, 0.8138, 0.5425, 0.0693, 0.1396, 0.9904, 0.2790,\n","                      0.1458, 0.9121, 0.4482, 0.8927, 0.8628, 0.2596, 0.5064, 0.4886, 0.0788,\n","                      0.2386, 0.8285, 0.2916, 0.7884, 0.8000, 0.5241, 0.3361, 0.7744, 0.7043,\n","                      0.2506, 0.2645, 0.4094, 0.2986, 0.3611, 0.5552, 0.7216, 0.8893, 0.1476,\n","                      0.0777, 0.8585, 0.6704, 0.8981, 0.3037, 0.2978, 0.4632, 0.7046, 0.5801,\n","                      0.2283])),\n","             ('incept4.conv3.bn.bias',\n","              tensor([-8.0144e-02, -1.2689e-01, -6.8790e-02, -6.3198e-02,  1.1861e-03,\n","                      -1.0578e-01,  3.1350e-02, -6.3225e-04, -3.0417e-02, -5.9384e-02,\n","                      -6.3513e-02, -9.7795e-02, -1.6563e-02,  9.9752e-04, -2.1592e-02,\n","                      -9.8681e-02, -5.9434e-02, -3.0167e-02,  4.0306e-02, -1.2013e-01,\n","                       5.8702e-03, -9.6477e-02, -3.7227e-02, -3.4505e-03, -3.3055e-05,\n","                      -2.4940e-02, -2.0250e-02,  4.3945e-03, -7.5079e-02, -6.2567e-02,\n","                      -1.2106e-01, -1.0175e-01, -1.2755e-02, -1.1626e-01, -3.2043e-02,\n","                      -7.8547e-03, -6.6790e-03, -9.3470e-02, -3.8714e-02, -9.6768e-02,\n","                      -1.0862e-01, -1.5628e-02, -4.0389e-02, -5.8972e-02, -3.7848e-02,\n","                      -3.7338e-02, -1.8032e-03, -3.4686e-02, -4.6975e-02, -4.2042e-02,\n","                      -1.4724e-02, -3.5898e-02, -2.6886e-02,  2.1209e-02,  1.6291e-02,\n","                      -7.8836e-02,  1.5079e-03, -2.8924e-02, -5.0885e-03, -4.6821e-02,\n","                      -6.5596e-02, -2.8044e-02, -7.2559e-02, -5.4605e-03])),\n","             ('incept4.conv3.bn.running_mean',\n","              tensor([-0.4128, -0.5657, -0.1819,  0.2078, -0.0834, -0.6486,  0.0649, -0.2151,\n","                      -0.3026,  0.3808, -0.1023, -0.8140, -0.3097, -1.3626, -0.2111, -0.3943,\n","                      -0.5013,  0.0188, -0.3683, -0.1753, -0.1037, -0.3825,  0.2756,  0.1920,\n","                       0.0216, -0.9034, -0.2112, -0.0940, -0.3518, -0.1184,  0.1399, -0.1134,\n","                      -0.1808,  0.1430, -0.2463, -0.0298,  0.2431,  0.0302, -0.0566, -0.0059,\n","                      -0.0070,  0.2122, -0.0644, -0.0499, -1.1708,  0.2045, -0.1024, -0.2759,\n","                       0.5900, -0.1614, -0.0866, -0.7083, -0.6058, -0.2359, -0.1200, -0.2963,\n","                      -0.0719, -0.5570, -0.3472, -0.3059, -0.1873, -0.6408, -0.6638, -0.0723])),\n","             ('incept4.conv3.bn.running_var',\n","              tensor([0.3063, 0.2532, 0.3825, 0.3945, 0.0691, 0.3645, 0.0444, 0.1062, 0.2166,\n","                      0.2125, 0.4669, 0.4247, 0.1145, 0.5035, 0.1542, 0.1467, 0.2370, 0.1433,\n","                      0.0982, 0.3025, 0.0498, 0.4704, 0.2633, 0.0291, 0.0312, 0.4114, 0.0646,\n","                      0.0341, 0.4525, 0.1834, 0.3660, 0.3790, 0.0761, 0.3153, 0.1976, 0.0315,\n","                      0.0664, 0.3423, 0.0688, 0.4176, 0.5229, 0.2008, 0.1187, 0.3835, 0.3483,\n","                      0.0749, 0.0625, 0.1360, 0.0922, 0.1273, 0.1695, 0.3559, 0.3616, 0.0435,\n","                      0.0360, 0.4710, 0.3657, 0.4755, 0.0830, 0.0663, 0.1474, 0.5728, 0.1984,\n","                      0.0489])),\n","             ('incept4.conv3.bn.num_batches_tracked', tensor(4157)),\n","             ('incept5.conv1.conv.weight', tensor([[[[-0.0291]],\n","              \n","                       [[ 0.0205]],\n","              \n","                       [[ 0.0660]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0680]],\n","              \n","                       [[-0.0343]],\n","              \n","                       [[-0.0707]]],\n","              \n","              \n","                      [[[-0.0386]],\n","              \n","                       [[-0.0369]],\n","              \n","                       [[-0.0397]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0297]],\n","              \n","                       [[ 0.0639]],\n","              \n","                       [[ 0.0487]]],\n","              \n","              \n","                      [[[ 0.0591]],\n","              \n","                       [[ 0.0293]],\n","              \n","                       [[ 0.0899]],\n","              \n","                       ...,\n","              \n","                       [[ 0.1005]],\n","              \n","                       [[-0.0089]],\n","              \n","                       [[-0.0116]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 0.0658]],\n","              \n","                       [[-0.0297]],\n","              \n","                       [[-0.0227]],\n","              \n","                       ...,\n","              \n","                       [[-0.0035]],\n","              \n","                       [[ 0.0287]],\n","              \n","                       [[-0.0237]]],\n","              \n","              \n","                      [[[-0.0422]],\n","              \n","                       [[ 0.0535]],\n","              \n","                       [[ 0.0697]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0276]],\n","              \n","                       [[ 0.0574]],\n","              \n","                       [[-0.0384]]],\n","              \n","              \n","                      [[[ 0.0508]],\n","              \n","                       [[ 0.0553]],\n","              \n","                       [[ 0.0202]],\n","              \n","                       ...,\n","              \n","                       [[-0.0099]],\n","              \n","                       [[ 0.0238]],\n","              \n","                       [[ 0.0681]]]])),\n","             ('incept5.conv1.conv.bias',\n","              tensor([ 0.0332, -0.0421, -0.0133, -0.0412, -0.0698, -0.0155,  0.0469,  0.0707,\n","                      -0.0710, -0.0437,  0.0593,  0.0735, -0.0380,  0.0536, -0.0220,  0.0623,\n","                      -0.0007, -0.0111, -0.0535,  0.0191, -0.0681, -0.0007,  0.0065,  0.0296,\n","                       0.0356,  0.0429,  0.0679, -0.0212,  0.0086,  0.0753,  0.0333,  0.0414,\n","                       0.0478,  0.0753, -0.0432,  0.0061, -0.0273, -0.0648, -0.0662,  0.0525,\n","                       0.0221, -0.0660, -0.0199, -0.0674,  0.0707,  0.0264, -0.0221, -0.0252,\n","                      -0.0749, -0.0019,  0.0478,  0.0476,  0.0125, -0.0626, -0.0786,  0.0601,\n","                       0.0005, -0.0533, -0.0685, -0.0480,  0.0323, -0.0783, -0.0391,  0.0089,\n","                      -0.0695,  0.0717, -0.0459, -0.0095,  0.0667, -0.0552, -0.0451, -0.0623,\n","                       0.0783, -0.0144, -0.0186,  0.0198,  0.0103, -0.0281, -0.0180, -0.0235])),\n","             ('incept5.conv1.bn.weight',\n","              tensor([0.4294, 0.3602, 0.8781, 0.2399, 0.6768, 0.7844, 0.7880, 0.3913, 0.7536,\n","                      0.1134, 0.8180, 0.1862, 0.1017, 0.6935, 0.6161, 0.5513, 0.7885, 0.6235,\n","                      0.7054, 0.7379, 0.8098, 0.1173, 0.4686, 0.7311, 0.8008, 0.7469, 0.3699,\n","                      0.7431, 0.6743, 0.0067, 0.1842, 0.1722, 0.3897, 0.4285, 0.5128, 0.6286,\n","                      0.4519, 0.5517, 0.0883, 0.3031, 0.6244, 0.7851, 0.8008, 0.6585, 0.9111,\n","                      0.6266, 0.6507, 0.1909, 0.6366, 0.6395, 0.5947, 0.2656, 0.1486, 0.4613,\n","                      0.2704, 0.7896, 0.8069, 0.3275, 0.4567, 0.0344, 0.0129, 0.7412, 0.3143,\n","                      0.0018, 0.4643, 0.4960, 0.3711, 0.4383, 0.7111, 0.7167, 0.8807, 0.4255,\n","                      0.6060, 0.5382, 0.1115, 0.3735, 0.6361, 0.7236, 0.5424, 0.4119])),\n","             ('incept5.conv1.bn.bias',\n","              tensor([-0.0235,  0.0080, -0.0630,  0.0076, -0.0622, -0.0872, -0.0960, -0.0045,\n","                      -0.0362, -0.0057, -0.0615, -0.0281, -0.0322, -0.0479, -0.0714, -0.0367,\n","                      -0.0815, -0.0380, -0.0653, -0.0313, -0.0847,  0.0087, -0.0541, -0.0756,\n","                      -0.0573, -0.0405, -0.0037, -0.0641, -0.0343, -0.0237,  0.0053,  0.0225,\n","                       0.0016, -0.0702,  0.0042, -0.0422, -0.0708, -0.0464,  0.0138, -0.0149,\n","                      -0.0055, -0.0995, -0.0751, -0.0479, -0.1017, -0.0745, -0.0357, -0.0019,\n","                      -0.0638, -0.0656, -0.0449,  0.0135, -0.0273, -0.0330,  0.0105, -0.0818,\n","                      -0.0501,  0.0024,  0.0191,  0.0209,  0.0135, -0.0622, -0.0185, -0.0075,\n","                      -0.0438, -0.0205, -0.0004, -0.0405, -0.0289, -0.0513, -0.0580, -0.0025,\n","                      -0.0828, -0.0580, -0.0057,  0.0101, -0.0733, -0.0700, -0.0421, -0.0205])),\n","             ('incept5.conv1.bn.running_mean',\n","              tensor([ 0.2645, -0.1061, -0.0450, -0.2948, -0.1222,  0.0198,  0.0069, -0.0417,\n","                      -0.1391, -0.1785,  0.3777, -0.0676, -0.1834,  0.0023, -0.1036,  0.0185,\n","                       0.1123, -0.1984,  0.0505,  0.0236, -0.0093,  0.0331, -0.2026, -0.0674,\n","                      -0.1069,  0.2692,  0.0356, -0.0048,  0.0491,  0.0078,  0.1298,  0.2648,\n","                       0.1124,  0.2207,  0.0065, -0.0985,  0.0673,  0.0666, -0.2224,  0.1022,\n","                      -0.0395, -0.0643, -0.1186, -0.1846,  0.0840,  0.0145,  0.0860, -0.2142,\n","                       0.0885, -0.1695, -0.1526, -0.1258,  0.0717, -0.1968, -0.1471,  0.4385,\n","                      -0.0925,  0.0115, -0.3002,  0.1048,  0.0778, -0.0693, -0.1166, -0.1054,\n","                      -0.0479,  0.2530,  0.0137, -0.1179,  0.0069, -0.1309,  0.1556,  0.0176,\n","                      -0.1143, -0.0814, -0.1958, -0.0512, -0.1019,  0.0117, -0.2650, -0.0157])),\n","             ('incept5.conv1.bn.running_var',\n","              tensor([0.0407, 0.0357, 0.0817, 0.0294, 0.0558, 0.0691, 0.0730, 0.0357, 0.0608,\n","                      0.0379, 0.0877, 0.0353, 0.0403, 0.0564, 0.0632, 0.0659, 0.0697, 0.0531,\n","                      0.0589, 0.0800, 0.0871, 0.0336, 0.0446, 0.0679, 0.0737, 0.0807, 0.0411,\n","                      0.0705, 0.0644, 0.0238, 0.0241, 0.0385, 0.0448, 0.0463, 0.0355, 0.0511,\n","                      0.0345, 0.0467, 0.0353, 0.0287, 0.0621, 0.0817, 0.0740, 0.0720, 0.1555,\n","                      0.0658, 0.0498, 0.0284, 0.0643, 0.0538, 0.0608, 0.0299, 0.0283, 0.0464,\n","                      0.0384, 0.0726, 0.0746, 0.0366, 0.0337, 0.0272, 0.0349, 0.0722, 0.0362,\n","                      0.0279, 0.0389, 0.0549, 0.0413, 0.0527, 0.0570, 0.0549, 0.0913, 0.0297,\n","                      0.0644, 0.0650, 0.0287, 0.0413, 0.0560, 0.0893, 0.0456, 0.0349])),\n","             ('incept5.conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept5.conv3.conv.weight',\n","              tensor([[[[ 0.0165,  0.0398, -0.0197],\n","                        [ 0.0348,  0.0067, -0.0109],\n","                        [-0.0053, -0.0011, -0.0526]],\n","              \n","                       [[-0.0354, -0.0310,  0.0215],\n","                        [ 0.0034,  0.0089,  0.0383],\n","                        [-0.0448,  0.0229, -0.0090]],\n","              \n","                       [[ 0.0193, -0.0021,  0.0030],\n","                        [ 0.0049, -0.0438, -0.0235],\n","                        [-0.0021,  0.0106, -0.0010]],\n","              \n","                       ...,\n","              \n","                       [[-0.0076, -0.0595, -0.0607],\n","                        [-0.0474,  0.0065,  0.0241],\n","                        [-0.0857, -0.0405,  0.0317]],\n","              \n","                       [[ 0.0130,  0.0205, -0.0025],\n","                        [ 0.0223, -0.0324, -0.0123],\n","                        [ 0.0106, -0.0114,  0.0059]],\n","              \n","                       [[ 0.0127,  0.0176, -0.0150],\n","                        [ 0.0190,  0.0112, -0.0146],\n","                        [-0.0186,  0.0188, -0.0126]]],\n","              \n","              \n","                      [[[-0.0291, -0.0346, -0.0148],\n","                        [-0.0247, -0.0117,  0.0159],\n","                        [ 0.0394,  0.0018, -0.0144]],\n","              \n","                       [[ 0.0113, -0.0133,  0.0057],\n","                        [ 0.0153, -0.0031,  0.0174],\n","                        [-0.0061, -0.0121,  0.0014]],\n","              \n","                       [[ 0.0052, -0.0299, -0.0177],\n","                        [ 0.0351,  0.0196, -0.0107],\n","                        [-0.0036, -0.0274,  0.0109]],\n","              \n","                       ...,\n","              \n","                       [[-0.0105,  0.0123, -0.0075],\n","                        [ 0.0017,  0.0207, -0.0092],\n","                        [ 0.0213, -0.0585,  0.0034]],\n","              \n","                       [[ 0.0128,  0.0158,  0.0035],\n","                        [ 0.0062,  0.0191,  0.0023],\n","                        [-0.0039,  0.0096, -0.0012]],\n","              \n","                       [[ 0.0132,  0.0220,  0.0063],\n","                        [-0.0030, -0.0211, -0.0046],\n","                        [-0.0154,  0.0116,  0.0085]]],\n","              \n","              \n","                      [[[ 0.0019,  0.0355, -0.0160],\n","                        [ 0.0447, -0.0093, -0.0052],\n","                        [ 0.0045,  0.0351, -0.0274]],\n","              \n","                       [[-0.0281, -0.0273, -0.0060],\n","                        [-0.0197,  0.0210,  0.0184],\n","                        [ 0.0259,  0.0021,  0.0197]],\n","              \n","                       [[-0.0005, -0.0243, -0.0230],\n","                        [-0.0092, -0.0074,  0.0115],\n","                        [ 0.0126,  0.0290, -0.0218]],\n","              \n","                       ...,\n","              \n","                       [[-0.0045,  0.0002,  0.0053],\n","                        [-0.0383,  0.0018, -0.0077],\n","                        [-0.0118, -0.0376, -0.0163]],\n","              \n","                       [[ 0.0029, -0.0299, -0.0295],\n","                        [-0.0224, -0.0008, -0.0149],\n","                        [-0.0298, -0.0163, -0.0080]],\n","              \n","                       [[ 0.0155, -0.0165,  0.0032],\n","                        [ 0.0027, -0.0069,  0.0057],\n","                        [-0.0203, -0.0279,  0.0288]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[-0.0519, -0.0352, -0.0580],\n","                        [-0.0681, -0.0586, -0.0289],\n","                        [-0.0194,  0.0094, -0.0253]],\n","              \n","                       [[ 0.0183,  0.0103,  0.0484],\n","                        [ 0.0116, -0.0224, -0.0033],\n","                        [-0.0157, -0.0235, -0.0245]],\n","              \n","                       [[-0.0402,  0.0124,  0.0311],\n","                        [ 0.0046,  0.0043,  0.0060],\n","                        [-0.0117, -0.0133, -0.0038]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0299,  0.0263,  0.0306],\n","                        [ 0.0243,  0.0527,  0.0516],\n","                        [-0.0212, -0.0071,  0.0601]],\n","              \n","                       [[-0.0201,  0.0233,  0.0023],\n","                        [-0.0159,  0.0090,  0.0269],\n","                        [ 0.0230, -0.0105, -0.0225]],\n","              \n","                       [[ 0.0077, -0.0247, -0.0124],\n","                        [ 0.0225,  0.0123, -0.0354],\n","                        [ 0.0135, -0.0102, -0.0242]]],\n","              \n","              \n","                      [[[-0.0039,  0.0031,  0.0289],\n","                        [-0.0065, -0.0015, -0.0429],\n","                        [ 0.0025, -0.0061, -0.0104]],\n","              \n","                       [[-0.0136, -0.0242,  0.0287],\n","                        [-0.0284, -0.0126,  0.0130],\n","                        [ 0.0201,  0.0013,  0.0007]],\n","              \n","                       [[-0.0211,  0.0139,  0.0052],\n","                        [-0.0020, -0.0196, -0.0160],\n","                        [ 0.0028, -0.0212, -0.0009]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0031, -0.0026,  0.0115],\n","                        [-0.0228,  0.0015,  0.0090],\n","                        [-0.0270,  0.0125,  0.0026]],\n","              \n","                       [[-0.0153, -0.0053,  0.0253],\n","                        [ 0.0195,  0.0272, -0.0181],\n","                        [ 0.0072, -0.0022, -0.0141]],\n","              \n","                       [[ 0.0047,  0.0142,  0.0210],\n","                        [ 0.0089, -0.0125,  0.0062],\n","                        [-0.0320, -0.0006,  0.0208]]],\n","              \n","              \n","                      [[[ 0.0064, -0.0370, -0.0480],\n","                        [ 0.0406, -0.0253, -0.0432],\n","                        [ 0.0349,  0.0009, -0.0158]],\n","              \n","                       [[ 0.0164,  0.0151, -0.0205],\n","                        [ 0.0017,  0.0163,  0.0043],\n","                        [-0.0480,  0.0015,  0.0054]],\n","              \n","                       [[-0.0031,  0.0129,  0.0062],\n","                        [-0.0115,  0.0115,  0.0125],\n","                        [-0.0154,  0.0487,  0.0273]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0085, -0.0271, -0.0128],\n","                        [-0.0050, -0.0363, -0.0484],\n","                        [-0.0446, -0.0415, -0.0103]],\n","              \n","                       [[-0.0062,  0.0134,  0.0238],\n","                        [-0.0235,  0.0249,  0.0341],\n","                        [-0.0103,  0.0140, -0.0133]],\n","              \n","                       [[ 0.0045, -0.0258,  0.0132],\n","                        [-0.0157,  0.0171,  0.0261],\n","                        [ 0.0257,  0.0053, -0.0228]]]])),\n","             ('incept5.conv3.conv.bias',\n","              tensor([-8.4532e-03, -2.6290e-02,  2.2849e-02,  2.3432e-02, -1.6591e-02,\n","                      -1.4723e-02, -7.3674e-03,  6.7322e-03,  2.3444e-02,  4.4259e-03,\n","                       3.9752e-03,  1.3017e-02,  1.4019e-02,  1.1317e-02, -2.6244e-02,\n","                       2.2278e-02, -6.4749e-03,  1.4234e-02,  3.0080e-03,  5.9174e-03,\n","                       1.0005e-02,  1.4769e-02, -1.3750e-02,  3.6453e-03, -9.7984e-03,\n","                      -1.1285e-02, -1.6768e-02,  8.1417e-03,  6.2104e-03, -2.1949e-02,\n","                       9.1597e-03, -8.2546e-03, -1.2630e-02, -2.1722e-02,  1.3759e-02,\n","                       2.5957e-02, -1.7606e-02, -9.1110e-03, -2.2630e-02,  2.6554e-03,\n","                       1.3666e-02, -2.5188e-02, -1.7705e-02,  1.5456e-03, -4.5075e-03,\n","                       6.2721e-03, -7.8501e-03,  1.5994e-02,  8.1617e-03,  6.4253e-05,\n","                       2.3217e-02,  2.1269e-02,  1.7831e-02, -1.1113e-02, -2.3240e-02,\n","                       1.1012e-02, -5.0634e-04,  1.8116e-02, -6.9296e-03, -4.6084e-03,\n","                       1.9775e-02,  9.1551e-03, -2.0203e-02,  1.8423e-02, -6.1323e-03,\n","                      -6.7037e-03,  1.8686e-02, -1.5008e-02,  2.4003e-02, -2.1489e-02,\n","                       1.3911e-02,  2.8028e-03,  1.5280e-02,  1.3402e-02, -1.4264e-02,\n","                      -1.1996e-02,  6.8145e-03, -9.0211e-03,  1.8240e-02,  8.1199e-03])),\n","             ('incept5.conv3.bn.weight',\n","              tensor([0.6986, 0.5060, 0.4653, 0.0188, 0.7687, 0.7663, 0.3559, 0.6782, 0.1341,\n","                      0.0714, 0.5470, 0.8847, 0.6697, 0.4983, 0.4513, 0.3677, 0.8532, 0.4200,\n","                      0.5123, 0.8945, 0.3520, 0.1203, 0.2674, 0.8268, 0.8171, 0.5308, 0.6153,\n","                      0.3125, 0.7907, 0.4641, 0.3058, 0.7290, 0.6695, 0.5371, 0.0876, 0.6602,\n","                      0.7678, 0.8496, 0.5252, 0.6055, 0.2014, 0.2419, 0.7834, 0.1009, 0.4734,\n","                      0.3424, 0.9091, 0.8357, 0.6310, 0.4231, 0.2478, 0.8269, 0.1570, 0.9479,\n","                      0.6460, 0.1719, 0.2627, 0.3407, 0.2207, 0.0766, 0.8379, 0.6761, 0.5199,\n","                      0.8370, 0.0051, 0.6541, 0.4878, 0.4431, 0.1984, 0.5142, 0.5097, 0.6520,\n","                      0.7459, 0.8892, 0.0937, 0.6168, 0.8080, 0.7499, 0.4825, 0.7240])),\n","             ('incept5.conv3.bn.bias',\n","              tensor([-0.0932, -0.0734, -0.0396, -0.0101, -0.1226, -0.1047, -0.0300, -0.0592,\n","                      -0.0010,  0.0005, -0.0833, -0.1059, -0.0851, -0.0613, -0.0377, -0.0383,\n","                      -0.0866, -0.0469, -0.0543, -0.0670, -0.0126,  0.0104, -0.0020, -0.1059,\n","                      -0.0828, -0.0332, -0.0392,  0.0016, -0.1105, -0.0069, -0.0173, -0.0999,\n","                      -0.0687, -0.0456,  0.0087, -0.0649, -0.0654, -0.0633, -0.0801, -0.0667,\n","                       0.0111, -0.0167, -0.0945, -0.0053, -0.0628, -0.0303, -0.0517, -0.0976,\n","                      -0.0924,  0.0052, -0.0069, -0.1000,  0.0119, -0.1271, -0.0871, -0.0342,\n","                       0.0148, -0.0134,  0.0006,  0.0142, -0.0843, -0.0872, -0.0326, -0.0542,\n","                      -0.0105, -0.0638, -0.0615, -0.0760,  0.0205, -0.0254, -0.0935, -0.1280,\n","                      -0.1334, -0.1119, -0.0131, -0.0582, -0.1217, -0.1083, -0.0411, -0.1247])),\n","             ('incept5.conv3.bn.running_mean',\n","              tensor([-0.5477,  0.0314, -0.5390,  0.0812, -0.7837, -0.3421, -0.2613, -0.2402,\n","                      -0.1771, -0.0107, -0.0235, -0.7740,  0.1253,  0.0234, -0.2820, -0.3390,\n","                      -0.7827,  0.3033, -0.3905, -0.5900, -0.1545, -0.0011, -0.2810,  0.4678,\n","                      -0.4658,  0.1098, -0.0827, -0.0059,  0.1477, -0.0445,  0.0591, -0.4387,\n","                      -0.2987, -0.2835,  0.0700, -0.3734, -1.0172, -0.3058, -0.1356, -0.0643,\n","                      -0.0331, -0.0740, -0.8972, -0.1613, -0.0901, -0.1159, -0.5479, -0.9813,\n","                      -0.3390, -0.3433,  0.2454,  0.1846,  0.1118, -0.5283, -0.2373,  0.1144,\n","                      -0.0143,  0.4128, -0.1065,  0.1034, -0.2600, -0.3002,  0.2471, -0.6441,\n","                       0.0811, -0.4305, -0.0926,  0.0484, -0.1573, -0.0462, -0.1192, -0.8326,\n","                       0.0931, -0.8584,  0.0546, -0.2089, -0.6328, -0.6018, -0.1237, -0.2375])),\n","             ('incept5.conv3.bn.running_var',\n","              tensor([0.2365, 0.1489, 0.1407, 0.0233, 0.4173, 0.2617, 0.0760, 0.2422, 0.0337,\n","                      0.0311, 0.1676, 0.3948, 0.1927, 0.1432, 0.1225, 0.0863, 0.3321, 0.1067,\n","                      0.1711, 0.3199, 0.0612, 0.0345, 0.0520, 0.2859, 0.4144, 0.1283, 0.1565,\n","                      0.0662, 0.3213, 0.0818, 0.0730, 0.2782, 0.1969, 0.1365, 0.0381, 0.1757,\n","                      0.4603, 0.3195, 0.1335, 0.1719, 0.0351, 0.0569, 0.2542, 0.0324, 0.1053,\n","                      0.0659, 0.2957, 0.3406, 0.2106, 0.0933, 0.0417, 0.3312, 0.0343, 0.3926,\n","                      0.1832, 0.0420, 0.0432, 0.0670, 0.0458, 0.0367, 0.2877, 0.2644, 0.1348,\n","                      0.2957, 0.0292, 0.2327, 0.1406, 0.1011, 0.0314, 0.1306, 0.1692, 0.2936,\n","                      0.2460, 0.3789, 0.0380, 0.1583, 0.2893, 0.3350, 0.1271, 0.3128])),\n","             ('incept5.conv3.bn.num_batches_tracked', tensor(4157)),\n","             ('incept6.conv1.conv.weight', tensor([[[[ 0.0735]],\n","              \n","                       [[ 0.0588]],\n","              \n","                       [[ 0.0959]],\n","              \n","                       ...,\n","              \n","                       [[-0.0909]],\n","              \n","                       [[-0.0830]],\n","              \n","                       [[ 0.0057]]],\n","              \n","              \n","                      [[[-0.1083]],\n","              \n","                       [[-0.0751]],\n","              \n","                       [[-0.0568]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0732]],\n","              \n","                       [[-0.0299]],\n","              \n","                       [[-0.0648]]],\n","              \n","              \n","                      [[[-0.0673]],\n","              \n","                       [[-0.0447]],\n","              \n","                       [[-0.0120]],\n","              \n","                       ...,\n","              \n","                       [[-0.0173]],\n","              \n","                       [[-0.0072]],\n","              \n","                       [[ 0.0594]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[-0.0139]],\n","              \n","                       [[-0.0180]],\n","              \n","                       [[-0.0180]],\n","              \n","                       ...,\n","              \n","                       [[ 0.1146]],\n","              \n","                       [[-0.0909]],\n","              \n","                       [[-0.0845]]],\n","              \n","              \n","                      [[[-0.0397]],\n","              \n","                       [[ 0.0134]],\n","              \n","                       [[ 0.0050]],\n","              \n","                       ...,\n","              \n","                       [[-0.0288]],\n","              \n","                       [[ 0.0841]],\n","              \n","                       [[ 0.0518]]],\n","              \n","              \n","                      [[[ 0.0241]],\n","              \n","                       [[-0.0080]],\n","              \n","                       [[ 0.0378]],\n","              \n","                       ...,\n","              \n","                       [[-0.0408]],\n","              \n","                       [[-0.0444]],\n","              \n","                       [[ 0.0453]]]])),\n","             ('incept6.conv1.conv.bias',\n","              tensor([ 0.0070,  0.0025,  0.0289, -0.0396, -0.0292, -0.0032, -0.0744,  0.0577,\n","                      -0.0489, -0.0149,  0.0411,  0.0098,  0.0389, -0.0047, -0.0501, -0.0190,\n","                      -0.0561,  0.0143, -0.0082,  0.0552,  0.0185, -0.0654,  0.0254,  0.0119,\n","                      -0.0330, -0.0456,  0.0745, -0.0552,  0.0114,  0.0398,  0.0231,  0.0286,\n","                       0.0210, -0.0004,  0.0733,  0.0109, -0.0182, -0.0690,  0.0615, -0.0594,\n","                      -0.0680, -0.0045, -0.0345, -0.0013,  0.0655, -0.0222, -0.0736, -0.0442])),\n","             ('incept6.conv1.bn.weight',\n","              tensor([0.5892, 0.8310, 0.4164, 0.4652, 0.3619, 0.1487, 0.2019, 0.5774, 0.6282,\n","                      0.4205, 0.0730, 0.0094, 0.3818, 0.2063, 0.7287, 0.9189, 0.5502, 0.0397,\n","                      0.8921, 0.0379, 0.3137, 0.3732, 0.6186, 0.1603, 0.3056, 0.0281, 0.8656,\n","                      0.1262, 0.5559, 0.6014, 0.5364, 0.3813, 0.5734, 0.8157, 0.8243, 0.6141,\n","                      0.3710, 0.6194, 0.2350, 0.7567, 0.5406, 0.7441, 0.3954, 0.3222, 0.8853,\n","                      0.8636, 0.6086, 0.0373])),\n","             ('incept6.conv1.bn.bias',\n","              tensor([-0.0115, -0.0358, -0.0165,  0.0047, -0.0084,  0.0040,  0.0077, -0.0116,\n","                      -0.0216, -0.0279, -0.0114,  0.0061, -0.0180, -0.0144, -0.0394, -0.0549,\n","                      -0.0323,  0.0059, -0.0390, -0.0005, -0.0310, -0.0158, -0.0496,  0.0054,\n","                      -0.0201, -0.0050, -0.0606, -0.0078, -0.0355, -0.0268, -0.0446, -0.0155,\n","                      -0.0378, -0.0510, -0.0723, -0.0335, -0.0143, -0.0280,  0.0126, -0.0559,\n","                      -0.0295, -0.0314, -0.0202, -0.0216, -0.0539, -0.0516, -0.0569, -0.0049])),\n","             ('incept6.conv1.bn.running_mean',\n","              tensor([-0.0225,  0.2372, -0.1283, -0.0292, -0.0138,  0.1732, -0.0808, -0.0157,\n","                      -0.0398,  0.0999,  0.0869,  0.0253, -0.2009,  0.1181,  0.0273, -0.2667,\n","                      -0.1386, -0.1426,  0.2495,  0.2070,  0.1191,  0.0455,  0.2068, -0.0517,\n","                      -0.0356,  0.0163,  0.2343,  0.0666, -0.2044, -0.0606, -0.1355, -0.1820,\n","                      -0.0697, -0.0073, -0.2408,  0.2758,  0.0124,  0.1558,  0.2053, -0.2440,\n","                      -0.0325, -0.2475,  0.0206, -0.0226, -0.0356,  0.3103, -0.1047, -0.1924])),\n","             ('incept6.conv1.bn.running_var',\n","              tensor([0.0468, 0.0791, 0.0455, 0.0337, 0.0506, 0.0275, 0.0310, 0.0459, 0.0416,\n","                      0.0401, 0.0310, 0.0245, 0.0469, 0.0371, 0.0654, 0.0579, 0.0702, 0.0591,\n","                      0.0735, 0.0432, 0.0328, 0.0305, 0.0572, 0.0305, 0.0434, 0.0268, 0.0963,\n","                      0.0433, 0.0597, 0.0470, 0.0579, 0.0509, 0.0498, 0.0854, 0.0669, 0.0497,\n","                      0.0360, 0.0510, 0.0300, 0.0743, 0.0419, 0.0747, 0.0476, 0.0306, 0.0952,\n","                      0.0928, 0.0628, 0.0317])),\n","             ('incept6.conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept6.conv3.conv.weight',\n","              tensor([[[[ 1.5726e-02,  2.1561e-02, -1.4175e-03],\n","                        [-2.1689e-02,  3.7533e-03,  5.4196e-05],\n","                        [ 2.6955e-02,  1.5824e-02,  2.0574e-02]],\n","              \n","                       [[-3.6809e-02, -1.0407e-02, -2.5689e-03],\n","                        [-2.2664e-02, -2.6514e-02, -3.3034e-02],\n","                        [-6.2974e-03, -9.0647e-03, -1.0217e-02]],\n","              \n","                       [[ 9.3435e-03, -7.3373e-03, -4.0657e-02],\n","                        [ 1.3183e-02, -2.8803e-02, -3.6558e-02],\n","                        [ 2.2036e-02,  9.9048e-03, -6.8058e-02]],\n","              \n","                       ...,\n","              \n","                       [[-1.7779e-02, -6.3462e-03,  2.1270e-02],\n","                        [-3.3799e-02, -2.2209e-02, -2.9180e-03],\n","                        [-3.5538e-02,  3.5895e-02,  3.0435e-02]],\n","              \n","                       [[-3.5214e-02,  1.4140e-02,  9.6981e-04],\n","                        [ 4.3067e-03, -2.8310e-02,  2.1050e-02],\n","                        [-3.4487e-02,  1.1341e-02, -1.9205e-02]],\n","              \n","                       [[-2.3663e-02, -4.2680e-03,  1.1528e-02],\n","                        [ 4.3661e-03, -1.4973e-02,  1.3795e-02],\n","                        [ 1.7538e-03,  8.5661e-03,  3.1582e-02]]],\n","              \n","              \n","                      [[[-3.7389e-02, -2.9973e-02, -1.0509e-02],\n","                        [-1.3482e-02, -2.9648e-02, -3.2921e-02],\n","                        [ 2.5008e-02, -4.3431e-03,  7.3414e-03]],\n","              \n","                       [[-3.7640e-02, -3.4692e-02, -3.4289e-02],\n","                        [-5.0260e-03,  2.9825e-02,  3.9248e-02],\n","                        [-1.8188e-04,  4.1377e-03,  9.3630e-03]],\n","              \n","                       [[-6.3299e-03, -1.5018e-02, -3.2795e-02],\n","                        [-3.0094e-02, -3.4340e-02,  2.5214e-02],\n","                        [-2.1129e-02, -3.8364e-04,  2.9354e-03]],\n","              \n","                       ...,\n","              \n","                       [[-4.3049e-02, -1.4808e-02,  2.1170e-02],\n","                        [ 4.9851e-03, -3.5671e-02, -2.4629e-02],\n","                        [-2.3750e-02, -4.4532e-02, -1.6450e-02]],\n","              \n","                       [[-3.0158e-02, -3.2976e-02,  3.3645e-02],\n","                        [-1.2023e-02,  4.8603e-03,  1.5823e-02],\n","                        [ 2.8541e-02,  2.7716e-02, -2.3705e-02]],\n","              \n","                       [[-7.9701e-03,  2.0725e-02, -6.5825e-02],\n","                        [-2.1666e-02, -1.4407e-03, -5.9988e-02],\n","                        [ 2.8995e-02,  3.3662e-02,  8.2882e-03]]],\n","              \n","              \n","                      [[[ 1.3646e-02, -4.0824e-02, -4.6875e-02],\n","                        [-1.1898e-02, -1.1406e-02, -4.0715e-02],\n","                        [ 9.8693e-03,  2.4145e-02,  2.7282e-02]],\n","              \n","                       [[ 9.0978e-03,  7.0236e-03,  2.2354e-02],\n","                        [-6.3199e-03, -1.6510e-03, -5.8474e-03],\n","                        [-5.3968e-03, -3.7064e-02, -2.8042e-02]],\n","              \n","                       [[-5.3752e-02, -1.1370e-02, -5.8506e-03],\n","                        [-2.3190e-02, -4.4753e-02,  3.6227e-02],\n","                        [ 2.9939e-02,  5.9286e-03,  4.8455e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 2.6362e-03,  2.3719e-02,  3.0056e-02],\n","                        [-2.3178e-02,  2.6317e-03, -1.7474e-03],\n","                        [ 9.8581e-03,  9.7317e-03, -2.4004e-02]],\n","              \n","                       [[ 1.6767e-02,  4.6718e-03,  3.0679e-02],\n","                        [-3.9467e-03, -4.3449e-02,  2.2705e-03],\n","                        [ 1.0373e-02, -6.2508e-03,  5.3288e-02]],\n","              \n","                       [[ 3.3661e-03,  1.1192e-02,  3.3822e-02],\n","                        [-4.6532e-02, -5.3852e-02, -1.0703e-02],\n","                        [-8.0823e-02, -6.9506e-02, -7.1740e-03]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[-1.5783e-02, -2.7171e-02, -2.1638e-02],\n","                        [ 2.6536e-02,  4.1851e-04, -1.5482e-02],\n","                        [-1.2863e-02, -1.4806e-02, -1.7357e-02]],\n","              \n","                       [[-2.1564e-02,  2.3867e-02,  2.4107e-02],\n","                        [ 1.5501e-02,  1.3501e-02,  7.5908e-04],\n","                        [-1.3508e-02,  1.9080e-02,  6.6278e-03]],\n","              \n","                       [[-9.7196e-03,  1.2739e-02, -1.2452e-02],\n","                        [ 1.8938e-02, -1.3032e-02,  2.0430e-02],\n","                        [ 1.4235e-02,  9.9893e-03,  1.2681e-02]],\n","              \n","                       ...,\n","              \n","                       [[-2.0776e-02,  1.4348e-02,  1.9895e-02],\n","                        [ 2.1789e-02, -5.5581e-03,  7.2611e-03],\n","                        [-1.6103e-02,  1.2308e-02,  8.5034e-03]],\n","              \n","                       [[-2.5057e-02, -1.8384e-02,  1.8687e-02],\n","                        [ 2.5144e-03, -2.5938e-02, -2.2701e-02],\n","                        [ 1.5688e-02, -1.3384e-02,  1.3042e-02]],\n","              \n","                       [[ 9.6608e-03, -2.7635e-02,  2.7512e-02],\n","                        [-2.6303e-03,  1.9954e-02, -1.9370e-03],\n","                        [ 2.3004e-02, -9.8144e-03,  1.3689e-03]]],\n","              \n","              \n","                      [[[ 1.7162e-02,  1.5473e-03, -2.5892e-02],\n","                        [-9.6368e-03, -3.8772e-02,  1.4000e-02],\n","                        [-4.6606e-02, -1.8981e-02, -3.3868e-02]],\n","              \n","                       [[ 3.1549e-02, -6.9490e-03, -2.0819e-02],\n","                        [-1.6822e-02, -1.8592e-02,  3.6117e-02],\n","                        [ 1.2867e-02, -2.6390e-04, -6.4496e-03]],\n","              \n","                       [[-6.1851e-03,  3.5614e-03, -3.3407e-02],\n","                        [-1.6570e-02,  1.7732e-02, -3.9521e-02],\n","                        [ 3.7352e-02,  6.6003e-02, -8.0251e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 9.1088e-03, -1.6776e-02,  1.1734e-02],\n","                        [ 1.9563e-04, -2.1234e-02, -1.1560e-02],\n","                        [-5.1751e-03, -6.8882e-02, -3.2435e-02]],\n","              \n","                       [[-2.3973e-02,  2.6261e-03, -1.6435e-02],\n","                        [ 2.9691e-02,  2.0483e-04, -3.3801e-02],\n","                        [ 2.3924e-02, -1.3142e-02,  6.6515e-03]],\n","              \n","                       [[-5.4169e-03,  3.5812e-03, -4.4884e-02],\n","                        [-3.2619e-02, -2.8764e-02, -7.1459e-03],\n","                        [-5.0639e-02, -3.1858e-02, -3.5168e-02]]],\n","              \n","              \n","                      [[[-1.7613e-02, -1.8827e-02, -1.9302e-02],\n","                        [-1.1833e-02, -3.0224e-02, -3.3330e-02],\n","                        [-1.8997e-02, -3.3222e-02, -4.3989e-02]],\n","              \n","                       [[ 7.1791e-04,  1.0049e-02, -3.4173e-03],\n","                        [ 8.3262e-03, -3.1683e-02, -1.6188e-02],\n","                        [-1.5546e-02, -7.6305e-03,  6.8807e-04]],\n","              \n","                       [[-3.2155e-02, -3.1510e-02, -2.7756e-02],\n","                        [ 2.1928e-02,  2.9467e-02,  4.5585e-02],\n","                        [-8.4468e-03, -3.1905e-02, -5.5252e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 1.1708e-02,  5.6819e-03,  7.3348e-03],\n","                        [ 2.0530e-02,  1.8999e-02,  3.2423e-02],\n","                        [ 4.5863e-02, -7.6154e-04,  3.9480e-02]],\n","              \n","                       [[ 1.5691e-02, -1.9880e-02,  2.5190e-02],\n","                        [ 1.7648e-02,  2.5947e-02, -1.1673e-02],\n","                        [ 4.4897e-02,  2.4566e-02,  9.8336e-03]],\n","              \n","                       [[ 6.3832e-03,  4.1235e-02,  5.6409e-02],\n","                        [-1.4492e-02, -2.9561e-03,  2.4361e-02],\n","                        [-1.7632e-02, -3.1800e-02, -5.0129e-02]]]])),\n","             ('incept6.conv3.conv.bias',\n","              tensor([-0.0050, -0.0137, -0.0067, -0.0083,  0.0017, -0.0217, -0.0145, -0.0001,\n","                       0.0079, -0.0116,  0.0003,  0.0055,  0.0244,  0.0145,  0.0111,  0.0112,\n","                      -0.0164, -0.0038, -0.0222, -0.0195,  0.0159, -0.0192, -0.0088,  0.0256,\n","                      -0.0121, -0.0115, -0.0239,  0.0260, -0.0060, -0.0105, -0.0037, -0.0099,\n","                      -0.0233,  0.0056, -0.0184,  0.0018, -0.0149, -0.0075, -0.0151, -0.0135,\n","                       0.0263,  0.0212,  0.0062, -0.0174, -0.0170,  0.0175,  0.0170,  0.0164,\n","                       0.0056,  0.0057,  0.0069, -0.0100, -0.0076,  0.0036,  0.0189, -0.0109,\n","                      -0.0233, -0.0136,  0.0113,  0.0061,  0.0027,  0.0255,  0.0021,  0.0211,\n","                      -0.0146, -0.0095,  0.0210, -0.0115,  0.0132, -0.0130, -0.0215, -0.0194,\n","                      -0.0248, -0.0246,  0.0021,  0.0229,  0.0068,  0.0140,  0.0146, -0.0145,\n","                      -0.0207, -0.0184,  0.0164,  0.0228, -0.0187,  0.0201,  0.0037, -0.0054,\n","                      -0.0145, -0.0197,  0.0073,  0.0201, -0.0241,  0.0032,  0.0004, -0.0207])),\n","             ('incept6.conv3.bn.weight',\n","              tensor([0.6294, 0.7213, 0.7613, 0.7453, 0.6339, 0.5597, 0.4017, 0.8573, 0.7510,\n","                      0.6942, 0.9074, 0.5386, 0.4932, 0.7876, 0.5709, 0.5350, 0.4920, 0.6532,\n","                      0.0907, 0.8686, 0.2525, 0.7950, 0.6505, 0.3946, 0.8784, 0.4709, 0.7509,\n","                      0.3229, 0.3734, 0.4541, 0.8128, 0.6334, 0.6572, 0.3303, 0.6249, 0.7058,\n","                      0.3614, 0.5309, 0.4881, 0.3766, 0.6680, 0.5187, 0.1499, 0.7771, 0.3525,\n","                      0.2956, 0.8204, 0.8344, 0.2409, 0.2893, 0.3019, 0.8037, 0.2021, 0.6741,\n","                      0.8523, 0.6242, 0.7676, 0.7476, 0.2115, 0.6684, 0.4919, 0.4935, 0.2860,\n","                      0.2626, 0.5334, 0.2307, 0.4938, 0.6345, 0.0444, 0.8517, 0.2131, 0.4701,\n","                      0.7816, 0.5990, 0.7192, 0.4437, 0.5635, 0.2220, 0.6610, 0.2235, 0.3988,\n","                      0.0958, 0.5527, 0.5241, 0.1370, 0.6555, 0.6367, 0.5999, 0.6494, 0.6552,\n","                      0.2954, 0.9036, 0.4280, 0.0940, 0.6319, 0.7090])),\n","             ('incept6.conv3.bn.bias',\n","              tensor([-0.0475, -0.0340, -0.1157, -0.0659, -0.0759, -0.0700, -0.0351, -0.1581,\n","                      -0.0943, -0.0563, -0.1703, -0.0809, -0.0525, -0.0374, -0.0903, -0.0487,\n","                      -0.1030, -0.0817,  0.0140, -0.0190, -0.0103, -0.0889, -0.0755, -0.0589,\n","                      -0.1047, -0.0792, -0.1154, -0.0513, -0.0142, -0.0342, -0.0422, -0.1228,\n","                      -0.0708, -0.0500, -0.0892, -0.0638, -0.0460, -0.0652, -0.0135, -0.0686,\n","                      -0.0872, -0.0405, -0.0018, -0.0673, -0.0470, -0.0082, -0.1155, -0.1114,\n","                      -0.0084,  0.0144, -0.0189, -0.0709, -0.0127, -0.1038, -0.0636, -0.0627,\n","                      -0.0397, -0.0787, -0.0081, -0.0835, -0.0615, -0.0320, -0.0110, -0.0186,\n","                      -0.1159, -0.0111, -0.0399, -0.0574,  0.0039, -0.0703, -0.0065, -0.0354,\n","                      -0.0769, -0.0700, -0.0422, -0.0139, -0.0371, -0.0214, -0.0508,  0.0076,\n","                      -0.0198, -0.0086, -0.0943, -0.0575, -0.0060, -0.0725, -0.0714, -0.0892,\n","                      -0.0726, -0.0886, -0.0028, -0.0723, -0.0479,  0.0021, -0.0588, -0.1077])),\n","             ('incept6.conv3.bn.running_mean',\n","              tensor([-1.6925e-01, -4.0769e-01, -4.5997e-01, -4.3633e-01, -1.4807e-01,\n","                      -3.0724e-01, -2.2941e-01, -5.8225e-01, -6.0548e-01, -6.2366e-01,\n","                      -9.9786e-02,  1.0290e-01, -2.9376e-01, -3.0399e-01,  2.3432e-02,\n","                      -3.1969e-02, -2.0892e-01,  1.7946e-01,  9.6677e-02, -4.6754e-01,\n","                       1.0018e-01,  3.5997e-01,  1.2815e-01,  2.7409e-01, -3.4520e-01,\n","                      -3.1623e-01, -8.6215e-01, -2.0134e-02, -1.6648e-01, -3.8364e-01,\n","                      -1.0243e+00, -2.0771e-01, -4.7356e-01,  2.3141e-01, -2.5659e-01,\n","                       2.0199e-01, -4.6416e-02, -2.6019e-01, -9.7452e-02, -2.2508e-01,\n","                      -2.7479e-01,  1.9450e-01, -7.6570e-02, -9.2931e-01, -9.5013e-02,\n","                       2.4910e-01, -3.0481e-01, -3.2879e-01, -9.9526e-02,  5.3406e-04,\n","                      -1.8887e-01, -6.2716e-01, -1.5706e-01, -1.3528e-01, -8.6461e-01,\n","                      -3.2355e-02, -5.3845e-01, -3.1841e-01,  6.7408e-02, -3.8292e-01,\n","                       4.9435e-01, -2.2961e-01, -8.8429e-02, -7.9759e-02,  2.2221e-02,\n","                       2.4017e-01,  2.0339e-03,  3.0592e-01, -3.4961e-02,  1.0835e-01,\n","                      -1.2527e-01,  5.9368e-02, -3.5507e-01, -6.7476e-01,  1.6190e-01,\n","                      -2.0016e-01,  4.1085e-02,  2.1602e-01,  2.3277e-01, -2.0696e-01,\n","                      -2.7853e-01, -7.8054e-02,  2.6858e-02, -2.6619e-01, -2.1159e-01,\n","                      -4.9916e-02,  1.0068e-01, -4.4644e-01, -2.3266e-01, -1.0399e-02,\n","                      -2.0844e-01, -4.6916e-01,  2.1862e-01,  2.0991e-01, -3.6192e-01,\n","                      -2.9878e-01])),\n","             ('incept6.conv3.bn.running_var',\n","              tensor([0.1395, 0.2018, 0.3333, 0.2303, 0.1885, 0.1659, 0.0835, 0.4007, 0.3368,\n","                      0.2212, 0.3983, 0.1973, 0.2032, 0.2031, 0.2017, 0.1362, 0.1634, 0.2073,\n","                      0.0326, 0.2324, 0.0459, 0.3335, 0.2003, 0.0855, 0.3792, 0.1427, 0.3086,\n","                      0.0739, 0.0899, 0.1308, 0.2736, 0.2374, 0.2300, 0.0865, 0.2635, 0.2508,\n","                      0.0852, 0.1477, 0.1146, 0.1068, 0.2362, 0.1393, 0.0346, 0.2870, 0.0799,\n","                      0.0540, 0.3923, 0.3370, 0.0480, 0.0509, 0.0573, 0.2631, 0.0405, 0.2535,\n","                      0.2917, 0.1686, 0.2775, 0.2702, 0.0387, 0.2687, 0.1236, 0.1462, 0.0510,\n","                      0.0679, 0.1961, 0.0482, 0.1070, 0.1739, 0.0322, 0.2746, 0.0447, 0.1147,\n","                      0.2060, 0.1772, 0.1994, 0.0978, 0.1437, 0.0466, 0.2331, 0.0462, 0.0741,\n","                      0.0335, 0.1949, 0.1594, 0.0304, 0.1484, 0.1930, 0.1868, 0.2217, 0.2734,\n","                      0.0478, 0.3120, 0.0917, 0.0239, 0.2037, 0.3410])),\n","             ('incept6.conv3.bn.num_batches_tracked', tensor(4157)),\n","             ('downsample2.conv.conv.weight',\n","              tensor([[[[ 0.0018, -0.0240,  0.0063],\n","                        [-0.0274, -0.0297,  0.0368],\n","                        [ 0.0052,  0.0105, -0.0181]],\n","              \n","                       [[ 0.0016, -0.0080,  0.0150],\n","                        [-0.0306, -0.0120, -0.0036],\n","                        [-0.0309, -0.0218, -0.0166]],\n","              \n","                       [[-0.0223, -0.0217,  0.0199],\n","                        [ 0.0150,  0.0100, -0.0134],\n","                        [ 0.0109, -0.0138,  0.0002]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0219,  0.0142, -0.0161],\n","                        [-0.0225,  0.0176, -0.0030],\n","                        [-0.0194,  0.0296, -0.0195]],\n","              \n","                       [[-0.0148,  0.0156, -0.0081],\n","                        [ 0.0122, -0.0121, -0.0092],\n","                        [-0.0122, -0.0158, -0.0101]],\n","              \n","                       [[-0.0256, -0.0209,  0.0267],\n","                        [ 0.0138,  0.0072, -0.0192],\n","                        [-0.0430, -0.0306, -0.0041]]],\n","              \n","              \n","                      [[[-0.0266,  0.0235,  0.0147],\n","                        [ 0.0175, -0.0151,  0.0024],\n","                        [ 0.0512,  0.0129, -0.0213]],\n","              \n","                       [[ 0.0100,  0.0229, -0.0294],\n","                        [-0.0036, -0.0347, -0.0347],\n","                        [ 0.0083, -0.0197, -0.0247]],\n","              \n","                       [[-0.0168, -0.0140, -0.0401],\n","                        [-0.0207, -0.0345, -0.0305],\n","                        [-0.0282, -0.0183, -0.0208]],\n","              \n","                       ...,\n","              \n","                       [[-0.0054, -0.0154,  0.0127],\n","                        [-0.0171,  0.0084,  0.0125],\n","                        [-0.0252,  0.0257,  0.0267]],\n","              \n","                       [[-0.0303,  0.0096,  0.0194],\n","                        [ 0.0185, -0.0112, -0.0174],\n","                        [-0.0108,  0.0071,  0.0139]],\n","              \n","                       [[-0.0284, -0.0143, -0.0335],\n","                        [-0.0394,  0.0012,  0.0046],\n","                        [-0.0380, -0.0082, -0.0496]]],\n","              \n","              \n","                      [[[-0.0201, -0.0157,  0.0260],\n","                        [ 0.0109,  0.0075,  0.0232],\n","                        [-0.0094,  0.0286, -0.0065]],\n","              \n","                       [[-0.0150,  0.0022,  0.0219],\n","                        [-0.0240,  0.0162, -0.0199],\n","                        [-0.0058, -0.0156,  0.0194]],\n","              \n","                       [[ 0.0213,  0.0156,  0.0008],\n","                        [-0.0255, -0.0124,  0.0195],\n","                        [-0.0009, -0.0162, -0.0160]],\n","              \n","                       ...,\n","              \n","                       [[-0.0078, -0.0137,  0.0029],\n","                        [-0.0215, -0.0153, -0.0222],\n","                        [-0.0133,  0.0062,  0.0183]],\n","              \n","                       [[ 0.0269,  0.0205, -0.0261],\n","                        [ 0.0097,  0.0081, -0.0185],\n","                        [-0.0095,  0.0193, -0.0126]],\n","              \n","                       [[ 0.0063,  0.0148, -0.0287],\n","                        [-0.0177, -0.0168, -0.0238],\n","                        [ 0.0070,  0.0035, -0.0270]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[-0.0032,  0.0122, -0.0140],\n","                        [-0.0315, -0.0138, -0.0677],\n","                        [-0.0060, -0.0205,  0.0285]],\n","              \n","                       [[ 0.0128,  0.0209, -0.0223],\n","                        [ 0.0422,  0.0016,  0.0198],\n","                        [-0.0013,  0.0048, -0.0124]],\n","              \n","                       [[ 0.0023,  0.0315,  0.0033],\n","                        [-0.0087, -0.0205, -0.0083],\n","                        [-0.0336, -0.0021, -0.0208]],\n","              \n","                       ...,\n","              \n","                       [[-0.0241, -0.0054, -0.0068],\n","                        [-0.0120, -0.0085, -0.0280],\n","                        [-0.0306,  0.0074,  0.0154]],\n","              \n","                       [[-0.0098,  0.0066,  0.0152],\n","                        [-0.0294, -0.0071,  0.0197],\n","                        [-0.0358, -0.0020,  0.0134]],\n","              \n","                       [[-0.0119,  0.0251, -0.0237],\n","                        [-0.0301, -0.0266,  0.0047],\n","                        [-0.0101, -0.0397, -0.0015]]],\n","              \n","              \n","                      [[[ 0.0280, -0.0256, -0.0223],\n","                        [-0.0133, -0.0034,  0.0043],\n","                        [ 0.0080, -0.0214,  0.0171]],\n","              \n","                       [[ 0.0185,  0.0084, -0.0044],\n","                        [-0.0031, -0.0311, -0.0036],\n","                        [ 0.0135,  0.0008, -0.0252]],\n","              \n","                       [[-0.0056, -0.0196,  0.0038],\n","                        [-0.0084, -0.0200, -0.0200],\n","                        [ 0.0284,  0.0082,  0.0115]],\n","              \n","                       ...,\n","              \n","                       [[-0.0136, -0.0218,  0.0226],\n","                        [ 0.0254, -0.0168, -0.0232],\n","                        [-0.0262, -0.0259, -0.0195]],\n","              \n","                       [[-0.0160, -0.0219, -0.0203],\n","                        [-0.0031, -0.0158,  0.0073],\n","                        [ 0.0218, -0.0174, -0.0121]],\n","              \n","                       [[ 0.0223, -0.0070, -0.0284],\n","                        [ 0.0010, -0.0276,  0.0184],\n","                        [-0.0272, -0.0257, -0.0110]]],\n","              \n","              \n","                      [[[-0.0173,  0.0124,  0.0067],\n","                        [-0.0072,  0.0100, -0.0077],\n","                        [ 0.0218, -0.0036, -0.0006]],\n","              \n","                       [[-0.0095,  0.0143, -0.0204],\n","                        [-0.0217,  0.0149, -0.0254],\n","                        [ 0.0269, -0.0204,  0.0084]],\n","              \n","                       [[ 0.0034, -0.0244, -0.0257],\n","                        [-0.0235, -0.0090, -0.0256],\n","                        [ 0.0158,  0.0276,  0.0025]],\n","              \n","                       ...,\n","              \n","                       [[-0.0188, -0.0220,  0.0165],\n","                        [-0.0079,  0.0100,  0.0234],\n","                        [-0.0150,  0.0155,  0.0046]],\n","              \n","                       [[-0.0058,  0.0031, -0.0105],\n","                        [-0.0184,  0.0285,  0.0197],\n","                        [-0.0156,  0.0124, -0.0221]],\n","              \n","                       [[-0.0028, -0.0188, -0.0121],\n","                        [-0.0217, -0.0171,  0.0018],\n","                        [-0.0174,  0.0038,  0.0037]]]])),\n","             ('downsample2.conv.conv.bias',\n","              tensor([-0.0213, -0.0244, -0.0194, -0.0032,  0.0024,  0.0204,  0.0002, -0.0242,\n","                      -0.0082, -0.0129, -0.0055, -0.0007, -0.0271,  0.0119,  0.0163,  0.0206,\n","                      -0.0127, -0.0107, -0.0222,  0.0150,  0.0081,  0.0140,  0.0269, -0.0058,\n","                       0.0121, -0.0084,  0.0059,  0.0102, -0.0225, -0.0019,  0.0199, -0.0264,\n","                      -0.0273,  0.0208,  0.0037,  0.0185,  0.0142,  0.0270,  0.0180, -0.0091,\n","                      -0.0065,  0.0216, -0.0075, -0.0073, -0.0200,  0.0202, -0.0047, -0.0164,\n","                      -0.0003,  0.0053,  0.0244,  0.0037, -0.0096,  0.0039,  0.0103, -0.0203,\n","                      -0.0028,  0.0167,  0.0146,  0.0184,  0.0157, -0.0023,  0.0063, -0.0191,\n","                      -0.0142,  0.0069,  0.0133,  0.0111,  0.0149, -0.0094, -0.0260, -0.0261,\n","                       0.0058,  0.0067, -0.0197, -0.0020, -0.0113, -0.0139,  0.0225,  0.0129,\n","                      -0.0199,  0.0014,  0.0242,  0.0152,  0.0217,  0.0056, -0.0151,  0.0235,\n","                       0.0004,  0.0089,  0.0061,  0.0017,  0.0008, -0.0156, -0.0080, -0.0217])),\n","             ('downsample2.conv.bn.weight',\n","              tensor([0.4640, 0.7597, 0.0996, 0.4194, 0.6431, 0.2535, 0.4685, 0.0703, 0.2085,\n","                      0.2030, 0.6531, 0.3701, 0.7118, 0.3337, 0.9780, 0.0583, 0.0785, 0.5987,\n","                      0.2856, 0.4373, 0.1472, 0.5835, 0.2390, 0.6005, 0.7223, 0.6280, 0.5523,\n","                      0.6251, 0.6287, 0.1689, 0.8642, 0.2410, 0.5610, 0.8862, 0.7177, 0.9282,\n","                      0.7972, 0.9352, 0.8721, 0.6208, 0.7242, 0.2166, 0.2608, 0.6160, 0.1964,\n","                      0.1218, 0.6015, 0.6441, 0.3556, 0.1232, 0.4246, 0.6738, 0.8927, 0.0713,\n","                      0.7578, 0.0238, 0.0313, 0.7101, 0.8685, 0.4070, 0.3024, 0.5286, 0.4599,\n","                      0.6870, 0.4379, 0.5388, 0.0644, 0.2781, 0.7335, 0.8788, 0.3377, 0.7041,\n","                      0.8438, 0.8415, 0.5985, 0.4420, 0.5583, 0.5155, 0.8069, 0.7835, 0.1369,\n","                      0.7805, 0.4628, 0.9957, 0.0918, 0.6473, 0.6147, 0.6371, 0.4000, 0.4586,\n","                      0.2079, 0.0276, 0.8572, 0.7714, 0.2377, 0.1450])),\n","             ('downsample2.conv.bn.bias',\n","              tensor([-0.0151, -0.0631, -0.0052, -0.0227, -0.0365, -0.0049, -0.0169,  0.0003,\n","                       0.0047, -0.0072, -0.0296, -0.0092, -0.0487, -0.0030, -0.0625, -0.0077,\n","                      -0.0058, -0.0168, -0.0045, -0.0189, -0.0001, -0.0099,  0.0041, -0.0255,\n","                      -0.0186, -0.0218, -0.0239, -0.0102, -0.0238, -0.0051, -0.0353, -0.0038,\n","                      -0.0276, -0.0510, -0.0352, -0.0943, -0.0335, -0.0270, -0.0289, -0.0117,\n","                      -0.0310, -0.0115, -0.0028, -0.0238, -0.0096, -0.0026, -0.0113, -0.0161,\n","                      -0.0127,  0.0075, -0.0100, -0.0275, -0.0465, -0.0055, -0.0693, -0.0060,\n","                      -0.0069, -0.0235, -0.0877, -0.0154, -0.0111,  0.0022, -0.0246, -0.0150,\n","                      -0.0202, -0.0001, -0.0089, -0.0006, -0.0293, -0.0581, -0.0080, -0.0105,\n","                      -0.0406, -0.0375, -0.0228, -0.0238, -0.0249, -0.0176, -0.0411, -0.0180,\n","                       0.0039, -0.0277, -0.0163, -0.0374, -0.0011, -0.0380, -0.0230, -0.0206,\n","                      -0.0218, -0.0160, -0.0138, -0.0056, -0.0275, -0.0381, -0.0047, -0.0011])),\n","             ('downsample2.conv.bn.running_mean',\n","              tensor([-2.4104e-01, -3.8473e-01, -8.7378e-02, -9.6072e-02, -2.3727e-01,\n","                      -3.2320e-02, -3.7919e-01, -5.2579e-02, -9.3861e-02, -6.7153e-02,\n","                       9.8466e-02,  5.8586e-02, -1.8340e-01,  1.3786e-01,  4.0475e-01,\n","                      -1.4161e-02, -1.2399e-02, -2.2424e-01,  2.4861e-01, -3.5332e-01,\n","                       2.3464e-01, -2.4129e-01, -1.6498e-01,  4.5105e-01,  5.5311e-01,\n","                       1.1261e-02,  1.2717e-01, -2.6938e-01, -3.0822e-01,  1.1284e-02,\n","                       6.8386e-01, -9.8850e-02,  1.2309e-01,  2.5165e-01, -3.1000e-01,\n","                       1.3916e-02,  5.5987e-01, -3.8971e-01, -1.3989e-01,  5.7401e-02,\n","                      -4.0409e-01,  7.3332e-02, -9.5528e-02, -1.1552e-01,  4.3034e-02,\n","                       1.2214e-04, -2.2066e-01,  3.6002e-01,  3.6461e-02,  1.3625e-04,\n","                       3.9526e-01,  1.4386e-01, -3.7972e-01, -2.6832e-03, -1.2529e-01,\n","                       6.5617e-02,  1.5639e-01, -1.7116e-01,  1.5318e-01, -2.8642e-02,\n","                      -3.1669e-01,  2.6343e-01,  7.5656e-02, -3.0080e-01,  3.9712e-01,\n","                       6.1115e-02,  1.2083e-01, -2.8775e-01,  3.9893e-01, -3.4326e-01,\n","                       1.2782e-01, -7.1644e-02, -8.2206e-02, -3.6033e-01, -1.6921e-01,\n","                      -3.9154e-02, -9.8217e-02, -6.9534e-02, -3.3937e-02, -2.0216e-01,\n","                       1.3144e-01, -3.0354e-01,  1.2170e-01, -1.9826e-02, -5.9171e-02,\n","                       3.6832e-02,  1.7505e-01,  5.6123e-02,  2.4907e-01,  1.5154e-01,\n","                       1.0640e-01,  3.6254e-02,  6.6431e-01, -2.3839e-01, -4.9351e-02,\n","                       3.2867e-02])),\n","             ('downsample2.conv.bn.running_var',\n","              tensor([0.0672, 0.1104, 0.0266, 0.0509, 0.0713, 0.0344, 0.0437, 0.0279, 0.0265,\n","                      0.0273, 0.0674, 0.0311, 0.1093, 0.0482, 0.1221, 0.0284, 0.0310, 0.0587,\n","                      0.0340, 0.0474, 0.0406, 0.0791, 0.0270, 0.0897, 0.0912, 0.0640, 0.0569,\n","                      0.0680, 0.0720, 0.0234, 0.1059, 0.0359, 0.0752, 0.1232, 0.0753, 0.1477,\n","                      0.0932, 0.1181, 0.0846, 0.1091, 0.0796, 0.0391, 0.0397, 0.0771, 0.0417,\n","                      0.0341, 0.0816, 0.0640, 0.0401, 0.0266, 0.0503, 0.0776, 0.1139, 0.0224,\n","                      0.1230, 0.0247, 0.0224, 0.0761, 0.1423, 0.0642, 0.0440, 0.0703, 0.0499,\n","                      0.0545, 0.0576, 0.0633, 0.0272, 0.0329, 0.0822, 0.1193, 0.0304, 0.1098,\n","                      0.1003, 0.1040, 0.0705, 0.0597, 0.0795, 0.0418, 0.1072, 0.0984, 0.0251,\n","                      0.0844, 0.0508, 0.1627, 0.0219, 0.0798, 0.0705, 0.0775, 0.0434, 0.0626,\n","                      0.0289, 0.0300, 0.1303, 0.0938, 0.0386, 0.0256])),\n","             ('downsample2.conv.bn.num_batches_tracked', tensor(4157)),\n","             ('incept7.conv1.conv.weight', tensor([[[[ 0.0128]],\n","              \n","                       [[-0.0733]],\n","              \n","                       [[ 0.0080]],\n","              \n","                       ...,\n","              \n","                       [[-0.0464]],\n","              \n","                       [[ 0.0235]],\n","              \n","                       [[ 0.0023]]],\n","              \n","              \n","                      [[[-0.0149]],\n","              \n","                       [[-0.0242]],\n","              \n","                       [[-0.0617]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0006]],\n","              \n","                       [[ 0.0126]],\n","              \n","                       [[-0.0456]]],\n","              \n","              \n","                      [[[-0.0416]],\n","              \n","                       [[ 0.0211]],\n","              \n","                       [[-0.0325]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0570]],\n","              \n","                       [[ 0.0235]],\n","              \n","                       [[ 0.0096]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[-0.0297]],\n","              \n","                       [[-0.0607]],\n","              \n","                       [[-0.0287]],\n","              \n","                       ...,\n","              \n","                       [[-0.0359]],\n","              \n","                       [[-0.0646]],\n","              \n","                       [[-0.0589]]],\n","              \n","              \n","                      [[[ 0.0418]],\n","              \n","                       [[-0.0219]],\n","              \n","                       [[-0.0214]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0500]],\n","              \n","                       [[ 0.0489]],\n","              \n","                       [[-0.0518]]],\n","              \n","              \n","                      [[[ 0.0181]],\n","              \n","                       [[-0.0034]],\n","              \n","                       [[ 0.0404]],\n","              \n","                       ...,\n","              \n","                       [[-0.0598]],\n","              \n","                       [[ 0.0449]],\n","              \n","                       [[-0.0345]]]])),\n","             ('incept7.conv1.conv.bias',\n","              tensor([-4.9597e-02, -4.5335e-02,  1.2806e-02, -2.7313e-02, -3.5892e-02,\n","                       2.2770e-02, -1.5948e-02,  3.3430e-02,  1.8819e-02, -3.4282e-02,\n","                       9.1505e-03, -2.0268e-02,  1.4758e-02,  2.6064e-02,  5.3524e-02,\n","                      -5.5864e-03,  3.0598e-02, -3.7651e-02,  1.7236e-02,  2.9180e-02,\n","                       2.2430e-02,  6.2467e-03, -5.3765e-02,  4.3902e-02,  6.3047e-02,\n","                       3.3071e-02,  4.2562e-02,  3.0801e-02,  1.7847e-02,  2.7565e-02,\n","                      -5.5595e-03,  2.4972e-03, -3.7798e-02, -1.3229e-02, -1.2565e-02,\n","                       2.5558e-02,  5.4495e-04,  4.5470e-03, -5.5068e-02, -3.0455e-02,\n","                       1.9236e-02,  3.9908e-02,  2.4814e-02,  5.2260e-02, -5.1958e-02,\n","                      -6.2437e-02,  4.7619e-02, -1.0477e-02,  3.5014e-02,  2.9697e-02,\n","                      -2.6382e-02, -1.7254e-02, -5.1026e-02, -3.3977e-02, -4.7743e-02,\n","                       5.1350e-02, -1.8921e-02, -4.7037e-02,  5.4722e-02,  2.1687e-02,\n","                      -1.3631e-02, -2.7929e-04,  4.9224e-02, -3.8451e-02, -1.1595e-02,\n","                       6.3785e-02, -4.2268e-02, -4.2344e-02, -4.7787e-02, -3.1905e-02,\n","                      -5.8079e-02, -5.6158e-02,  4.2197e-02,  3.8671e-02,  5.0926e-02,\n","                       4.1927e-02,  9.0765e-03,  4.7466e-02,  6.3427e-02,  4.5601e-02,\n","                      -4.0748e-03,  5.8520e-02,  1.7201e-04, -4.8546e-02, -6.1418e-03,\n","                       3.4068e-02, -5.5582e-02,  4.7610e-02,  6.1385e-02,  1.8221e-02,\n","                      -2.1422e-02,  6.2672e-02, -6.2991e-02, -5.4732e-02,  6.2928e-02,\n","                       2.4573e-02, -4.1271e-02,  1.7617e-02,  5.0353e-02, -1.2438e-02,\n","                       4.4312e-02,  4.4905e-02,  3.1562e-02,  6.2392e-02,  2.7626e-02,\n","                      -4.0412e-02, -2.4930e-02,  6.8796e-03, -4.0334e-02,  1.3727e-02,\n","                      -1.7721e-02, -3.6479e-02,  1.0476e-02,  4.2571e-02, -1.3031e-02,\n","                      -5.3866e-02,  4.1760e-02,  2.2185e-02, -7.0108e-03,  5.0970e-03,\n","                       2.1971e-02,  2.1448e-02, -3.6182e-02,  4.8339e-02,  6.2581e-02,\n","                      -4.9688e-02,  4.6753e-02,  5.6913e-02, -3.3970e-02,  4.6480e-02,\n","                      -4.3116e-02, -5.6044e-02,  4.7662e-02,  5.2543e-02, -3.6566e-02,\n","                      -1.8499e-02, -4.1605e-02, -1.4555e-02,  2.3699e-02,  4.1176e-02,\n","                      -1.6136e-02,  9.0081e-03, -6.0443e-03,  1.5415e-02,  2.7237e-02,\n","                      -4.2806e-03,  1.5252e-02,  3.5900e-02,  1.9413e-02, -1.9256e-02,\n","                      -8.6937e-03, -2.6473e-02,  4.7575e-02,  1.0252e-02,  6.4544e-02,\n","                       2.8026e-02, -3.0197e-02,  1.6093e-02,  2.6306e-02,  7.8784e-03,\n","                      -2.4990e-02,  4.3698e-02,  1.4629e-02, -5.5883e-02, -6.2753e-02,\n","                       6.0517e-02,  3.3397e-02,  6.1649e-02, -5.4980e-02,  5.7622e-02,\n","                       4.6144e-02,  1.4260e-02,  1.9624e-02,  5.8275e-02, -1.1041e-02,\n","                       1.5028e-05])),\n","             ('incept7.conv1.bn.weight',\n","              tensor([7.6344e-01, 8.4019e-01, 8.2449e-01, 9.3810e-01, 1.3577e-01, 7.3338e-01,\n","                      7.3129e-01, 7.4042e-01, 4.2254e-02, 8.1939e-01, 9.5520e-01, 8.0419e-01,\n","                      8.5589e-01, 2.1257e-02, 9.2709e-01, 6.8084e-01, 4.4255e-01, 1.9706e-01,\n","                      5.2408e-02, 3.0668e-01, 7.7806e-01, 3.5125e-01, 5.5252e-01, 3.9147e-01,\n","                      5.2072e-01, 1.2604e-01, 2.7224e-01, 8.7959e-01, 3.6281e-01, 8.9247e-01,\n","                      9.0021e-01, 6.1570e-01, 9.1200e-01, 7.7417e-01, 6.2865e-01, 1.6000e-01,\n","                      1.3434e-01, 2.2771e-01, 5.9916e-02, 3.1616e-01, 7.4032e-01, 3.7517e-02,\n","                      7.7989e-01, 4.2426e-01, 3.6087e-01, 3.6417e-01, 4.2019e-01, 8.7656e-01,\n","                      7.8578e-02, 6.4830e-01, 4.6135e-01, 2.0186e-01, 9.0183e-01, 7.6269e-01,\n","                      6.9729e-01, 6.4811e-01, 1.5720e-01, 7.1669e-01, 5.4899e-01, 4.5496e-01,\n","                      1.0499e-01, 7.7925e-01, 6.8305e-01, 3.8319e-01, 3.1589e-01, 4.6663e-01,\n","                      5.9024e-01, 7.0240e-01, 8.7864e-01, 5.6227e-01, 7.3244e-01, 5.7684e-01,\n","                      4.3112e-03, 2.7227e-01, 8.1020e-01, 5.4966e-02, 6.8983e-02, 5.6926e-01,\n","                      8.1621e-01, 5.7510e-01, 6.7640e-01, 9.5924e-01, 4.4281e-01, 2.9384e-01,\n","                      5.3290e-01, 9.5970e-01, 6.0495e-01, 5.4794e-01, 6.9985e-01, 3.3338e-01,\n","                      1.9845e-02, 3.6208e-01, 2.2487e-01, 9.5663e-01, 2.0333e-01, 5.6337e-01,\n","                      4.8233e-01, 2.7017e-01, 4.7439e-02, 3.2044e-01, 2.4301e-01, 5.5384e-01,\n","                      7.6910e-01, 6.3897e-02, 6.1463e-01, 6.5101e-01, 8.7317e-01, 8.6691e-01,\n","                      8.2179e-01, 7.7932e-01, 8.8629e-01, 8.6246e-01, 4.5542e-01, 3.5266e-01,\n","                      8.4761e-02, 3.7321e-02, 1.1590e-01, 4.7398e-02, 2.9134e-01, 6.7699e-01,\n","                      6.5538e-01, 4.8043e-02, 3.2674e-01, 7.7954e-01, 2.5366e-01, 8.6595e-01,\n","                      5.1777e-01, 3.9789e-01, 5.6591e-01, 3.1598e-01, 1.2027e-01, 6.9471e-02,\n","                      2.0384e-01, 2.4676e-01, 9.9561e-02, 5.4842e-01, 5.0842e-01, 7.1707e-01,\n","                      2.2465e-01, 2.5833e-01, 4.3585e-01, 6.8250e-05, 2.7956e-01, 4.5037e-01,\n","                      4.4947e-01, 9.3917e-01, 8.0534e-01, 8.8912e-01, 2.1511e-01, 9.3103e-01,\n","                      8.8894e-01, 7.8437e-02, 5.0475e-01, 8.0511e-01, 6.1545e-01, 5.2966e-01,\n","                      7.1517e-01, 3.0631e-01, 9.2422e-01, 3.4701e-01, 6.1785e-01, 1.7929e-02,\n","                      5.5917e-01, 5.7530e-01, 9.9074e-01, 7.5547e-01, 3.0473e-01, 3.0442e-02,\n","                      5.0767e-01, 4.4476e-01, 1.9653e-01, 5.1176e-01, 6.7906e-01, 2.6621e-01,\n","                      4.2581e-01, 6.3589e-01])),\n","             ('incept7.conv1.bn.bias',\n","              tensor([-0.0341, -0.0461, -0.0212, -0.0721, -0.0060, -0.0284, -0.0225, -0.0277,\n","                       0.0080, -0.0300, -0.0321, -0.0167, -0.0756, -0.0051, -0.0160, -0.0261,\n","                      -0.0145, -0.0022,  0.0014, -0.0199, -0.0296, -0.0118, -0.0199, -0.0015,\n","                      -0.0187, -0.0030, -0.0094, -0.0309, -0.0132, -0.0167, -0.0295, -0.0278,\n","                      -0.0503, -0.0518, -0.0112,  0.0022, -0.0137, -0.0021, -0.0133, -0.0133,\n","                      -0.0312,  0.0010, -0.0402, -0.0054, -0.0034, -0.0172, -0.0099, -0.0285,\n","                       0.0052, -0.0025, -0.0163, -0.0163, -0.0372, -0.0097, -0.0345, -0.0310,\n","                      -0.0085, -0.0147, -0.0186, -0.0127, -0.0047, -0.0342, -0.0176, -0.0207,\n","                      -0.0098, -0.0271, -0.0365, -0.0278, -0.0132, -0.0301, -0.0270, -0.0154,\n","                      -0.0033, -0.0075, -0.0316, -0.0189, -0.0016, -0.0376, -0.0276, -0.0310,\n","                      -0.0512, -0.0337, -0.0109, -0.0169, -0.0224, -0.0540,  0.0054, -0.0199,\n","                      -0.0249, -0.0007, -0.0019, -0.0109, -0.0050, -0.0203, -0.0116, -0.0250,\n","                      -0.0188, -0.0118, -0.0048, -0.0214, -0.0105, -0.0330, -0.0223, -0.0139,\n","                      -0.0248, -0.0345, -0.0281, -0.0462, -0.0326, -0.1027, -0.0466, -0.0246,\n","                      -0.0063, -0.0100, -0.0025, -0.0010,  0.0075,  0.0071, -0.0150, -0.0235,\n","                      -0.0273,  0.0005, -0.0261, -0.0227, -0.0143, -0.0292, -0.0176, -0.0077,\n","                      -0.0188, -0.0105, -0.0089, -0.0129, -0.0015, -0.0014,  0.0031, -0.0192,\n","                      -0.0312, -0.0246, -0.0104, -0.0109, -0.0155, -0.0005, -0.0032, -0.0099,\n","                      -0.0117, -0.0347, -0.0120, -0.0243, -0.0040, -0.0453, -0.0259, -0.0075,\n","                      -0.0255, -0.0165, -0.0275, -0.0192, -0.0182, -0.0132, -0.0346, -0.0104,\n","                      -0.0306, -0.0059, -0.0214, -0.0223, -0.0588, -0.0314, -0.0064,  0.0020,\n","                       0.0001, -0.0120, -0.0061, -0.0295, -0.0090, -0.0129, -0.0027, -0.0212])),\n","             ('incept7.conv1.bn.running_mean',\n","              tensor([ 0.5423, -0.4143,  0.1068,  0.5264, -0.0424, -0.1143, -0.0887, -0.2009,\n","                       0.2743,  0.3193, -0.4848, -0.3885,  0.4904, -0.0847,  0.4441, -0.1194,\n","                       0.0184, -0.0391, -0.1240, -0.3205, -0.0217, -0.3156, -0.5185,  0.1360,\n","                       0.5079, -0.1145,  0.1504,  0.3471,  0.1680,  0.2286, -0.5243, -0.0303,\n","                       0.7144,  0.3649, -0.0646,  0.1257, -0.1758, -0.7114, -0.2258, -0.1300,\n","                       0.7897, -0.1154,  0.6054,  0.3481,  0.3629,  0.3410,  0.6337,  0.1598,\n","                       0.8241, -0.3376, -0.3540, -0.4627, -0.5534,  0.5902,  0.3957,  0.8210,\n","                      -0.0407, -0.1753,  0.2581, -0.4497, -0.1951,  0.4961,  0.6458, -0.2262,\n","                      -0.0869,  0.1248, -0.0548, -0.4889,  0.5771, -0.0749,  0.1306,  0.5201,\n","                      -0.2818, -0.2976, -0.1203, -0.4179, -0.0318,  0.1761,  0.5804,  0.3457,\n","                       0.4656,  0.7539, -0.1751,  0.3829, -0.0369,  0.3457, -0.0997,  0.8146,\n","                       0.4107,  0.3575,  0.4914, -0.0077, -0.3519, -0.0131,  0.6466, -0.0540,\n","                       0.0573,  0.1915,  0.3222, -0.0677,  0.0870,  0.5501,  0.0880,  0.0588,\n","                       0.4468,  0.1724, -0.2298,  0.3592, -0.0772,  0.4789,  0.5939, -0.9477,\n","                      -0.0779, -0.1927,  0.0877,  0.1098, -0.3533, -0.1696, -0.0435,  0.1005,\n","                       0.0830, -0.0879,  0.3783, -0.5909, -0.1032, -0.2789,  0.1833,  0.4008,\n","                       0.5542,  0.2972,  0.0528, -0.4141,  0.1360,  0.2443, -0.1169, -0.0488,\n","                       0.1521, -0.0665,  0.0770,  0.2829, -0.5339, -0.4021,  0.5266, -0.1742,\n","                       0.4166, -0.4390,  0.0345,  0.4838, -0.0114,  0.1812,  0.3202, -0.0520,\n","                       0.3957,  0.0611,  0.1506, -0.0144,  0.1425,  0.1028, -0.2879, -0.0193,\n","                      -0.1221,  0.1458, -0.2435, -0.0238, -0.1260, -0.2105, -0.1366, -0.1203,\n","                      -0.3435, -0.1856, -0.2328, -0.0964, -0.6195, -0.4536, -0.1249, -0.0848])),\n","             ('incept7.conv1.bn.running_var',\n","              tensor([0.0748, 0.0813, 0.0818, 0.1008, 0.0402, 0.0635, 0.0750, 0.0595, 0.0552,\n","                      0.0817, 0.1000, 0.0773, 0.0728, 0.0451, 0.0803, 0.0795, 0.0485, 0.0398,\n","                      0.0325, 0.0463, 0.0638, 0.0589, 0.0824, 0.0533, 0.0737, 0.0508, 0.0459,\n","                      0.0744, 0.0377, 0.0868, 0.0755, 0.0463, 0.0939, 0.0613, 0.0929, 0.0449,\n","                      0.0346, 0.0565, 0.0462, 0.0478, 0.0940, 0.0420, 0.0703, 0.0550, 0.0429,\n","                      0.0654, 0.0744, 0.0645, 0.0539, 0.0659, 0.0773, 0.0447, 0.0972, 0.0750,\n","                      0.0664, 0.0755, 0.0453, 0.0640, 0.0661, 0.0506, 0.0437, 0.0576, 0.0833,\n","                      0.0584, 0.0426, 0.0704, 0.0587, 0.0988, 0.0756, 0.0486, 0.0701, 0.0747,\n","                      0.0412, 0.0525, 0.0757, 0.0438, 0.0332, 0.0905, 0.1021, 0.0621, 0.0642,\n","                      0.0892, 0.0396, 0.0644, 0.0703, 0.0734, 0.0617, 0.1126, 0.0648, 0.0546,\n","                      0.0619, 0.0584, 0.0618, 0.0933, 0.0559, 0.0530, 0.0735, 0.0697, 0.0476,\n","                      0.0534, 0.0449, 0.0593, 0.0662, 0.0286, 0.0691, 0.0663, 0.0970, 0.0665,\n","                      0.0788, 0.0602, 0.0972, 0.1020, 0.0644, 0.0446, 0.0417, 0.0476, 0.0412,\n","                      0.0409, 0.0580, 0.0435, 0.0586, 0.0410, 0.0594, 0.0874, 0.0558, 0.0725,\n","                      0.0773, 0.0501, 0.0704, 0.0432, 0.0467, 0.0559, 0.0444, 0.0463, 0.0526,\n","                      0.0375, 0.0649, 0.0554, 0.0486, 0.0664, 0.0651, 0.0586, 0.0575, 0.0582,\n","                      0.0566, 0.0823, 0.0825, 0.0821, 0.0595, 0.0700, 0.0670, 0.0430, 0.0692,\n","                      0.0600, 0.0620, 0.0498, 0.0505, 0.0390, 0.0842, 0.0345, 0.0585, 0.0560,\n","                      0.0774, 0.0623, 0.0877, 0.0692, 0.0610, 0.0365, 0.0710, 0.0605, 0.0376,\n","                      0.0572, 0.0921, 0.0494, 0.0617, 0.0982])),\n","             ('incept7.conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept7.conv3.conv.weight',\n","              tensor([[[[-1.8162e-02, -7.4176e-03,  4.4168e-03],\n","                        [-1.6247e-02,  5.2376e-03,  4.4165e-03],\n","                        [-4.6972e-03,  1.3975e-02, -1.2185e-02]],\n","              \n","                       [[ 3.8969e-03,  1.2254e-02,  2.3524e-03],\n","                        [-1.5582e-03, -1.4888e-02,  4.2802e-03],\n","                        [-1.8604e-02, -2.2319e-02, -1.1496e-03]],\n","              \n","                       [[ 7.4523e-03,  7.9460e-03,  9.8997e-03],\n","                        [-1.1198e-02,  1.9044e-02, -1.7420e-02],\n","                        [-4.7909e-03,  6.6881e-03,  1.9897e-02]],\n","              \n","                       ...,\n","              \n","                       [[-1.4032e-03,  6.7343e-03, -5.7113e-03],\n","                        [-1.4151e-02, -9.5889e-03, -1.5084e-02],\n","                        [-4.4868e-03,  1.4147e-03, -2.0314e-03]],\n","              \n","                       [[-5.5194e-03, -1.3926e-02,  8.0958e-03],\n","                        [ 7.5264e-03,  1.2558e-02,  1.4340e-02],\n","                        [ 9.4850e-03, -6.8960e-03, -1.1974e-03]],\n","              \n","                       [[-2.6565e-02,  2.0927e-02,  1.0337e-02],\n","                        [-2.0388e-02,  5.8979e-03,  2.4037e-02],\n","                        [-2.4354e-02, -9.8148e-03, -2.5494e-03]]],\n","              \n","              \n","                      [[[ 9.3007e-03,  2.1908e-02,  2.2462e-02],\n","                        [ 4.2637e-03, -1.6134e-02, -1.1471e-02],\n","                        [ 2.3592e-02,  2.0923e-02, -2.3670e-03]],\n","              \n","                       [[-2.1885e-03, -9.2119e-03,  1.2250e-02],\n","                        [ 1.9183e-02, -1.4824e-04, -2.8047e-03],\n","                        [-8.2002e-03,  3.9053e-03,  2.2797e-02]],\n","              \n","                       [[-1.1398e-02, -1.7620e-02,  6.0478e-03],\n","                        [ 2.1117e-02, -1.4477e-02, -1.5956e-02],\n","                        [ 3.0964e-03, -6.4489e-04, -2.0046e-03]],\n","              \n","                       ...,\n","              \n","                       [[-2.0495e-02,  5.3746e-03,  8.5964e-03],\n","                        [ 3.7421e-04, -7.1448e-05, -1.2513e-02],\n","                        [-1.4105e-03,  4.9235e-03,  9.6011e-03]],\n","              \n","                       [[ 2.0549e-02,  1.0252e-02,  1.7423e-02],\n","                        [ 1.7633e-02,  3.1753e-03,  8.0582e-03],\n","                        [ 7.8568e-03,  3.6623e-02,  3.7333e-02]],\n","              \n","                       [[-2.0775e-02, -1.0578e-02, -7.7121e-03],\n","                        [-7.4567e-03, -7.7704e-03,  8.0460e-03],\n","                        [-3.1783e-03, -2.7037e-02, -1.4297e-02]]],\n","              \n","              \n","                      [[[-1.1656e-02,  1.6862e-02, -3.1460e-03],\n","                        [ 1.7348e-02,  2.0791e-03, -1.2666e-02],\n","                        [-1.9226e-02, -1.5543e-02, -1.4234e-02]],\n","              \n","                       [[-4.3801e-03, -1.8155e-02,  8.2345e-03],\n","                        [ 6.2998e-03,  7.7471e-03, -5.1722e-03],\n","                        [ 3.2002e-02,  1.1599e-02,  7.8302e-03]],\n","              \n","                       [[-2.0012e-02, -1.2933e-02,  2.1596e-03],\n","                        [-8.7008e-03,  1.8144e-02,  1.6354e-02],\n","                        [-4.0990e-03,  6.9815e-03,  8.2713e-04]],\n","              \n","                       ...,\n","              \n","                       [[-1.8866e-02, -1.8178e-02,  7.9786e-03],\n","                        [-1.8427e-02, -9.7121e-03,  9.6644e-03],\n","                        [ 2.0849e-02, -9.2850e-03,  1.7531e-02]],\n","              \n","                       [[ 7.1620e-03,  1.3428e-03, -1.4170e-02],\n","                        [ 1.7791e-02, -4.4322e-03,  5.4246e-03],\n","                        [-6.6739e-03,  3.0101e-02,  2.2134e-02]],\n","              \n","                       [[ 1.3525e-02, -1.2716e-02, -1.6180e-02],\n","                        [-1.9609e-02, -3.2366e-03, -1.6551e-02],\n","                        [-1.2901e-02, -2.6212e-03, -2.2959e-03]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 5.5222e-03, -1.4712e-02,  2.6361e-03],\n","                        [-1.2583e-02,  1.3383e-02,  1.1084e-02],\n","                        [ 1.8990e-03,  1.7661e-02, -1.2295e-03]],\n","              \n","                       [[ 9.0032e-03,  1.4983e-02,  1.2335e-02],\n","                        [ 8.7673e-04,  8.9451e-03, -2.8571e-03],\n","                        [-1.1244e-02, -1.3710e-02,  1.8419e-03]],\n","              \n","                       [[-1.2284e-02, -1.0636e-02,  1.9816e-02],\n","                        [ 1.6403e-02, -4.8985e-04, -1.6934e-02],\n","                        [ 8.4287e-03,  2.1211e-02,  9.2098e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 3.5114e-03, -2.0071e-02, -9.3110e-03],\n","                        [ 3.3024e-03, -1.4348e-04,  1.9355e-02],\n","                        [ 2.1688e-03,  5.0683e-03,  5.4960e-03]],\n","              \n","                       [[-2.6230e-04,  1.2444e-02,  2.0090e-02],\n","                        [-3.5008e-03,  2.4812e-02,  2.8140e-02],\n","                        [ 1.4926e-02, -9.7754e-03, -1.4475e-02]],\n","              \n","                       [[-1.9865e-03, -6.2139e-03,  1.2116e-03],\n","                        [ 1.6871e-03, -1.6273e-02, -5.2003e-03],\n","                        [-1.6123e-02, -2.0107e-02,  1.8852e-02]]],\n","              \n","              \n","                      [[[ 1.3840e-02,  2.5309e-04, -1.4118e-03],\n","                        [ 7.9040e-03,  6.7556e-03,  1.5058e-02],\n","                        [ 2.3422e-02,  2.0401e-03, -8.5326e-03]],\n","              \n","                       [[-2.7566e-02,  2.3384e-02,  5.8673e-03],\n","                        [-2.0852e-03, -8.5345e-04, -6.1260e-03],\n","                        [ 9.6598e-03,  2.4825e-02,  2.8490e-02]],\n","              \n","                       [[ 2.4857e-05, -1.8016e-02, -1.7320e-03],\n","                        [-2.3839e-03,  1.0281e-02, -4.1481e-03],\n","                        [-1.9807e-02,  2.9185e-04,  9.1364e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 2.0480e-02,  2.0079e-02,  1.2783e-02],\n","                        [ 8.4410e-04, -6.7808e-03, -1.0464e-02],\n","                        [ 1.6099e-02,  3.5621e-03, -5.8316e-04]],\n","              \n","                       [[ 2.2537e-02,  1.4472e-02,  1.6015e-02],\n","                        [ 3.0820e-02,  2.6043e-02,  3.8166e-02],\n","                        [ 8.0836e-03,  2.2998e-02,  1.4345e-02]],\n","              \n","                       [[ 1.4174e-02, -1.4857e-02,  1.4177e-02],\n","                        [-2.1249e-03, -1.1308e-02,  8.3145e-04],\n","                        [-3.7094e-02, -2.1274e-02, -1.6043e-02]]],\n","              \n","              \n","                      [[[-1.7046e-02, -4.0088e-03, -2.3074e-02],\n","                        [ 2.4421e-02,  1.3212e-02,  1.9352e-02],\n","                        [ 1.6694e-02,  1.7037e-02,  1.8041e-02]],\n","              \n","                       [[ 2.8175e-02, -8.1528e-03, -2.2239e-02],\n","                        [ 2.4510e-02,  6.1724e-03,  1.0349e-02],\n","                        [ 3.8880e-02,  3.9057e-02,  1.9534e-02]],\n","              \n","                       [[ 1.0230e-02,  1.6445e-02, -1.7656e-02],\n","                        [ 6.5955e-03, -3.8906e-04,  3.0200e-04],\n","                        [ 2.0426e-02, -8.1986e-03,  8.9471e-03]],\n","              \n","                       ...,\n","              \n","                       [[-8.5014e-03,  1.6942e-02,  1.0292e-02],\n","                        [ 1.1573e-02, -4.7148e-03, -4.0596e-03],\n","                        [-4.1023e-03, -1.5258e-02, -3.7699e-03]],\n","              \n","                       [[ 3.0270e-02,  2.2050e-02,  3.5748e-02],\n","                        [ 6.9316e-03,  3.4402e-02, -6.1512e-03],\n","                        [-6.8201e-03,  1.4698e-02,  1.4533e-02]],\n","              \n","                       [[-5.7831e-03,  2.2047e-02,  2.0761e-02],\n","                        [ 7.2492e-03, -9.9253e-03, -1.1867e-02],\n","                        [ 2.7184e-02, -7.2908e-03, -7.8960e-03]]]])),\n","             ('incept7.conv3.conv.bias',\n","              tensor([ 0.0003, -0.0147,  0.0107, -0.0065,  0.0016, -0.0158,  0.0010, -0.0087,\n","                       0.0002, -0.0050,  0.0014,  0.0043,  0.0096, -0.0070,  0.0197,  0.0106,\n","                      -0.0133,  0.0175,  0.0057, -0.0192, -0.0192, -0.0204,  0.0164,  0.0034,\n","                      -0.0057, -0.0200, -0.0038,  0.0020, -0.0021,  0.0146, -0.0145,  0.0065,\n","                       0.0013,  0.0105, -0.0066,  0.0084, -0.0055,  0.0029,  0.0147, -0.0057,\n","                      -0.0102, -0.0180,  0.0035, -0.0189, -0.0002, -0.0189, -0.0085, -0.0202,\n","                      -0.0133, -0.0184,  0.0049,  0.0086, -0.0057,  0.0106, -0.0050, -0.0179,\n","                      -0.0137, -0.0160,  0.0160, -0.0162])),\n","             ('incept7.conv3.bn.weight',\n","              tensor([0.5824, 0.6724, 0.2891, 0.1160, 0.5679, 0.8963, 0.9104, 0.6544, 0.1039,\n","                      1.0387, 0.9773, 0.3012, 0.5371, 0.7349, 0.8824, 0.8710, 0.5485, 0.3425,\n","                      0.7818, 0.6161, 0.5211, 0.4540, 0.4996, 0.5111, 0.4193, 0.6000, 0.6150,\n","                      0.6765, 0.7913, 0.4341, 0.2756, 1.0118, 0.0149, 0.4742, 0.3497, 1.0223,\n","                      0.8689, 0.1991, 0.2294, 0.7917, 0.2066, 0.8428, 0.0190, 0.2650, 0.3036,\n","                      1.0604, 0.0934, 0.3528, 0.0857, 0.1447, 0.1962, 0.5109, 0.3226, 0.3414,\n","                      0.1926, 0.4762, 0.6469, 0.2779, 0.6333, 0.8460])),\n","             ('incept7.conv3.bn.bias',\n","              tensor([-0.0169, -0.0165, -0.0022, -0.0073, -0.0103, -0.0772, -0.0744, -0.0157,\n","                       0.0044, -0.1121, -0.0658,  0.0154, -0.0355, -0.0040, -0.0999, -0.0183,\n","                      -0.0212, -0.0062, -0.0715, -0.0024, -0.0044, -0.0112, -0.0333, -0.0340,\n","                      -0.0077, -0.0610, -0.0867,  0.0093, -0.0128, -0.0067, -0.0003, -0.0485,\n","                      -0.0015, -0.0364, -0.0052, -0.1658, -0.0977, -0.0104, -0.0046, -0.0371,\n","                       0.0041, -0.0824,  0.0032,  0.0136, -0.0111, -0.0464,  0.0082,  0.0123,\n","                       0.0050,  0.0025, -0.0093, -0.0216, -0.0147,  0.0044,  0.0056, -0.0063,\n","                      -0.0247,  0.0010, -0.0089, -0.0500])),\n","             ('incept7.conv3.bn.running_mean',\n","              tensor([-0.2193, -0.2513,  0.2886,  0.1364, -0.1793, -0.6955,  0.5389, -0.0801,\n","                       0.1375,  0.5685, -0.1191,  0.0919,  0.2399, -0.0839,  0.5423,  0.6039,\n","                      -0.0543,  0.1652, -0.2952, -0.2791, -0.2209, -0.7963,  0.6265,  0.4513,\n","                       0.1226,  0.0155,  0.3640, -0.0770, -0.3887, -0.1764,  0.1841,  0.3969,\n","                      -0.0665,  0.1619, -0.5520,  0.2265,  0.1088,  0.0525,  0.1627, -0.6673,\n","                       0.0991,  0.5393, -0.2425, -0.1909,  0.1269,  0.4708,  0.1302,  0.2492,\n","                       0.0268, -0.0289,  0.1223,  0.1369, -0.1039,  0.0201,  0.0126,  0.1881,\n","                      -0.5702, -0.1496, -0.0778,  0.5974])),\n","             ('incept7.conv3.bn.running_var',\n","              tensor([0.1196, 0.1105, 0.0586, 0.0527, 0.1035, 0.2782, 0.1971, 0.1418, 0.0538,\n","                      0.3014, 0.2325, 0.0763, 0.1072, 0.1328, 0.2536, 0.2127, 0.1052, 0.0645,\n","                      0.2185, 0.1427, 0.0906, 0.1403, 0.0989, 0.1291, 0.0891, 0.1385, 0.1439,\n","                      0.1557, 0.2311, 0.0959, 0.0989, 0.3093, 0.0344, 0.1021, 0.0818, 0.2853,\n","                      0.2168, 0.0516, 0.0535, 0.2479, 0.0574, 0.2529, 0.0447, 0.0695, 0.0632,\n","                      0.2477, 0.0468, 0.0695, 0.0593, 0.0483, 0.0485, 0.1058, 0.0662, 0.0609,\n","                      0.0365, 0.1008, 0.0960, 0.0674, 0.1406, 0.1994])),\n","             ('incept7.conv3.bn.num_batches_tracked', tensor(4157)),\n","             ('incept8.conv1.conv.weight', tensor([[[[-0.0048]],\n","              \n","                       [[-0.0467]],\n","              \n","                       [[-0.0388]],\n","              \n","                       ...,\n","              \n","                       [[ 0.0610]],\n","              \n","                       [[-0.0230]],\n","              \n","                       [[-0.0016]]],\n","              \n","              \n","                      [[[-0.0362]],\n","              \n","                       [[-0.0530]],\n","              \n","                       [[ 0.0114]],\n","              \n","                       ...,\n","              \n","                       [[-0.0219]],\n","              \n","                       [[ 0.0120]],\n","              \n","                       [[ 0.0191]]],\n","              \n","              \n","                      [[[ 0.0074]],\n","              \n","                       [[ 0.0197]],\n","              \n","                       [[ 0.0309]],\n","              \n","                       ...,\n","              \n","                       [[-0.0385]],\n","              \n","                       [[ 0.0572]],\n","              \n","                       [[ 0.0636]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 0.0090]],\n","              \n","                       [[ 0.0025]],\n","              \n","                       [[ 0.0290]],\n","              \n","                       ...,\n","              \n","                       [[-0.0125]],\n","              \n","                       [[ 0.1069]],\n","              \n","                       [[ 0.0463]]],\n","              \n","              \n","                      [[[-0.0421]],\n","              \n","                       [[-0.0420]],\n","              \n","                       [[ 0.0050]],\n","              \n","                       ...,\n","              \n","                       [[-0.0400]],\n","              \n","                       [[ 0.0584]],\n","              \n","                       [[-0.0325]]],\n","              \n","              \n","                      [[[ 0.0183]],\n","              \n","                       [[-0.0710]],\n","              \n","                       [[-0.0131]],\n","              \n","                       ...,\n","              \n","                       [[-0.0215]],\n","              \n","                       [[ 0.0596]],\n","              \n","                       [[ 0.0013]]]])),\n","             ('incept8.conv1.conv.bias',\n","              tensor([ 0.0650,  0.0490, -0.0202,  0.0426,  0.0145, -0.0142, -0.0319,  0.0398,\n","                       0.0031, -0.0174, -0.0580, -0.0469,  0.0345,  0.0160,  0.0058,  0.0399,\n","                      -0.0186,  0.0277, -0.0407,  0.0159, -0.0073,  0.0249,  0.0176, -0.0554,\n","                      -0.0174,  0.0069,  0.0012, -0.0594,  0.0601,  0.0625,  0.0256, -0.0497,\n","                       0.0298,  0.0356,  0.0156,  0.0079,  0.0646, -0.0094,  0.0236,  0.0462,\n","                       0.0169,  0.0036,  0.0034,  0.0317, -0.0538,  0.0323, -0.0398,  0.0461,\n","                      -0.0149, -0.0435,  0.0385,  0.0057, -0.0546, -0.0557, -0.0071,  0.0550,\n","                       0.0560, -0.0366, -0.0557,  0.0559, -0.0242,  0.0515, -0.0264,  0.0108,\n","                       0.0516, -0.0576, -0.0637, -0.0173,  0.0128,  0.0496, -0.0130,  0.0173,\n","                      -0.0341,  0.0201, -0.0097, -0.0044,  0.0173,  0.0035,  0.0097, -0.0260,\n","                      -0.0464, -0.0076,  0.0020, -0.0161, -0.0211, -0.0300, -0.0615, -0.0067,\n","                       0.0134,  0.0642, -0.0024, -0.0162,  0.0648,  0.0431,  0.0182,  0.0365,\n","                      -0.0175,  0.0377, -0.0149, -0.0590, -0.0567, -0.0361,  0.0540, -0.0388,\n","                      -0.0142, -0.0198,  0.0072, -0.0126,  0.0471,  0.0185, -0.0284, -0.0302,\n","                       0.0241, -0.0203,  0.0440, -0.0338, -0.0226,  0.0276, -0.0511, -0.0539,\n","                      -0.0194,  0.0575, -0.0626, -0.0075,  0.0323,  0.0503,  0.0100,  0.0265,\n","                      -0.0574, -0.0224,  0.0066,  0.0404,  0.0583,  0.0561,  0.0525, -0.0625,\n","                      -0.0434, -0.0158, -0.0482,  0.0027,  0.0124, -0.0440, -0.0187,  0.0636,\n","                      -0.0118,  0.0255, -0.0223,  0.0448,  0.0095,  0.0005,  0.0617,  0.0167,\n","                       0.0247,  0.0506,  0.0626, -0.0603, -0.0643,  0.0200, -0.0367,  0.0051,\n","                      -0.0237, -0.0059, -0.0215, -0.0357,  0.0019,  0.0539, -0.0430, -0.0062,\n","                      -0.0593, -0.0621, -0.0580, -0.0621,  0.0554, -0.0629, -0.0136, -0.0572])),\n","             ('incept8.conv1.bn.weight',\n","              tensor([ 0.8215,  0.5673,  0.4003,  0.1652,  0.1461,  0.5267,  0.3467,  0.6367,\n","                       0.7969,  0.8935,  1.0931,  0.6362,  0.4656,  0.2423,  0.3695,  0.6919,\n","                       1.1720,  0.0033,  0.6765,  0.5517,  0.3137,  0.1917,  0.7601,  0.5609,\n","                       1.2269,  0.7790,  1.1529,  0.4342,  0.2931,  1.1565,  0.9429,  0.7654,\n","                       0.7952,  0.8334,  0.6435,  0.3142,  0.2795,  0.9490,  0.0627,  0.2267,\n","                       0.7996,  0.0415,  0.8036,  0.7840,  0.4157,  0.8031,  0.3024,  0.9176,\n","                       0.2122,  0.5902,  0.4734,  0.6457,  0.8357,  0.7918,  0.8541,  1.0825,\n","                       1.0311,  1.0931,  0.2078,  0.3098,  0.0936,  1.0169,  0.0807,  0.1876,\n","                       0.8755,  0.0548,  0.7119,  0.8481,  0.3687,  0.5430,  0.5912,  1.1473,\n","                       0.8450,  1.0815,  0.4596,  0.2565,  0.7258,  0.6332,  0.6191,  1.0679,\n","                       0.7038,  0.2792,  0.2087,  1.1493,  0.5495,  0.1258,  1.1372,  1.0586,\n","                       0.6806,  0.7732,  1.0199,  0.3283,  0.1385,  0.0277,  1.0844,  0.7169,\n","                       1.1830,  0.7645,  0.6442,  0.2472,  1.1213,  0.9322,  1.0429,  0.1069,\n","                       0.4144,  1.1695,  0.5808,  0.6766,  0.3339,  0.1003,  0.9536,  0.3267,\n","                      -0.0167,  0.1991,  0.8941,  0.3586,  0.1610,  0.8843,  0.5697,  0.1748,\n","                       0.6758,  0.8035,  0.3911,  0.1331,  0.6699,  0.7873,  0.3040,  0.6467,\n","                       0.5946,  0.5524,  0.4508,  0.3687,  0.1697,  0.6621,  0.9217,  0.8687,\n","                       1.1617,  0.0405,  0.6586,  0.2898,  1.2938,  1.2477,  0.7215,  0.3345,\n","                       0.4102,  0.1132,  0.1024,  0.8441,  0.7017,  0.3826,  0.6650,  0.7726,\n","                       0.2252,  0.5036,  0.8888,  0.9070,  0.0151,  0.0382,  0.5549,  1.3060,\n","                       0.3970,  0.4757,  0.7649,  0.2938,  0.4374,  0.8496,  0.1561,  0.7748,\n","                       0.0555,  0.6329,  0.8263,  0.9553,  0.5733,  0.9736,  1.1546,  0.7848])),\n","             ('incept8.conv1.bn.bias',\n","              tensor([ 0.1036,  0.0422,  0.0563,  0.0196,  0.0079,  0.0612,  0.0248,  0.0482,\n","                       0.1178,  0.1102,  0.1165,  0.0824,  0.0338,  0.0292,  0.0656,  0.0907,\n","                       0.1668, -0.0015,  0.0736,  0.0769,  0.0287,  0.0201,  0.1012,  0.0783,\n","                       0.1340,  0.0926,  0.0931,  0.0448,  0.0182,  0.1158,  0.0855,  0.0580,\n","                       0.1151,  0.1258,  0.0613,  0.0481,  0.0609,  0.0896,  0.0236,  0.0584,\n","                       0.1363,  0.0135,  0.1261,  0.1486,  0.0489,  0.1154,  0.0466,  0.1465,\n","                       0.0155,  0.1076,  0.0458,  0.0668,  0.1014,  0.1046,  0.0953,  0.1396,\n","                       0.1393,  0.1271,  0.0224,  0.0178,  0.0275,  0.1394,  0.0209,  0.0333,\n","                       0.1109,  0.0040,  0.0889,  0.0802,  0.0621,  0.0902,  0.0699,  0.1620,\n","                       0.1240,  0.1296,  0.0557,  0.0196,  0.0705,  0.0780,  0.0687,  0.1407,\n","                       0.0970,  0.0433,  0.0304,  0.1011,  0.0567,  0.0106,  0.1235,  0.1098,\n","                       0.0768,  0.0924,  0.1169,  0.0243,  0.0350, -0.0077,  0.1571,  0.0656,\n","                       0.1678,  0.0784,  0.0841,  0.0097,  0.1037,  0.1079,  0.1130,  0.0063,\n","                       0.0337,  0.1511,  0.0810,  0.0608,  0.0430, -0.0035,  0.1029,  0.0399,\n","                       0.0095,  0.0406,  0.0892,  0.0355,  0.0078,  0.0845,  0.0936,  0.0297,\n","                       0.0816,  0.1060,  0.0578,  0.0307,  0.0760,  0.0673,  0.0271,  0.0436,\n","                       0.0543,  0.0550,  0.0517,  0.0588,  0.0249,  0.0867,  0.1598,  0.1120,\n","                       0.1211,  0.0044,  0.0828,  0.0331,  0.2176,  0.1374,  0.1092,  0.0466,\n","                       0.0511,  0.0010,  0.0057,  0.1022,  0.0646,  0.0474,  0.0701,  0.1125,\n","                       0.0171,  0.0907,  0.1081,  0.0905, -0.0235,  0.0120,  0.0771,  0.1685,\n","                       0.0505,  0.0798,  0.0854,  0.0728,  0.0473,  0.1148,  0.0143,  0.0490,\n","                       0.0200,  0.0689,  0.0926,  0.1043,  0.1005,  0.1048,  0.0988,  0.1032])),\n","             ('incept8.conv1.bn.running_mean',\n","              tensor([ 0.1741,  0.0695, -0.0164,  0.0717,  0.1834,  0.0092,  0.0298, -0.1128,\n","                      -0.0538, -0.0660,  0.0167, -0.0529,  0.0552, -0.0169,  0.0884,  0.2472,\n","                      -0.1623, -0.0024, -0.1175,  0.1550, -0.0492,  0.0183, -0.0222, -0.0683,\n","                       0.0311,  0.0790,  0.0303, -0.0378, -0.0810,  0.1998, -0.0139, -0.1229,\n","                       0.0549,  0.0103, -0.1192,  0.0537,  0.1582,  0.0781,  0.2048,  0.0817,\n","                       0.0690, -0.2814,  0.0714,  0.2516, -0.1928,  0.2628,  0.0203, -0.0254,\n","                      -0.1957, -0.0474,  0.0106, -0.0902, -0.1687, -0.2296,  0.0055,  0.0252,\n","                       0.0456, -0.1105, -0.0496,  0.0533, -0.0569,  0.0442, -0.0570,  0.0130,\n","                      -0.0191, -0.0154, -0.1780, -0.0224,  0.1441,  0.0933,  0.0342, -0.1097,\n","                      -0.0513, -0.0430,  0.0178,  0.0141,  0.0900, -0.0013,  0.0034, -0.1574,\n","                      -0.0130, -0.0869, -0.0554, -0.0370,  0.0793, -0.0353, -0.1385,  0.0245,\n","                       0.0206,  0.0632, -0.0132, -0.1933,  0.0337, -0.0621,  0.0352,  0.2447,\n","                      -0.0733,  0.0954, -0.0034,  0.0904, -0.0760, -0.0713, -0.0288, -0.0224,\n","                       0.2468, -0.2085,  0.1278,  0.0071,  0.0704,  0.1247, -0.0874,  0.0871,\n","                       0.1761,  0.0465,  0.1349,  0.0533,  0.0786,  0.1548, -0.0781,  0.0131,\n","                      -0.0261,  0.0062, -0.1600, -0.0757,  0.0142, -0.1446, -0.0067,  0.1470,\n","                      -0.1242, -0.1078, -0.1308, -0.0256,  0.1770,  0.2009,  0.0747, -0.0046,\n","                       0.0049,  0.0083, -0.0006,  0.1101, -0.0118, -0.0564, -0.1033, -0.0026,\n","                      -0.0225,  0.3962, -0.0483, -0.0011, -0.0043, -0.0156,  0.1865,  0.2570,\n","                      -0.0477,  0.0181, -0.0429, -0.2151,  0.0283,  0.1407,  0.0286, -0.1240,\n","                      -0.0038,  0.1129, -0.0751, -0.0301, -0.0350, -0.0539, -0.0090,  0.1180,\n","                      -0.1580, -0.1294, -0.0855, -0.1066,  0.1035, -0.1210,  0.0295,  0.0238])),\n","             ('incept8.conv1.bn.running_var',\n","              tensor([0.0864, 0.0781, 0.0578, 0.0353, 0.0494, 0.0584, 0.0561, 0.0471, 0.0590,\n","                      0.0751, 0.0837, 0.0656, 0.0678, 0.0541, 0.0444, 0.0609, 0.0758, 0.0382,\n","                      0.0587, 0.0613, 0.0500, 0.0312, 0.0601, 0.0596, 0.1351, 0.0646, 0.1074,\n","                      0.0621, 0.0358, 0.0781, 0.0585, 0.0597, 0.0583, 0.0661, 0.0622, 0.0587,\n","                      0.0522, 0.0934, 0.0346, 0.0506, 0.0587, 0.0391, 0.0736, 0.0640, 0.0495,\n","                      0.0757, 0.0509, 0.0613, 0.0406, 0.0480, 0.0511, 0.0566, 0.0550, 0.0671,\n","                      0.0661, 0.0848, 0.0681, 0.0715, 0.0293, 0.0479, 0.0342, 0.0665, 0.0249,\n","                      0.0436, 0.0607, 0.0459, 0.0405, 0.0790, 0.0486, 0.0619, 0.0594, 0.0992,\n","                      0.0765, 0.0705, 0.0597, 0.0358, 0.0857, 0.0594, 0.0446, 0.0574, 0.0545,\n","                      0.0441, 0.0444, 0.0761, 0.0858, 0.0279, 0.0930, 0.1091, 0.0659, 0.0495,\n","                      0.0564, 0.0468, 0.0377, 0.0371, 0.0711, 0.0600, 0.0694, 0.0757, 0.0584,\n","                      0.0549, 0.0868, 0.0653, 0.0841, 0.0271, 0.0428, 0.0665, 0.0601, 0.0532,\n","                      0.0432, 0.0387, 0.0627, 0.0492, 0.0246, 0.0408, 0.0856, 0.0465, 0.0303,\n","                      0.0700, 0.0514, 0.0360, 0.0718, 0.0773, 0.0544, 0.0430, 0.0479, 0.0597,\n","                      0.0457, 0.0432, 0.0493, 0.0470, 0.0551, 0.0672, 0.0337, 0.0571, 0.0612,\n","                      0.0689, 0.0976, 0.0395, 0.0487, 0.0441, 0.0756, 0.0746, 0.0644, 0.0613,\n","                      0.0459, 0.0473, 0.0411, 0.0537, 0.0519, 0.0473, 0.0489, 0.0623, 0.0380,\n","                      0.0423, 0.0855, 0.0691, 0.0343, 0.0304, 0.0537, 0.0854, 0.0563, 0.0564,\n","                      0.0598, 0.0518, 0.0509, 0.0559, 0.0466, 0.0814, 0.0499, 0.0518, 0.0640,\n","                      0.0663, 0.0600, 0.0657, 0.0843, 0.0705])),\n","             ('incept8.conv1.bn.num_batches_tracked', tensor(4157)),\n","             ('incept8.conv3.conv.weight',\n","              tensor([[[[-1.6296e-02,  3.7440e-04, -6.2168e-03],\n","                        [-1.7150e-02, -1.2223e-02, -6.5657e-03],\n","                        [-5.8852e-03, -1.9681e-02, -4.1913e-03]],\n","              \n","                       [[-1.9446e-02, -1.1838e-02,  1.1552e-02],\n","                        [ 1.5765e-02, -3.9384e-04,  1.7225e-02],\n","                        [-1.1700e-03, -5.9106e-03,  7.0641e-03]],\n","              \n","                       [[ 1.7224e-02, -1.3411e-03, -4.5360e-03],\n","                        [ 1.4725e-02,  1.3514e-02,  1.0996e-02],\n","                        [-8.6904e-03,  1.8342e-02, -5.5784e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 7.0851e-03,  1.3837e-02,  5.7915e-03],\n","                        [ 2.7601e-04,  1.7431e-02,  5.1766e-03],\n","                        [ 1.1346e-02, -1.1687e-02, -6.3409e-03]],\n","              \n","                       [[ 1.4434e-02,  6.3432e-03, -4.8251e-03],\n","                        [-1.0373e-02, -2.6388e-03,  2.5622e-03],\n","                        [-3.6205e-03,  2.0703e-03, -1.0613e-02]],\n","              \n","                       [[ 8.3461e-03, -1.2659e-02, -3.8382e-03],\n","                        [-1.4501e-02,  2.0550e-02,  1.6215e-02],\n","                        [-1.0260e-03, -1.4355e-02, -2.7230e-03]]],\n","              \n","              \n","                      [[[ 8.2325e-03, -1.0111e-02, -1.4254e-03],\n","                        [ 9.9203e-03,  2.3475e-05, -7.5551e-03],\n","                        [ 3.8306e-03, -1.2439e-02,  9.9107e-03]],\n","              \n","                       [[-6.7390e-04, -7.7517e-03, -2.3019e-03],\n","                        [-1.4100e-02,  9.2789e-04,  2.2567e-02],\n","                        [ 2.0084e-02, -5.3042e-03,  1.1863e-02]],\n","              \n","                       [[-3.0226e-03, -1.3167e-02, -1.9351e-02],\n","                        [-7.9930e-03,  7.7699e-03, -1.0723e-02],\n","                        [-6.3598e-04,  1.9629e-02, -7.1335e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 5.2722e-03, -7.4494e-03,  1.9086e-02],\n","                        [ 1.9427e-02,  4.3255e-03, -5.5379e-03],\n","                        [ 1.4842e-02,  1.3162e-02, -7.9512e-03]],\n","              \n","                       [[-6.3508e-03,  1.0541e-02, -2.1403e-02],\n","                        [-7.8512e-03, -2.1803e-02, -6.8314e-03],\n","                        [ 1.2525e-02,  7.9984e-03, -1.9312e-03]],\n","              \n","                       [[-1.0379e-02,  1.5739e-02, -1.6981e-03],\n","                        [ 1.9418e-02,  2.2077e-03, -9.5046e-03],\n","                        [-1.8392e-03, -1.5577e-02,  1.8703e-02]]],\n","              \n","              \n","                      [[[-3.4063e-03, -9.0268e-03, -8.0486e-03],\n","                        [ 9.4874e-03,  3.1986e-03,  2.1430e-03],\n","                        [ 1.0820e-02,  2.1684e-02,  2.0006e-02]],\n","              \n","                       [[-1.9787e-02, -1.2902e-02,  8.4189e-03],\n","                        [-1.6465e-02, -6.0917e-03, -1.1685e-02],\n","                        [-1.3186e-02, -3.7280e-04,  7.5314e-03]],\n","              \n","                       [[ 1.0343e-02,  1.6372e-02, -1.1093e-02],\n","                        [-1.5530e-02, -1.2334e-02, -1.5230e-02],\n","                        [ 1.8327e-02,  1.6955e-02,  1.1255e-04]],\n","              \n","                       ...,\n","              \n","                       [[-1.6856e-02,  9.3002e-03, -1.4333e-02],\n","                        [-1.2008e-02, -3.4481e-03, -9.0805e-03],\n","                        [ 1.7310e-02,  1.2779e-02, -1.3080e-02]],\n","              \n","                       [[ 8.4473e-03, -2.3935e-02,  6.9301e-04],\n","                        [-1.0991e-02,  4.3834e-03, -1.0637e-03],\n","                        [ 3.2530e-04,  1.5724e-02, -1.2411e-02]],\n","              \n","                       [[ 1.0299e-03, -1.5761e-02, -1.9411e-02],\n","                        [ 2.0960e-03, -9.2309e-03, -1.7317e-02],\n","                        [ 1.6881e-03,  1.2391e-02, -3.8591e-03]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 1.1579e-02, -1.0585e-02, -5.7937e-03],\n","                        [-1.2484e-02,  1.8007e-02, -1.5394e-02],\n","                        [-1.6018e-02,  1.7623e-02, -4.1958e-03]],\n","              \n","                       [[ 5.7168e-03,  1.3332e-02,  3.6045e-02],\n","                        [ 7.7175e-03,  9.7289e-03,  4.3416e-03],\n","                        [ 2.4379e-02,  8.0410e-03,  3.0314e-02]],\n","              \n","                       [[ 2.6595e-02, -1.2266e-02,  2.2488e-02],\n","                        [ 6.6461e-04, -1.3259e-02,  1.8474e-02],\n","                        [ 1.2823e-02,  1.5505e-02,  2.0399e-03]],\n","              \n","                       ...,\n","              \n","                       [[ 4.4853e-03,  1.5275e-02, -1.2112e-02],\n","                        [-5.5576e-03,  1.6922e-03,  1.6687e-02],\n","                        [-5.5812e-03, -2.2048e-02, -2.1345e-02]],\n","              \n","                       [[ 4.0769e-05, -4.0221e-03,  1.0252e-02],\n","                        [-1.1082e-02,  1.7996e-02, -7.3645e-03],\n","                        [ 1.7401e-02,  1.4013e-02,  1.8578e-02]],\n","              \n","                       [[ 1.6117e-02,  2.4232e-03,  2.0250e-02],\n","                        [-1.7878e-02, -1.2982e-02,  9.3133e-03],\n","                        [ 8.1280e-03,  3.6659e-03, -1.6308e-02]]],\n","              \n","              \n","                      [[[-7.3604e-03, -7.8290e-03,  2.6839e-03],\n","                        [-5.7714e-03,  1.0144e-02, -1.3498e-02],\n","                        [ 1.5687e-02,  5.3005e-03,  4.8336e-03]],\n","              \n","                       [[ 2.7026e-02,  3.1316e-02,  4.6359e-02],\n","                        [ 3.2722e-02,  2.7045e-02,  2.6649e-02],\n","                        [ 1.3561e-02,  2.5339e-02,  2.0045e-02]],\n","              \n","                       [[ 9.9709e-03,  2.2815e-02, -7.8226e-03],\n","                        [ 1.6386e-02, -3.2406e-03,  1.3812e-02],\n","                        [-2.9251e-03, -9.8510e-03,  2.1978e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 4.4253e-03, -1.6361e-02, -1.2605e-03],\n","                        [ 4.8106e-03,  1.0487e-03,  1.4390e-02],\n","                        [-8.3682e-03, -3.9874e-04,  2.2787e-02]],\n","              \n","                       [[ 2.8608e-02, -1.2293e-03,  3.4167e-02],\n","                        [ 5.9207e-03,  1.0301e-03,  2.7937e-02],\n","                        [-7.4856e-04,  2.9903e-02,  1.3919e-02]],\n","              \n","                       [[ 4.7963e-03, -1.0579e-04, -4.2912e-03],\n","                        [-3.0085e-02,  5.0602e-03, -7.9706e-03],\n","                        [-9.2143e-04, -6.0424e-03,  6.5189e-04]]],\n","              \n","              \n","                      [[[ 9.4213e-03,  3.8291e-02,  3.5362e-02],\n","                        [-1.7038e-02,  9.9219e-03,  2.1887e-02],\n","                        [ 2.3539e-03,  2.9897e-02,  1.9223e-02]],\n","              \n","                       [[ 5.2692e-03, -5.8152e-03, -8.2510e-03],\n","                        [ 1.0329e-02,  1.4285e-03, -1.8099e-02],\n","                        [-8.6332e-03, -4.1673e-03, -1.6604e-02]],\n","              \n","                       [[ 9.7885e-03,  1.6596e-02,  2.2776e-02],\n","                        [ 3.4492e-02,  3.7981e-02,  2.9475e-02],\n","                        [ 2.4779e-02,  4.1347e-02,  2.4989e-02]],\n","              \n","                       ...,\n","              \n","                       [[-7.3849e-03, -8.5363e-03,  8.3888e-03],\n","                        [ 1.7457e-02, -1.1622e-02,  1.4028e-02],\n","                        [ 2.6929e-03,  1.2852e-03, -5.5742e-04]],\n","              \n","                       [[-2.9056e-02, -2.3498e-02, -2.3423e-02],\n","                        [-2.0994e-02, -3.6202e-02,  2.3693e-03],\n","                        [-5.2423e-02, -2.1366e-02, -2.2696e-02]],\n","              \n","                       [[-1.4616e-02,  5.8464e-04, -2.7365e-02],\n","                        [ 2.1970e-02, -6.1915e-03, -1.7247e-02],\n","                        [ 1.3398e-02,  4.0692e-03, -4.3251e-03]]]])),\n","             ('incept8.conv3.conv.bias',\n","              tensor([-0.0109, -0.0045,  0.0125,  0.0109, -0.0079,  0.0033,  0.0001, -0.0053,\n","                      -0.0066,  0.0181,  0.0071,  0.0114,  0.0208, -0.0184,  0.0163, -0.0112,\n","                      -0.0110,  0.0084, -0.0094,  0.0150, -0.0183, -0.0206, -0.0201, -0.0026,\n","                      -0.0195, -0.0052,  0.0146,  0.0068,  0.0125,  0.0152,  0.0188,  0.0200,\n","                      -0.0114, -0.0077,  0.0061,  0.0076,  0.0209, -0.0131, -0.0109,  0.0036,\n","                      -0.0156,  0.0040,  0.0195, -0.0034, -0.0068, -0.0197, -0.0154, -0.0197,\n","                      -0.0151,  0.0172,  0.0160, -0.0210,  0.0130, -0.0151,  0.0086,  0.0123,\n","                      -0.0129, -0.0009, -0.0034, -0.0005])),\n","             ('incept8.conv3.bn.weight',\n","              tensor([0.0379, 0.2039, 0.3340, 0.4935, 0.5147, 0.5171, 0.5676, 1.0556, 0.3391,\n","                      1.3740, 0.7226, 0.4308, 1.5938, 1.3055, 0.3323, 0.2825, 1.2014, 0.9999,\n","                      1.2532, 0.5692, 0.4066, 1.0333, 1.1373, 0.5244, 0.0262, 1.2668, 0.0674,\n","                      1.4192, 0.3264, 0.3146, 0.7339, 0.9167, 0.6987, 0.2888, 0.3372, 0.9507,\n","                      1.0642, 1.1597, 0.7818, 0.4154, 0.2297, 0.3726, 0.6331, 1.4388, 0.7767,\n","                      0.9048, 1.3758, 0.1488, 0.7470, 1.0941, 0.8979, 0.4023, 0.9187, 1.4957,\n","                      0.6271, 1.0119, 0.0831, 0.6902, 0.9449, 1.5418])),\n","             ('incept8.conv3.bn.bias',\n","              tensor([0.0144, 0.0374, 0.0536, 0.0700, 0.0845, 0.0792, 0.1070, 0.1236, 0.0596,\n","                      0.2291, 0.1089, 0.1024, 0.2607, 0.1617, 0.0829, 0.0691, 0.2008, 0.1728,\n","                      0.1703, 0.1043, 0.0775, 0.1109, 0.1571, 0.1199, 0.0033, 0.1909, 0.0407,\n","                      0.2470, 0.0323, 0.0427, 0.1305, 0.1409, 0.0994, 0.0607, 0.0656, 0.1719,\n","                      0.1429, 0.1180, 0.1720, 0.0509, 0.0380, 0.0651, 0.1219, 0.2181, 0.1422,\n","                      0.1321, 0.2356, 0.0405, 0.1181, 0.1991, 0.1458, 0.0509, 0.1313, 0.3085,\n","                      0.0759, 0.1289, 0.0021, 0.1471, 0.1714, 0.2028])),\n","             ('incept8.conv3.bn.running_mean',\n","              tensor([-0.0017,  0.1064,  0.1159,  0.0390, -0.0606, -0.1342, -0.0023, -0.1040,\n","                      -0.0937,  0.0294, -0.1088, -0.1180, -0.3654, -0.1320,  0.0661,  0.0580,\n","                      -0.1045, -0.1955,  0.0427, -0.0642,  0.0424, -0.0832, -0.1596,  0.0670,\n","                      -0.0894,  0.0010,  0.0105, -0.0122,  0.0565,  0.0526, -0.1191, -0.2298,\n","                       0.1073,  0.0882,  0.1073, -0.1439,  0.0707,  0.0879, -0.1120,  0.0608,\n","                       0.1144,  0.0542, -0.1288, -0.3431, -0.0552, -0.0560, -0.2796, -0.0063,\n","                      -0.2174, -0.0294,  0.0461,  0.0735,  0.0961,  0.0148,  0.0835,  0.0056,\n","                       0.0456, -0.0525, -0.1592, -0.0400])),\n","             ('incept8.conv3.bn.running_var',\n","              tensor([0.0339, 0.0469, 0.0835, 0.1008, 0.0984, 0.0800, 0.1209, 0.1841, 0.0660,\n","                      0.1949, 0.0999, 0.0748, 0.2735, 0.1869, 0.0675, 0.0580, 0.1635, 0.1633,\n","                      0.1775, 0.0736, 0.0696, 0.1472, 0.1726, 0.0910, 0.0253, 0.1750, 0.0451,\n","                      0.2052, 0.0724, 0.0744, 0.0894, 0.1052, 0.1320, 0.0826, 0.0710, 0.1347,\n","                      0.1178, 0.1794, 0.1076, 0.0749, 0.0555, 0.0749, 0.0757, 0.2259, 0.1096,\n","                      0.1357, 0.2015, 0.0478, 0.0942, 0.1945, 0.1399, 0.0800, 0.1310, 0.2381,\n","                      0.1273, 0.1743, 0.0323, 0.1026, 0.1192, 0.2601])),\n","             ('incept8.conv3.bn.num_batches_tracked', tensor(4157)),\n","             ('linear.weight',\n","              tensor([[ 0.1481, -0.1453, -0.0927,  ..., -0.1562, -0.1120, -0.0324],\n","                      [-0.1293,  0.2573, -0.0486,  ..., -0.0659, -0.0846, -0.1598],\n","                      [-0.1226, -0.0302, -0.0653,  ...,  0.2536,  0.1250, -0.0630],\n","                      ...,\n","                      [-0.0749, -0.0742, -0.1140,  ..., -0.2037, -0.2503,  1.1320],\n","                      [ 0.2173,  0.0765, -0.0575,  ...,  0.0062, -0.0533, -0.1160],\n","                      [ 0.3601,  0.0146,  0.0797,  ..., -0.1015, -0.0860, -0.2130]])),\n","             ('linear.bias',\n","              tensor([-0.0090, -0.0602,  0.0448,  0.0797,  0.0481, -0.0565, -0.0239,  0.0386,\n","                       0.0008, -0.0111]))])"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9d47psr_lbo_","colab":{}},"source":["torch.save(inc_net_random_labels.state_dict(), \"inception_random.pt\")   #,Path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KMkycZSqlbpA"},"source":["# Load Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"miZDb7pylbpB","outputId":"334cae82-5926-433a-ef5d-ec3d4d202044","colab":{}},"source":["inc.load_state_dict(torch.load(\"inception.pt\"))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IncompatibleKeys(missing_keys=[], unexpected_keys=[])"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F3gJANtslbpE","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4JgyQ6eZlbpF","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5YufknsKlbpG"},"source":["# Alexnet"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P5XG-AqolbpH","colab":{}},"source":["class conv_alex(nn.Module):\n","    def __init__(self,in_ch,f):\n","        super(conv_alex,self).__init__()\n","        self.in_ch = in_ch\n","        self.f = f\n","        \n","        self.conv = nn.Conv2d(in_channels= self.in_ch,out_channels= self.f,kernel_size= 5,stride= 1 )\n","        \n","        self.pool = nn.MaxPool2d(3)\n","        \n","        self.normalization = nn.LocalResponseNorm(2)\n","        \n","    def forward(self,x):\n","        x = self.conv(x)\n","        x = self.pool(x)\n","        \n","        x = self.normalization(x)\n","        \n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bvwxybxZlbpJ","colab":{}},"source":["class alexnet(nn.Module):\n","    def __init__(self):\n","        super(alexnet,self).__init__()\n","        \n","        self.conv1 = conv_alex(3,256)\n","        \n","        self.conv2 = conv_alex(256,256)\n","        \n","        self.linear1 = nn.Linear(256,384)\n","        self.linear2 = nn.Linear(384,192) \n","        self.linear3 = nn.Linear(192,10)\n","    def forward(self,x):\n","        x = self.conv1(x)\n","        \n","        x = self.conv2(x)\n","        \n","        x = x.view(-1,1*256)\n","        \n","        x = self.linear1(x)\n","        x = self.linear2(x)\n","        x = self.linear3(x)\n","        return x\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M1n_Oa-ClbpK","colab":{}},"source":["\n","alex_net = alexnet()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AFGInU_dlbpL","colab":{}},"source":["criterion_alex = nn.CrossEntropyLoss()\n","optimizer_alex = optim.SGD(alex_net.parameters(), lr=0.01, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zpxQ88DblbpM","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"009abcf8-9571-4075-c62b-5bdf94b740f4","executionInfo":{"status":"ok","timestamp":1567870335584,"user_tz":-330,"elapsed":1030162,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["for epoch in range(20):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer_alex.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = alex_net(inputs)\n","        loss = criterion_alex(outputs, labels)\n","        loss.backward()\n","        optimizer_alex.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 50 == 49:    # print every 50 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 50))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["\r170500096it [00:30, 12325165.43it/s]                               "],"name":"stderr"},{"output_type":"stream","text":["[1,    50] loss: 2.160\n","[1,   100] loss: 1.896\n","[1,   150] loss: 1.707\n","[2,    50] loss: 1.513\n","[2,   100] loss: 1.470\n","[2,   150] loss: 1.427\n","[3,    50] loss: 1.311\n","[3,   100] loss: 1.265\n","[3,   150] loss: 1.246\n","[4,    50] loss: 1.168\n","[4,   100] loss: 1.155\n","[4,   150] loss: 1.138\n","[5,    50] loss: 1.070\n","[5,   100] loss: 1.076\n","[5,   150] loss: 1.045\n","[6,    50] loss: 1.000\n","[6,   100] loss: 0.961\n","[6,   150] loss: 0.971\n","[7,    50] loss: 0.890\n","[7,   100] loss: 0.888\n","[7,   150] loss: 0.902\n","[8,    50] loss: 0.817\n","[8,   100] loss: 0.817\n","[8,   150] loss: 0.835\n","[9,    50] loss: 0.742\n","[9,   100] loss: 0.750\n","[9,   150] loss: 0.752\n","[10,    50] loss: 0.648\n","[10,   100] loss: 0.666\n","[10,   150] loss: 0.679\n","[11,    50] loss: 0.575\n","[11,   100] loss: 0.616\n","[11,   150] loss: 0.613\n","[12,    50] loss: 0.501\n","[12,   100] loss: 0.536\n","[12,   150] loss: 0.555\n","[13,    50] loss: 0.446\n","[13,   100] loss: 0.444\n","[13,   150] loss: 0.479\n","[14,    50] loss: 0.396\n","[14,   100] loss: 0.416\n","[14,   150] loss: 0.438\n","[15,    50] loss: 0.343\n","[15,   100] loss: 0.334\n","[15,   150] loss: 0.372\n","[16,    50] loss: 0.289\n","[16,   100] loss: 0.269\n","[16,   150] loss: 0.351\n","[17,    50] loss: 0.269\n","[17,   100] loss: 0.271\n","[17,   150] loss: 0.326\n","[18,    50] loss: 0.230\n","[18,   100] loss: 0.197\n","[18,   150] loss: 0.209\n","[19,    50] loss: 0.203\n","[19,   100] loss: 0.173\n","[19,   150] loss: 0.189\n","[20,    50] loss: 0.225\n","[20,   100] loss: 0.214\n","[20,   150] loss: 0.231\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L9GfutKzlbpN","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"846014b7-aaa9-4413-90bd-fe380bc4f904","executionInfo":{"status":"ok","timestamp":1567870464358,"user_tz":-330,"elapsed":128791,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in trainloader:\n","        images, labels = data\n","        outputs = alex_net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 50000 train images: %d %%' % (\n","    100 * correct / total))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 50000 train images: 96 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jMcZT1GzlbpO","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"35939ecd-abb8-495e-eb5a-f0af1f9ac78d","executionInfo":{"status":"ok","timestamp":1567870464359,"user_tz":-330,"elapsed":23,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["total,correct"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 48101)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vY9U-GRSlbpP","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6fa3ef54-1324-4120-a54f-20d60023d008","executionInfo":{"status":"ok","timestamp":1567870496631,"user_tz":-330,"elapsed":28002,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = alex_net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 65 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TtXvK5oxlbpT"},"source":["# Save Model\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Siy8gDP9lbpU","colab":{}},"source":["torch.save(inc.state_dict(), \"inception.pt\")   #,Path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1DAPGoyklbpV","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tpNYNVyKlbpX"},"source":["# Load Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ztRCi1T2lbpX","colab":{}},"source":["inc_load = inception_net()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7zErGC2albpZ","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m8cKjcHTlbpa","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GshAxRjYlbpb","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}