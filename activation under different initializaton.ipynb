{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"activation under different initializaton.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"1qdG3ewSuklG","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import math\n","from matplotlib import pyplot as plt\n","\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from tqdm import tqdm\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2z1LFixouklQ","colab_type":"code","colab":{}},"source":["transform = transforms.Compose(\n","    [transforms.CenterCrop((28,28)),transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","# transform = transforms.Compose(\n","#     [transforms.ToTensor(),transforms.CenterCrop(28,28)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uz_zjP_Aukla","colab_type":"code","outputId":"b64514af-5488-4ac7-97de-72470154e0e9","executionInfo":{"status":"ok","timestamp":1562575236557,"user_tz":-330,"elapsed":8321,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["cifar_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","cifar_testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["170500096it [00:04, 42154560.84it/s]                               \n"],"name":"stderr"},{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qbYTW2bYuklr","colab_type":"code","outputId":"5b9ea68b-0579-4129-da07-5e1f4f453a8b","executionInfo":{"status":"ok","timestamp":1562575237746,"user_tz":-330,"elapsed":8828,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cifar_trainset_random = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","\n","cifar_trainset_random.targets[:50000] = np.random.randint(low=0,high=9,size=50000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W2Q5-nMyukl4","colab_type":"code","outputId":"0f1a2fb8-7e8b-4ccb-dedf-25b9af7dc9b6","executionInfo":{"status":"ok","timestamp":1562575237750,"user_tz":-330,"elapsed":8147,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.unique(cifar_trainset.targets)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"sgx66WSeukmC","colab_type":"code","colab":{}},"source":["trainloader = torch.utils.data.DataLoader(cifar_trainset, batch_size=256,\n","                                          shuffle=False, num_workers=2)\n","testloader = torch.utils.data.DataLoader(cifar_testset, batch_size=256,\n","                                         shuffle=False, num_workers=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"56IaY0k_ukmJ","colab_type":"code","colab":{}},"source":["trainloader_random = torch.utils.data.DataLoader(cifar_trainset_random,batch_size=256,shuffle=False,num_workers=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"onq-wUWDukmQ","colab_type":"code","colab":{}},"source":["classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0Bd9d7Xukma","colab_type":"code","colab":{}},"source":["def xavierweights_init(m):\n","    if isinstance(m,nn.Linear):\n","        size = m.weight.size()\n","        fan_out = size[0] # number of rows\n","        fan_in = size[1] # number of columns\n","        variance = np.sqrt(2.0/(fan_in + fan_out))\n","        \n","        m.weight.data.normal_(0.0, variance)\n","        #print(m.weight.data.normal_(0.0, variance))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ChJ6xPlpukmg","colab_type":"code","colab":{}},"source":["def uniformweights_init(m):\n","    if isinstance(m,nn.Linear):\n","        stdv = 1. / math.sqrt(m.weight.size(1))\n","        \n","        m.weight.data.uniform_(-stdv,stdv)\n","        \n","        if m.bias is not None:\n","             m.bias.data.uniform_(-stdv, stdv)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kBPf_fD7ukmr","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(3*28*28,512)\n","        self.fc2 = nn.Linear(512,512)\n","        self.fc3 = nn.Linear(512,512)\n","        self.fc4 = nn.Linear(512,10)\n","#         self.conv1 = nn.Conv2d(3, 6, 5)\n","#         self.pool = nn.MaxPool2d(2, 2)\n","#         self.conv2 = nn.Conv2d(6, 16, 5)\n","#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","#         self.fc2 = nn.Linear(120, 84)\n","#         self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        #x = x - x.mean(dim=(0,2),keepdim=True)/x.std(dim=(0,2),keepdim=True)\n","        \n","        x = (x.view(-1,3*28*28))\n","        x = self.fc1(x)\n","        x1 = F.relu(x)\n","        x2 = F.relu(self.fc2(x1))\n","        x3 = F.relu(self.fc3(x2))\n","        x = self.fc4(x3)\n","#         x = self.pool(F.relu(self.conv1(x)))\n","#         x = self.pool(F.relu(self.conv2(x)))\n","#         x = x.view(-1, 16 * 5 * 5)\n","#         x = F.relu(self.fc1(x))\n","#         x = F.relu(self.fc2(x))\n","#         x = self.fc3(x)\n","        return x,{'layer1':x1,'layer2':x2,'layer3':x3}\n","\n","\n","net1 = Net()\n","net2 = Net()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jjmzYSPJukmx","colab_type":"code","outputId":"7d64b058-870a-4546-fa7b-c1b3f465f793","executionInfo":{"status":"ok","timestamp":1562575238600,"user_tz":-330,"elapsed":4225,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["net1.apply(xavierweights_init)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=2352, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=512, bias=True)\n","  (fc3): Linear(in_features=512, out_features=512, bias=True)\n","  (fc4): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"icAslptVukm9","colab_type":"code","outputId":"05b52bb2-c75b-49bf-d8e3-48294fe6b642","executionInfo":{"status":"ok","timestamp":1562575238604,"user_tz":-330,"elapsed":3602,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["par_xavier = {}\n","params = list(net1.parameters())\n","i = 0\n","for p in params:\n","    i = i+1\n","    par_xavier[\"layer\"+str(i)] = p.cpu().data\n","    #print(p)\n","par_xavier[\"layer1\"]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0139,  0.0099,  0.0121,  ...,  0.0657, -0.0256,  0.0458],\n","        [-0.0415,  0.0351, -0.0397,  ...,  0.0231, -0.0255, -0.0152],\n","        [-0.0394,  0.0068,  0.0057,  ...,  0.0590,  0.0176,  0.0040],\n","        ...,\n","        [ 0.0150,  0.0272,  0.0011,  ..., -0.0394, -0.0486, -0.0107],\n","        [ 0.0013, -0.0607, -0.0101,  ..., -0.0152,  0.0032,  0.0138],\n","        [-0.0200,  0.0160,  0.0257,  ..., -0.0238,  0.0170,  0.0548]])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"qSMyj2xtuknH","colab_type":"code","outputId":"af3549f3-8fc0-43db-df04-09e9f952db10","executionInfo":{"status":"ok","timestamp":1562575238607,"user_tz":-330,"elapsed":2940,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["net2.apply(uniformweights_init)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=2352, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=512, bias=True)\n","  (fc3): Linear(in_features=512, out_features=512, bias=True)\n","  (fc4): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"_jUhmh_zuknP","colab_type":"code","outputId":"3a2b0b90-8dec-4b69-99b7-223523c6c6c7","executionInfo":{"status":"ok","timestamp":1562575238611,"user_tz":-330,"elapsed":2106,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["params = list(net2.parameters())\n","par_uniform = {}\n","i = 0  \n","for p in params:\n","    i = i+1\n","    par_uniform[\"layer\"+str(i)] = p.cpu().data\n","    #print(p.cpu().data)\n","print(par_uniform[\"layer1\"])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0164,  0.0135,  0.0031,  ...,  0.0111, -0.0008,  0.0096],\n","        [-0.0077, -0.0118, -0.0122,  ..., -0.0170, -0.0077, -0.0086],\n","        [ 0.0006, -0.0016, -0.0036,  ...,  0.0048, -0.0180, -0.0095],\n","        ...,\n","        [-0.0012, -0.0180,  0.0098,  ..., -0.0045, -0.0187,  0.0080],\n","        [ 0.0077, -0.0079,  0.0067,  ..., -0.0132, -0.0188,  0.0048],\n","        [ 0.0109,  0.0118,  0.0195,  ..., -0.0002,  0.0020, -0.0008]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WtCvri83ukna","colab_type":"code","outputId":"aceec208-65ca-415c-edf6-1a23f6e316ac","executionInfo":{"status":"ok","timestamp":1562575238616,"user_tz":-330,"elapsed":1075,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["par_uniform[\"layer1\"].shape\n","np.linalg.norm((par_uniform[\"layer1\"] - par_xavier[\"layer1\"]))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["31.819374"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"1wk0MD34uknm","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net1.parameters(), lr=0.01, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7V7bggrSuknu","colab_type":"code","outputId":"c453430f-4551-4970-fcc3-8dc72074ede9","executionInfo":{"status":"ok","timestamp":1562578650071,"user_tz":-330,"elapsed":380,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["act = []\n","loss_cur = []\n","for epoch in range(100):  # loop over the dataset multiple times\n","    ep_loss = []\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs,_ = net1(inputs)\n","        \n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        \n","\n","        if i % 50 == 49:    # print every 50 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 50))\n","            ep_loss.append(running_loss) # loss per minibatch\n","            running_loss = 0.0\n","            \n","    loss_cur.append(np.mean(ep_loss))   #loss per epoch\n","    if (epoch%5 == 0):\n","        _,acts= net1(inputs)\n","        act.append(acts)\n","\n","print('Finished Training')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[1,    50] loss: 2.039\n","[1,   100] loss: 1.762\n","[1,   150] loss: 1.676\n","[2,    50] loss: 1.551\n","[2,   100] loss: 1.502\n","[2,   150] loss: 1.493\n","[3,    50] loss: 1.411\n","[3,   100] loss: 1.374\n","[3,   150] loss: 1.377\n","[4,    50] loss: 1.309\n","[4,   100] loss: 1.276\n","[4,   150] loss: 1.286\n","[5,    50] loss: 1.223\n","[5,   100] loss: 1.191\n","[5,   150] loss: 1.203\n","[6,    50] loss: 1.143\n","[6,   100] loss: 1.115\n","[6,   150] loss: 1.126\n","[7,    50] loss: 1.065\n","[7,   100] loss: 1.039\n","[7,   150] loss: 1.049\n","[8,    50] loss: 0.988\n","[8,   100] loss: 0.965\n","[8,   150] loss: 0.972\n","[9,    50] loss: 0.913\n","[9,   100] loss: 0.891\n","[9,   150] loss: 0.896\n","[10,    50] loss: 0.841\n","[10,   100] loss: 0.820\n","[10,   150] loss: 0.822\n","[11,    50] loss: 0.768\n","[11,   100] loss: 0.753\n","[11,   150] loss: 0.749\n","[12,    50] loss: 0.696\n","[12,   100] loss: 0.685\n","[12,   150] loss: 0.683\n","[13,    50] loss: 0.631\n","[13,   100] loss: 0.626\n","[13,   150] loss: 0.630\n","[14,    50] loss: 0.572\n","[14,   100] loss: 0.582\n","[14,   150] loss: 0.610\n","[15,    50] loss: 0.574\n","[15,   100] loss: 0.596\n","[15,   150] loss: 0.690\n","[16,    50] loss: 0.595\n","[16,   100] loss: 0.641\n","[16,   150] loss: 0.670\n","[17,    50] loss: 0.596\n","[17,   100] loss: 0.655\n","[17,   150] loss: 0.580\n","[18,    50] loss: 0.558\n","[18,   100] loss: 0.580\n","[18,   150] loss: 0.529\n","[19,    50] loss: 0.512\n","[19,   100] loss: 0.502\n","[19,   150] loss: 0.478\n","[20,    50] loss: 0.480\n","[20,   100] loss: 0.427\n","[20,   150] loss: 0.425\n","[21,    50] loss: 0.449\n","[21,   100] loss: 0.430\n","[21,   150] loss: 0.428\n","[22,    50] loss: 0.445\n","[22,   100] loss: 0.421\n","[22,   150] loss: 0.403\n","[23,    50] loss: 0.419\n","[23,   100] loss: 0.357\n","[23,   150] loss: 0.363\n","[24,    50] loss: 0.384\n","[24,   100] loss: 0.339\n","[24,   150] loss: 0.348\n","[25,    50] loss: 0.320\n","[25,   100] loss: 0.347\n","[25,   150] loss: 0.347\n","[26,    50] loss: 0.321\n","[26,   100] loss: 0.318\n","[26,   150] loss: 0.333\n","[27,    50] loss: 0.321\n","[27,   100] loss: 0.317\n","[27,   150] loss: 0.310\n","[28,    50] loss: 0.293\n","[28,   100] loss: 0.307\n","[28,   150] loss: 0.281\n","[29,    50] loss: 0.244\n","[29,   100] loss: 0.256\n","[29,   150] loss: 0.251\n","[30,    50] loss: 0.227\n","[30,   100] loss: 0.226\n","[30,   150] loss: 0.268\n","[31,    50] loss: 0.235\n","[31,   100] loss: 0.192\n","[31,   150] loss: 0.251\n","[32,    50] loss: 0.233\n","[32,   100] loss: 0.195\n","[32,   150] loss: 0.204\n","[33,    50] loss: 0.215\n","[33,   100] loss: 0.199\n","[33,   150] loss: 0.178\n","[34,    50] loss: 0.197\n","[34,   100] loss: 0.208\n","[34,   150] loss: 0.179\n","[35,    50] loss: 0.166\n","[35,   100] loss: 0.188\n","[35,   150] loss: 0.186\n","[36,    50] loss: 0.179\n","[36,   100] loss: 0.165\n","[36,   150] loss: 0.171\n","[37,    50] loss: 0.166\n","[37,   100] loss: 0.134\n","[37,   150] loss: 0.125\n","[38,    50] loss: 0.131\n","[38,   100] loss: 0.117\n","[38,   150] loss: 0.118\n","[39,    50] loss: 0.117\n","[39,   100] loss: 0.111\n","[39,   150] loss: 0.116\n","[40,    50] loss: 0.087\n","[40,   100] loss: 0.089\n","[40,   150] loss: 0.105\n","[41,    50] loss: 0.083\n","[41,   100] loss: 0.074\n","[41,   150] loss: 0.084\n","[42,    50] loss: 0.078\n","[42,   100] loss: 0.066\n","[42,   150] loss: 0.076\n","[43,    50] loss: 0.069\n","[43,   100] loss: 0.062\n","[43,   150] loss: 0.067\n","[44,    50] loss: 0.052\n","[44,   100] loss: 0.054\n","[44,   150] loss: 0.063\n","[45,    50] loss: 0.049\n","[45,   100] loss: 0.052\n","[45,   150] loss: 0.052\n","[46,    50] loss: 0.042\n","[46,   100] loss: 0.048\n","[46,   150] loss: 0.039\n","[47,    50] loss: 0.039\n","[47,   100] loss: 0.040\n","[47,   150] loss: 0.031\n","[48,    50] loss: 0.029\n","[48,   100] loss: 0.033\n","[48,   150] loss: 0.026\n","[49,    50] loss: 0.028\n","[49,   100] loss: 0.023\n","[49,   150] loss: 0.023\n","[50,    50] loss: 0.018\n","[50,   100] loss: 0.018\n","[50,   150] loss: 0.018\n","[51,    50] loss: 0.014\n","[51,   100] loss: 0.015\n","[51,   150] loss: 0.016\n","[52,    50] loss: 0.012\n","[52,   100] loss: 0.010\n","[52,   150] loss: 0.014\n","[53,    50] loss: 0.009\n","[53,   100] loss: 0.009\n","[53,   150] loss: 0.009\n","[54,    50] loss: 0.007\n","[54,   100] loss: 0.007\n","[54,   150] loss: 0.008\n","[55,    50] loss: 0.005\n","[55,   100] loss: 0.005\n","[55,   150] loss: 0.006\n","[56,    50] loss: 0.004\n","[56,   100] loss: 0.003\n","[56,   150] loss: 0.004\n","[57,    50] loss: 0.003\n","[57,   100] loss: 0.003\n","[57,   150] loss: 0.003\n","[58,    50] loss: 0.002\n","[58,   100] loss: 0.002\n","[58,   150] loss: 0.002\n","[59,    50] loss: 0.002\n","[59,   100] loss: 0.002\n","[59,   150] loss: 0.002\n","[60,    50] loss: 0.001\n","[60,   100] loss: 0.001\n","[60,   150] loss: 0.001\n","[61,    50] loss: 0.001\n","[61,   100] loss: 0.001\n","[61,   150] loss: 0.001\n","[62,    50] loss: 0.001\n","[62,   100] loss: 0.001\n","[62,   150] loss: 0.001\n","[63,    50] loss: 0.001\n","[63,   100] loss: 0.001\n","[63,   150] loss: 0.001\n","[64,    50] loss: 0.001\n","[64,   100] loss: 0.001\n","[64,   150] loss: 0.001\n","[65,    50] loss: 0.001\n","[65,   100] loss: 0.001\n","[65,   150] loss: 0.001\n","[66,    50] loss: 0.001\n","[66,   100] loss: 0.001\n","[66,   150] loss: 0.001\n","[67,    50] loss: 0.001\n","[67,   100] loss: 0.001\n","[67,   150] loss: 0.001\n","[68,    50] loss: 0.001\n","[68,   100] loss: 0.001\n","[68,   150] loss: 0.001\n","[69,    50] loss: 0.001\n","[69,   100] loss: 0.001\n","[69,   150] loss: 0.001\n","[70,    50] loss: 0.001\n","[70,   100] loss: 0.001\n","[70,   150] loss: 0.001\n","[71,    50] loss: 0.001\n","[71,   100] loss: 0.001\n","[71,   150] loss: 0.001\n","[72,    50] loss: 0.001\n","[72,   100] loss: 0.001\n","[72,   150] loss: 0.001\n","[73,    50] loss: 0.001\n","[73,   100] loss: 0.001\n","[73,   150] loss: 0.001\n","[74,    50] loss: 0.001\n","[74,   100] loss: 0.001\n","[74,   150] loss: 0.001\n","[75,    50] loss: 0.001\n","[75,   100] loss: 0.001\n","[75,   150] loss: 0.001\n","[76,    50] loss: 0.001\n","[76,   100] loss: 0.001\n","[76,   150] loss: 0.001\n","[77,    50] loss: 0.000\n","[77,   100] loss: 0.001\n","[77,   150] loss: 0.001\n","[78,    50] loss: 0.000\n","[78,   100] loss: 0.000\n","[78,   150] loss: 0.000\n","[79,    50] loss: 0.000\n","[79,   100] loss: 0.000\n","[79,   150] loss: 0.000\n","[80,    50] loss: 0.000\n","[80,   100] loss: 0.000\n","[80,   150] loss: 0.000\n","[81,    50] loss: 0.000\n","[81,   100] loss: 0.000\n","[81,   150] loss: 0.000\n","[82,    50] loss: 0.000\n","[82,   100] loss: 0.000\n","[82,   150] loss: 0.000\n","[83,    50] loss: 0.000\n","[83,   100] loss: 0.000\n","[83,   150] loss: 0.000\n","[84,    50] loss: 0.000\n","[84,   100] loss: 0.000\n","[84,   150] loss: 0.000\n","[85,    50] loss: 0.000\n","[85,   100] loss: 0.000\n","[85,   150] loss: 0.000\n","[86,    50] loss: 0.000\n","[86,   100] loss: 0.000\n","[86,   150] loss: 0.000\n","[87,    50] loss: 0.000\n","[87,   100] loss: 0.000\n","[87,   150] loss: 0.000\n","[88,    50] loss: 0.000\n","[88,   100] loss: 0.000\n","[88,   150] loss: 0.000\n","[89,    50] loss: 0.000\n","[89,   100] loss: 0.000\n","[89,   150] loss: 0.000\n","[90,    50] loss: 0.000\n","[90,   100] loss: 0.000\n","[90,   150] loss: 0.000\n","[91,    50] loss: 0.000\n","[91,   100] loss: 0.000\n","[91,   150] loss: 0.000\n","[92,    50] loss: 0.000\n","[92,   100] loss: 0.000\n","[92,   150] loss: 0.000\n","[93,    50] loss: 0.000\n","[93,   100] loss: 0.000\n","[93,   150] loss: 0.000\n","[94,    50] loss: 0.000\n","[94,   100] loss: 0.000\n","[94,   150] loss: 0.000\n","[95,    50] loss: 0.000\n","[95,   100] loss: 0.000\n","[95,   150] loss: 0.000\n","[96,    50] loss: 0.000\n","[96,   100] loss: 0.000\n","[96,   150] loss: 0.000\n","[97,    50] loss: 0.000\n","[97,   100] loss: 0.000\n","[97,   150] loss: 0.000\n","[98,    50] loss: 0.000\n","[98,   100] loss: 0.000\n","[98,   150] loss: 0.000\n","[99,    50] loss: 0.000\n","[99,   100] loss: 0.000\n","[99,   150] loss: 0.000\n","[100,    50] loss: 0.000\n","[100,   100] loss: 0.000\n","[100,   150] loss: 0.000\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rdRaP1bBukn6","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net2.parameters(), lr=0.01, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6t4uHZfMukoC","colab_type":"code","outputId":"ec3b7845-a19b-45f3-af31-2b4b6ff47fb0","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1562578667090,"user_tz":-330,"elapsed":17137,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["actu = []\n","lossu_cur = []\n","for epoch in range(100):  # loop over the dataset multiple times\n","    ep_lossu = []\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs,_ = net2(inputs)\n","        \n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        \n","\n","        if i % 50 == 49:    # print every 50 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 50))\n","            ep_lossu.append(running_loss) # loss per minibatch\n","            running_loss = 0.0\n","            \n","    lossu_cur.append(np.mean(ep_lossu))   #loss per epoch\n","    if (epoch%5 == 0):\n","        _,acts= net2(inputs)\n","        actu.append(acts)\n","\n","print('Finished Training')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[1,    50] loss: 2.281\n","[1,   100] loss: 2.141\n","[1,   150] loss: 1.990\n","[2,    50] loss: 1.805\n","[2,   100] loss: 1.730\n","[2,   150] loss: 1.692\n","[3,    50] loss: 1.610\n","[3,   100] loss: 1.562\n","[3,   150] loss: 1.550\n","[4,    50] loss: 1.480\n","[4,   100] loss: 1.448\n","[4,   150] loss: 1.447\n","[5,    50] loss: 1.387\n","[5,   100] loss: 1.364\n","[5,   150] loss: 1.371\n","[6,    50] loss: 1.316\n","[6,   100] loss: 1.294\n","[6,   150] loss: 1.306\n","[7,    50] loss: 1.251\n","[7,   100] loss: 1.230\n","[7,   150] loss: 1.247\n","[8,    50] loss: 1.192\n","[8,   100] loss: 1.170\n","[8,   150] loss: 1.191\n","[9,    50] loss: 1.134\n","[9,   100] loss: 1.113\n","[9,   150] loss: 1.137\n","[10,    50] loss: 1.075\n","[10,   100] loss: 1.059\n","[10,   150] loss: 1.080\n","[11,    50] loss: 1.018\n","[11,   100] loss: 1.004\n","[11,   150] loss: 1.022\n","[12,    50] loss: 0.962\n","[12,   100] loss: 0.950\n","[12,   150] loss: 0.963\n","[13,    50] loss: 0.904\n","[13,   100] loss: 0.897\n","[13,   150] loss: 0.908\n","[14,    50] loss: 0.852\n","[14,   100] loss: 0.846\n","[14,   150] loss: 0.851\n","[15,    50] loss: 0.797\n","[15,   100] loss: 0.794\n","[15,   150] loss: 0.793\n","[16,    50] loss: 0.750\n","[16,   100] loss: 0.749\n","[16,   150] loss: 0.743\n","[17,    50] loss: 0.713\n","[17,   100] loss: 0.716\n","[17,   150] loss: 0.705\n","[18,    50] loss: 0.722\n","[18,   100] loss: 0.735\n","[18,   150] loss: 0.789\n","[19,    50] loss: 0.751\n","[19,   100] loss: 0.739\n","[19,   150] loss: 0.737\n","[20,    50] loss: 0.681\n","[20,   100] loss: 0.708\n","[20,   150] loss: 0.676\n","[21,    50] loss: 0.624\n","[21,   100] loss: 0.640\n","[21,   150] loss: 0.615\n","[22,    50] loss: 0.609\n","[22,   100] loss: 0.613\n","[22,   150] loss: 0.590\n","[23,    50] loss: 0.603\n","[23,   100] loss: 0.576\n","[23,   150] loss: 0.565\n","[24,    50] loss: 0.592\n","[24,   100] loss: 0.565\n","[24,   150] loss: 0.551\n","[25,    50] loss: 0.550\n","[25,   100] loss: 0.524\n","[25,   150] loss: 0.537\n","[26,    50] loss: 0.500\n","[26,   100] loss: 0.497\n","[26,   150] loss: 0.484\n","[27,    50] loss: 0.482\n","[27,   100] loss: 0.496\n","[27,   150] loss: 0.467\n","[28,    50] loss: 0.446\n","[28,   100] loss: 0.460\n","[28,   150] loss: 0.418\n","[29,    50] loss: 0.434\n","[29,   100] loss: 0.439\n","[29,   150] loss: 0.380\n","[30,    50] loss: 0.391\n","[30,   100] loss: 0.394\n","[30,   150] loss: 0.346\n","[31,    50] loss: 0.364\n","[31,   100] loss: 0.355\n","[31,   150] loss: 0.308\n","[32,    50] loss: 0.351\n","[32,   100] loss: 0.354\n","[32,   150] loss: 0.299\n","[33,    50] loss: 0.351\n","[33,   100] loss: 0.353\n","[33,   150] loss: 0.301\n","[34,    50] loss: 0.342\n","[34,   100] loss: 0.350\n","[34,   150] loss: 0.297\n","[35,    50] loss: 0.328\n","[35,   100] loss: 0.332\n","[35,   150] loss: 0.265\n","[36,    50] loss: 0.333\n","[36,   100] loss: 0.316\n","[36,   150] loss: 0.270\n","[37,    50] loss: 0.311\n","[37,   100] loss: 0.259\n","[37,   150] loss: 0.255\n","[38,    50] loss: 0.267\n","[38,   100] loss: 0.242\n","[38,   150] loss: 0.250\n","[39,    50] loss: 0.241\n","[39,   100] loss: 0.218\n","[39,   150] loss: 0.248\n","[40,    50] loss: 0.218\n","[40,   100] loss: 0.195\n","[40,   150] loss: 0.266\n","[41,    50] loss: 0.186\n","[41,   100] loss: 0.186\n","[41,   150] loss: 0.247\n","[42,    50] loss: 0.177\n","[42,   100] loss: 0.171\n","[42,   150] loss: 0.202\n","[43,    50] loss: 0.146\n","[43,   100] loss: 0.176\n","[43,   150] loss: 0.175\n","[44,    50] loss: 0.142\n","[44,   100] loss: 0.159\n","[44,   150] loss: 0.163\n","[45,    50] loss: 0.135\n","[45,   100] loss: 0.148\n","[45,   150] loss: 0.150\n","[46,    50] loss: 0.130\n","[46,   100] loss: 0.141\n","[46,   150] loss: 0.141\n","[47,    50] loss: 0.124\n","[47,   100] loss: 0.121\n","[47,   150] loss: 0.147\n","[48,    50] loss: 0.125\n","[48,   100] loss: 0.098\n","[48,   150] loss: 0.129\n","[49,    50] loss: 0.128\n","[49,   100] loss: 0.093\n","[49,   150] loss: 0.119\n","[50,    50] loss: 0.121\n","[50,   100] loss: 0.103\n","[50,   150] loss: 0.106\n","[51,    50] loss: 0.109\n","[51,   100] loss: 0.092\n","[51,   150] loss: 0.099\n","[52,    50] loss: 0.097\n","[52,   100] loss: 0.076\n","[52,   150] loss: 0.084\n","[53,    50] loss: 0.093\n","[53,   100] loss: 0.072\n","[53,   150] loss: 0.074\n","[54,    50] loss: 0.089\n","[54,   100] loss: 0.069\n","[54,   150] loss: 0.065\n","[55,    50] loss: 0.077\n","[55,   100] loss: 0.067\n","[55,   150] loss: 0.059\n","[56,    50] loss: 0.068\n","[56,   100] loss: 0.055\n","[56,   150] loss: 0.062\n","[57,    50] loss: 0.063\n","[57,   100] loss: 0.048\n","[57,   150] loss: 0.058\n","[58,    50] loss: 0.048\n","[58,   100] loss: 0.050\n","[58,   150] loss: 0.046\n","[59,    50] loss: 0.051\n","[59,   100] loss: 0.040\n","[59,   150] loss: 0.043\n","[60,    50] loss: 0.042\n","[60,   100] loss: 0.040\n","[60,   150] loss: 0.040\n","[61,    50] loss: 0.039\n","[61,   100] loss: 0.040\n","[61,   150] loss: 0.034\n","[62,    50] loss: 0.036\n","[62,   100] loss: 0.034\n","[62,   150] loss: 0.028\n","[63,    50] loss: 0.037\n","[63,   100] loss: 0.042\n","[63,   150] loss: 0.031\n","[64,    50] loss: 0.043\n","[64,   100] loss: 0.032\n","[64,   150] loss: 0.029\n","[65,    50] loss: 0.025\n","[65,   100] loss: 0.033\n","[65,   150] loss: 0.024\n","[66,    50] loss: 0.018\n","[66,   100] loss: 0.032\n","[66,   150] loss: 0.025\n","[67,    50] loss: 0.017\n","[67,   100] loss: 0.026\n","[67,   150] loss: 0.026\n","[68,    50] loss: 0.019\n","[68,   100] loss: 0.020\n","[68,   150] loss: 0.024\n","[69,    50] loss: 0.017\n","[69,   100] loss: 0.018\n","[69,   150] loss: 0.017\n","[70,    50] loss: 0.014\n","[70,   100] loss: 0.013\n","[70,   150] loss: 0.016\n","[71,    50] loss: 0.011\n","[71,   100] loss: 0.010\n","[71,   150] loss: 0.013\n","[72,    50] loss: 0.009\n","[72,   100] loss: 0.007\n","[72,   150] loss: 0.009\n","[73,    50] loss: 0.007\n","[73,   100] loss: 0.005\n","[73,   150] loss: 0.004\n","[74,    50] loss: 0.003\n","[74,   100] loss: 0.003\n","[74,   150] loss: 0.003\n","[75,    50] loss: 0.002\n","[75,   100] loss: 0.002\n","[75,   150] loss: 0.002\n","[76,    50] loss: 0.001\n","[76,   100] loss: 0.001\n","[76,   150] loss: 0.001\n","[77,    50] loss: 0.001\n","[77,   100] loss: 0.001\n","[77,   150] loss: 0.001\n","[78,    50] loss: 0.001\n","[78,   100] loss: 0.001\n","[78,   150] loss: 0.001\n","[79,    50] loss: 0.001\n","[79,   100] loss: 0.001\n","[79,   150] loss: 0.001\n","[80,    50] loss: 0.001\n","[80,   100] loss: 0.001\n","[80,   150] loss: 0.001\n","[81,    50] loss: 0.001\n","[81,   100] loss: 0.001\n","[81,   150] loss: 0.001\n","[82,    50] loss: 0.001\n","[82,   100] loss: 0.001\n","[82,   150] loss: 0.001\n","[83,    50] loss: 0.001\n","[83,   100] loss: 0.001\n","[83,   150] loss: 0.001\n","[84,    50] loss: 0.000\n","[84,   100] loss: 0.001\n","[84,   150] loss: 0.000\n","[85,    50] loss: 0.000\n","[85,   100] loss: 0.000\n","[85,   150] loss: 0.000\n","[86,    50] loss: 0.000\n","[86,   100] loss: 0.000\n","[86,   150] loss: 0.000\n","[87,    50] loss: 0.000\n","[87,   100] loss: 0.000\n","[87,   150] loss: 0.000\n","[88,    50] loss: 0.000\n","[88,   100] loss: 0.000\n","[88,   150] loss: 0.000\n","[89,    50] loss: 0.000\n","[89,   100] loss: 0.000\n","[89,   150] loss: 0.000\n","[90,    50] loss: 0.000\n","[90,   100] loss: 0.000\n","[90,   150] loss: 0.000\n","[91,    50] loss: 0.000\n","[91,   100] loss: 0.000\n","[91,   150] loss: 0.000\n","[92,    50] loss: 0.000\n","[92,   100] loss: 0.000\n","[92,   150] loss: 0.000\n","[93,    50] loss: 0.000\n","[93,   100] loss: 0.000\n","[93,   150] loss: 0.000\n","[94,    50] loss: 0.000\n","[94,   100] loss: 0.000\n","[94,   150] loss: 0.000\n","[95,    50] loss: 0.000\n","[95,   100] loss: 0.000\n","[95,   150] loss: 0.000\n","[96,    50] loss: 0.000\n","[96,   100] loss: 0.000\n","[96,   150] loss: 0.000\n","[97,    50] loss: 0.000\n","[97,   100] loss: 0.000\n","[97,   150] loss: 0.000\n","[98,    50] loss: 0.000\n","[98,   100] loss: 0.000\n","[98,   150] loss: 0.000\n","[99,    50] loss: 0.000\n","[99,   100] loss: 0.000\n","[99,   150] loss: 0.000\n","[100,    50] loss: 0.000\n","[100,   100] loss: 0.000\n","[100,   150] loss: 0.000\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CvBqCk0zukoP","colab_type":"code","colab":{}},"source":["ac = (act[0][\"layer1\"].cpu()).detach().numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sRWJS1C0ukoV","colab_type":"code","colab":{}},"source":["acu = (actu[0][\"layer1\"].cpu()).detach().numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuqsY4ACukoc","colab_type":"code","colab":{}},"source":["ac1 = (act[1][\"layer1\"].cpu()).detach().numpy()\n","acu1 = (actu[1][\"layer1\"].cpu()).detach().numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Expsgu5pukol","colab_type":"code","colab":{}},"source":["ace = (act[-1][\"layer1\"].cpu()).detach().numpy()\n","acue = (actu[-1][\"layer1\"].cpu()).detach().numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BJ5xswpAukox","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a95489dd-acc5-4275-847d-ec84d7093eb1","executionInfo":{"status":"ok","timestamp":1562579808370,"user_tz":-330,"elapsed":934,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["np.linalg.norm(acue>0 - (ace>0))"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["160.22484201895784"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"D4q5dHvUuko4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"af66cb0f-b209-40f3-ae9c-28b3ca4dafc9","executionInfo":{"status":"ok","timestamp":1562579810075,"user_tz":-330,"elapsed":588,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["act[-1][\"layer1\"]>0,actu[-1][\"layer1\"]>0"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 0, 1,  ..., 0, 1, 0],\n","         [1, 0, 0,  ..., 0, 0, 1],\n","         [1, 0, 0,  ..., 1, 1, 1],\n","         ...,\n","         [0, 0, 0,  ..., 0, 1, 1],\n","         [1, 1, 0,  ..., 0, 1, 0],\n","         [1, 1, 0,  ..., 1, 1, 0]], dtype=torch.uint8),\n"," tensor([[1, 1, 0,  ..., 0, 0, 1],\n","         [1, 1, 0,  ..., 1, 1, 0],\n","         [1, 1, 0,  ..., 1, 1, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 0,  ..., 1, 0, 0]], dtype=torch.uint8))"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"_-rx13A4ukpB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a7341f20-e44e-4acc-898a-44b9fdc5ed53","executionInfo":{"status":"ok","timestamp":1562579812646,"user_tz":-330,"elapsed":924,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["np.linalg.norm(acu>0 - (ac>0)),np.linalg.norm(acu1>0 - (ac1>0))"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(177.01412373028316, 172.41519654601214)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"c3bHtcFXukpK","colab_type":"code","outputId":"a5b07073-d11c-471a-f67f-41c712ce82eb","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1562580419757,"user_tz":-330,"elapsed":869,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["print(np.linalg.norm(ac>0))\n","print(np.linalg.norm(ace>0))\n","print(np.linalg.norm(acu>0))\n","print(np.linalg.norm(acue>0))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["142.9300528230505\n","130.330349496961\n","145.5163221085525\n","123.89511693363868\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dSasIEr8ukpS","colab_type":"code","outputId":"4eed926f-bcd1-4d7e-caa9-5adbe9590dbb","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1562580731573,"user_tz":-330,"elapsed":1472,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["print(np.linalg.norm( (ac>0) ^ (ace>0)))\n","print(np.linalg.norm( (acu>0) ^ (acue>0)))\n","print(np.linalg.norm( (ac>0) ^ (acu>0)))\n","print(np.linalg.norm( (ace>0) ^ (acue>0)))\n","# print(np.linalg.norm(acu>0-acue>0))\n","# print(np.linalg.norm(ac>0 - acu>0))\n","# print(np.linalg.norm(ace>0 - acue>0))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["105.0380883299006\n","122.81286577553672\n","145.13442045221387\n","137.8695035169127\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sud25R8cukpd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":817},"outputId":"47d12db9-105d-487c-ade0-2eaba8110b14","executionInfo":{"status":"ok","timestamp":1562580662213,"user_tz":-330,"elapsed":918,"user":{"displayName":"Rahul Vashisht cs18d006","photoUrl":"","userId":"07093414448675380290"}}},"source":["z=(ac>0) ^ (ace>0)\n","print(z.shape)\n","print(z[0])"],"execution_count":46,"outputs":[{"output_type":"stream","text":["(80, 512)\n","[ True False False  True False False  True  True False False  True False\n","  True  True False False  True  True  True  True False False False False\n","  True False False False False False False False  True False  True False\n"," False False False  True False False  True  True False False  True  True\n","  True  True False False False False False False False False False False\n"," False  True False  True False False False False False  True False False\n","  True False  True False False False False False  True  True False  True\n","  True False False False False False  True  True False  True  True False\n","  True False False False False False  True False False False False  True\n"," False False  True False  True False  True False False False False False\n"," False  True False False False False False False False  True False  True\n"," False  True False False False False False  True False  True False  True\n","  True  True  True False False False  True False False False False False\n"," False False  True False False False False False False  True False False\n","  True False  True False False False  True False  True  True  True  True\n","  True False False  True False False  True False False  True  True False\n","  True False  True  True False False False False False False False False\n"," False  True  True  True False False False  True  True False False  True\n","  True  True  True False False False False False False  True  True False\n"," False  True  True  True  True False  True False False False False False\n","  True False False False False  True  True False  True False False  True\n"," False False  True  True  True False False False False False False False\n","  True False  True  True  True False  True False False False False False\n"," False  True False False  True False  True False False False  True False\n"," False False False False False False False False False False False False\n"," False False False False  True False False False False  True  True False\n"," False False False False  True False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False  True False False False False False False\n"," False False False False False False False False False False False False\n","  True  True False  True  True  True False False False False False False\n","  True False  True  True  True False False  True  True False  True False\n"," False  True  True False  True False False False  True False False False\n"," False False False  True False  True False  True False  True False False\n","  True  True False False  True False False False  True False False False\n","  True False False False  True  True  True False  True  True False  True\n"," False  True False  True  True  True False False False False False False\n","  True False False False  True False False False False False  True False\n","  True  True False  True False False False False False False  True False\n"," False False False False False False False False False False False  True\n","  True False False False False  True False False False False False  True\n"," False False False False False False False False  True False False False\n"," False  True False False False False False False]\n"],"name":"stdout"}]}]}